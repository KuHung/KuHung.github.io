<!DOCTYPE html>
<html lang="zh-CN">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="谷粒">
  <meta name="description" content="数据挖掘/机器学习工程师">
  <meta name="keywords" content="华中科技大学,谷粒,数据挖掘,网易游戏,用户分析,增长黑客,开发者,极客,代码,开源,Developer,Programmer,Coder,Geek,DataScientist">
  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-76017508-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  <link rel="prev" href="https://kuhungio.me/2019/what-is-data-mining/" />
  <link rel="next" href="https://kuhungio.me/2019/the-next-step-for-machine-learning/" />
  <link rel="canonical" href="https://kuhungio.me/2019/bert-chinese-finetune/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           Bert Chinese Finetune 中文语料的 Bert 微调 | Kuhung&#39;s Blog
       
  </title>
  <meta name="title" content="Bert Chinese Finetune 中文语料的 Bert 微调 | Kuhung&#39;s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://kuhungio.me"
    },
    "articleSection" : "posts",
    "name" : "Bert Chinese Finetune 中文语料的 Bert 微调",
    "headline" : "Bert Chinese Finetune 中文语料的 Bert 微调",
    "description" : "Finetune Bert for Chinese NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。
Bert 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 Bert as service 代码的开源，使用 Bert 分类或阅读理解的副产物&ndash;词空间，成为一个更具实用价值的方向。
因而，此文档着重以一个例子，梳理 finetune 垂直语料，获得微调后的模型 这一过程。Bert 原理或 Bert as service 还请移步官方文档。
依赖 python==3.6 tensorflow&gt;=1.11.0  预训练模型  下载 BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  数据准备  train.tsv 训练集 dev.tsv 验证集   数据格式 第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。
fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!... houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客... game	赛季末用他们两天上一段，7.",
    "inLanguage" : "zh-CN",
    "author" : "谷粒",
    "creator" : "谷粒",
    "publisher": "谷粒",
    "accountablePerson" : "谷粒",
    "copyrightHolder" : "谷粒",
    "copyrightYear" : "2019",
    "datePublished": "2019-02-17 11:30:26 &#43;0800 CST",
    "dateModified" : "2019-02-17 11:30:26 &#43;0800 CST",
    "url" : "https://kuhungio.me/2019/bert-chinese-finetune/",
    "wordCount" : "260",
    "keywords" : [ "NLP","tutorial", "Kuhung&#39;s Blog"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://kuhungio.me">Kuhung&#39;s Blog</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="About">About</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://kuhungio.me">Kuhung&#39;s Blog</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="About">About</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Bert Chinese Finetune 中文语料的 Bert 微调</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://kuhungio.me" rel="author">谷粒</a> with ♥
                <span class="post-time">
                on <time datetime=2019-02-17 itemprop="datePublished">February 17, 2019</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://kuhungio.me/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"> 自然语言处理 </a>
                        
                </span>

                |
                <a href="#gitalk-container" itemprop="discussionUrl">
                    <span class="gitalk-comment-count" itemprop="commentCount"></span>
                </a>
                条评论
        </div>
    </header>

        <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title"></h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#finetune-bert-for-chinese">Finetune Bert for Chinese</a>
<ul>
<li><a href="#依赖">依赖</a>
<ul>
<li><a href="#预训练模型">预训练模型</a></li>
<li><a href="#数据准备">数据准备</a>
<ul>
<li><a href="#数据格式">数据格式</a></li>
</ul></li>
</ul></li>
<li><a href="#操作">操作</a>
<ul>
<li><a href="#修改-run-classifier-py">修改 <code>run_classifier.py</code></a>
<ul>
<li><a href="#自定义-dataprocessor">自定义 DataProcessor</a></li>
<li><a href="#添加-demoprocessor">添加 DemoProcessor</a></li>
</ul></li>
</ul></li>
<li><a href="#启动训练">启动训练</a></li>
<li><a href="#总结">总结</a></li>
</ul></li>
<li><a href="#参考资料">参考资料</a></li>
</ul>
</nav>
  </div>
</div>

<script type="text/javascript">
  window.onload = function () {
    var fix = $('.post-toc');
    var end = $('.post-comment');
    var fixTop = fix.offset().top, fixHeight = fix.height();
    var endTop, miss;
    var offsetTop = fix[0].offsetTop;

    $(window).scroll(function () {
      var docTop = Math.max(document.body.scrollTop, document.documentElement.scrollTop);

      if (end.length > 0) {
        endTop = end.offset().top;
        miss = endTop - docTop - fixHeight;
      }

      if (fixTop < docTop) {
        fix.css({ 'position': 'fixed' });
        if ((end.length > 0) && (endTop < (docTop + fixHeight))) {
          fix.css({ top: miss });
        } else {
          fix.css({ top: 0 });
        }
      } else {
        fix.css({ 'position': 'absolute' });
        fix.css({ top: offsetTop });
      }
    })
  }
</script>

    <div class="post-content">
        

        

        
        

          
          
          

          
          
          

          

<h1 id="finetune-bert-for-chinese">Finetune Bert for Chinese</h1>

<p>NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。</p>

<p><a href="https://github.com/google-research/bert" rel="nofollow noreferrer" target="_blank">Bert</a> 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 <a href="https://github.com/hanxiao/bert-as-service" rel="nofollow noreferrer" target="_blank">Bert as service</a> 代码的开源，使用 Bert 分类或阅读理解的副产物&ndash;词空间，成为一个更具实用价值的方向。</p>

<p>因而，此文档着重以一个例子，梳理 <strong>finetune 垂直语料，获得微调后的模型</strong> 这一过程。Bert 原理或 Bert as service 还请移步官方文档。</p>

<h2 id="依赖">依赖</h2>

<pre><code class="language-bash">python==3.6
tensorflow&gt;=1.11.0
</code></pre>

<h3 id="预训练模型">预训练模型</h3>

<ul>
<li>下载 <strong><a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" rel="nofollow noreferrer" target="_blank"><code>BERT-Base, Chinese</code></a></strong>:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters</li>
</ul>

<h3 id="数据准备">数据准备</h3>

<ul>
<li><code>train.tsv</code> 训练集</li>
<li><code>dev.tsv</code> 验证集
<br /></li>
</ul>

<h4 id="数据格式">数据格式</h4>

<p>第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。</p>

<pre><code class="language-csv">fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!...
houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客...
game	赛季末用他们两天上一段，7.20最强LOL上分英雄推荐！ 各位小伙...
</code></pre>

<p>样例数据位置：<a href="https://github.com/kuhung/bert_finetune/tree/master/data" rel="nofollow noreferrer" target="_blank">data</a></p>

<p>数据格式取决于业务场景，后面也可根据格式调整代码里的数据导入方式。</p>

<h2 id="操作">操作</h2>

<pre><code class="language-shell">git clone https://github.com/google-research/bert.git
cd bert
</code></pre>

<p>bert 的 finetune 主要存在两类应用场景：分类和阅读理解。因分类较为容易获得样本，以下以分类为例，做模型微调：</p>

<h3 id="修改-run-classifier-py">修改 <code>run_classifier.py</code></h3>

<h4 id="自定义-dataprocessor">自定义 DataProcessor</h4>

<pre><code class="language-python">class DemoProcessor(DataProcessor):
    &quot;&quot;&quot;Processor for Demo data set.&quot;&quot;&quot;

    def __init__(self):
        self.labels = set()
    
    def get_train_examples(self, data_dir):
        &quot;&quot;&quot;See base class.&quot;&quot;&quot;
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, &quot;train.tsv&quot;)), &quot;train&quot;)

    def get_dev_examples(self, data_dir):
        &quot;&quot;&quot;See base class.&quot;&quot;&quot;
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, &quot;dev.tsv&quot;)), &quot;dev&quot;)

    def get_test_examples(self, data_dir):
      &quot;&quot;&quot;See base class.&quot;&quot;&quot;
      return self._create_examples(
          self._read_tsv(os.path.join(data_dir, &quot;test.tsv&quot;)), &quot;test&quot;)

    def get_labels(self):
        &quot;&quot;&quot;See base class.&quot;&quot;&quot;
        # return list(self.labels)
        return [&quot;fashion&quot;, &quot;houseliving&quot;,&quot;game&quot;] # 根据 label 自定义


    def _create_examples(self, lines, set_type):
        &quot;&quot;&quot;Creates examples for the training and dev sets.&quot;&quot;&quot;
        examples = []
        for (i, line) in enumerate(lines):
            guid = &quot;%s-%s&quot; % (set_type, i)
            text_a = tokenization.convert_to_unicode(line[1])
            label = tokenization.convert_to_unicode(line[0])
            self.labels.add(label)
            examples.append(
                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))
        return examples

</code></pre>

<h4 id="添加-demoprocessor">添加 DemoProcessor</h4>

<pre><code class="language-python">  processors = {
      &quot;cola&quot;: ColaProcessor,
      &quot;mnli&quot;: MnliProcessor,
      &quot;mrpc&quot;: MrpcProcessor,
      &quot;xnli&quot;: XnliProcessor,
      &quot;demo&quot;: DemoProcessor,
  }
</code></pre>

<h2 id="启动训练">启动训练</h2>

<pre><code class="language-shell">export BERT_Chinese_DIR=/path/to/bert/chinese_L-12_H-768_A-12
export Demo_DIR=/path/to/DemoDate

python run_classifier.py \
  --task_name=demo \
  --do_train=true \
  --do_eval=true \
  --data_dir=$Demo_DIR \
  --vocab_file=$BERT_Chinese_DIR/vocab.txt \
  --bert_config_file=$BERT_Chinese_DIR/bert_config.json \
  --init_checkpoint=$BERT_Chinese_DIR/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/tmp/Demo_output/
</code></pre>

<p>若一切顺利，将会有以下输出:</p>

<pre><code class="language-shell">***** Eval results *****
  eval_accuracy = xx
  eval_loss = xx
  global_step = xx
  loss = xx
</code></pre>

<p>最终，微调后的模型保存在<strong>output_dir</strong>指向的文件夹中。</p>

<h2 id="总结">总结</h2>

<p>Bert 预训练后的 finetune，是一种很高效的方式，节省时间，同时提高模型在垂直语料的表现。finetune 过程，实际上不难。较大的难点在于数据准备和 pipeline 的设计。从商业角度讲，应着重考虑 finetune 之后，模型有效性的证明，以及在业务场景中的应用。如果评估指标和业务场景都已缕清，那么不妨一试。</p>

<ul>
<li>Github 地址：<a href="https://github.com/kuhung/bert_finetune" rel="nofollow noreferrer" target="_blank">https://github.com/kuhung/bert_finetune</a></li>
</ul>

<h1 id="参考资料">参考资料</h1>

<ul>
<li><a href="https://github.com/NLPScott/bert-Chinese-classification-task" rel="nofollow noreferrer" target="_blank">https://github.com/NLPScott/bert-Chinese-classification-task</a></li>
<li><a href="https://www.jianshu.com/p/aa2eff7ec5c1" rel="nofollow noreferrer" target="_blank">https://www.jianshu.com/p/aa2eff7ec5c1</a></li>
</ul>

    </div>

    <div class="post-copyright">
            
            <p class="copyright-item">
                <span>Author:</span>
                <span>谷粒 </span>
                </p>
            

            
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://kuhungio.me/2019/bert-chinese-finetune/>
                        <script>
                            document.write(decodeURI(location.origin + location.pathname))
                        </script>
                    </a>
            </p>
            
            
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>


    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s):
            
            <span class="tag"><a href="https://kuhungio.me/tags/nlp/">
                    #NLP</a></span>
            
            <span class="tag"><a href="https://kuhungio.me/tags/tutorial/">
                    #tutorial</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> ·
                <span><a href="https://kuhungio.me">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://kuhungio.me/2019/what-is-data-mining/" class="prev" rel="prev" title="What is Data Mining 什么是数据挖掘"><i class="iconfont icon-left"></i>&nbsp;What is Data Mining 什么是数据挖掘</a>
        
        
        <a href="https://kuhungio.me/2019/the-next-step-for-machine-learning/" class="next" rel="next" title="机器学习落地需攻破的9个难题 The Next Step for Machine Learning">机器学习落地需攻破的9个难题 The Next Step for Machine Learning&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>
</article>
          
<div class="post-comment"><div onclick="showDisqus();" id="disqus_title" class="disqus_title">显示 Disqus 评论</div><div id="gitalk-container" class="gitalk-container"></div>
    <link rel="stylesheet" href="/lib/gitalk/gitalk-1.2.2.min.css">
    <script src="/lib/gitalk/gitalk-1.2.2.min.js"></script>
    <script type="text/javascript">
      var gitalk = new Gitalk({
        id: 'a2b71e2bbe8c6f50be25facda34d9d63',
        title: 'Bert Chinese Finetune 中文语料的 Bert 微调',
        clientID: '7e5b8bd7063e5315e349',
        clientSecret: 'd6bd237e0a078b7e343775a47533d7b95d364899',
        repo: 'kuhung.github.io',
        owner: 'kuhung',
        admin: ['kuhung'],
        body: decodeURI(location.href)
      });
      gitalk.render('gitalk-container');
    </script>
    <noscript>Please enable JavaScript to view the
      <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a>
    </noscript><div id="disqus_thread"></div>
    <script type="text/javascript">
    function showDisqus() {
      

      
      
      
      

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = false;
      var disqus_shortname = 'kuhungio';
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

      window.location.hash = "#disqus_thread";
    }
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>

          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2016 - 2019</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i>
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://kuhungio.me">谷粒</a> | </span>
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span>
    </div>
</footer>












    
    
    <script src="/js/vendor_no_gallery.min.js" async=""></script>
    
  



     </div>
  </body>
</html>
