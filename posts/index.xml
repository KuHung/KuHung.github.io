<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/posts/</link>
    <description>Recent content in Posts on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 12 Dec 2020 10:57:25 +0800</lastBuildDate>
    
	<atom:link href="https://kuhungio.me/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>【手动置顶】文章发布计划</title>
      <link>https://kuhungio.me/2020/article-publishing-plan/</link>
      <pubDate>Sat, 12 Dec 2020 10:57:25 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/article-publishing-plan/</guid>
      <description>文章发布计划：
前言 拟定此文的目的，是为了监督文章产出。类似与 OKR，先自我设定目标，进行 SMART 拆解，防止文章输出流产。
事实上，在计划中的文章，远多于实际发布。因而，如何保证其稳步推进，保证“流水线”式的生产，显得尤为重要。
这条在商业中应用广泛：稳定的商业模式，除了可盈利外，另一项便是保证批量化、工业化生产，以期带来持续性的收益。
虽说文章这种东西，说它是流水线生产的结果，有降低其逼格的嫌疑。但对于我来说，实际上，每篇文章的写作，确实都是类似的流程。
广泛阅读/社交互动察觉 确定立意 收集资料/代码 构建思维导图，确定大纲 内容填充 反复阅读，修改表达 内容多平台发布 反馈收集：曝光、点击、停留、点赞、收藏、评论 几个月后重读，修改再发布（个人网站）  如果这套模式能够稳定下来，其迁移到小视频制作，也是稳妥的。
 排期计划    文章代号 耗时预估 计划发布 实际发布 优先级 备注     游戏机制设计 6h 2020.12.13  ⭐⭐⭐ 游戏可玩性的来源   高绩效教练        机器学习的可解释性        稀缺资源的分配        股市真规则         关于作者</description>
    </item>
    
    <item>
      <title>为度过原神长草期，我写了个原神放置类单机小游戏</title>
      <link>https://kuhungio.me/2020/yuanshen-idle-feedback/</link>
      <pubDate>Mon, 16 Nov 2020 00:37:39 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/yuanshen-idle-feedback/</guid>
      <description>游戏地址：https://kuhungio.me/yuanshen-idle/
很高兴能和大家分享这款小游戏。如果恰好你也喜欢原神这款游戏，想在长草期放松放松，那么这款放置类游戏一定不要错过。
游戏模板来源于 Couy69 的 vue-idle-game，副本填充内容来自原神米游社等公开社区。所有内容均来自公开互联网，业余时间打造，非内鬼，不py。
对这款放置挂类游戏的任何建议，欢迎通过以下三种方式联系。
 拥有 GitHub 账号，可直接下方留言。 关注我万年不发一条的微信公众号【谷粒说数】，留言反馈。 发送电子邮件至 kuhung#foxmail.com(@替换#)，进行反馈。  请选择你最方便的形式。
为答谢各位的支持，将于12月1号，送出三份原神周边。抽取三位提出宝贵建议的同学，快递上门。
另寻前端高手，优化移动端布局，以及迭代整体交互逻辑。
目前的更新计划：
   项目 预计耗时 预期上线时间 实际上线时间 备注 最后一次修改时间     原神放置类小游戏 7x10h 已上线 2020.11 项目整体概况 2020.12.10   完成全部副本的文字描述替换 4h 2020.12.13  1116 完成蒙德区副本文字描述 2020.11.16   增加新手引导 1h 已上线 2020.11 增加文字描述引导 2020.11.19   调整增益道具UI        增加道具洗练，将摩拉进行消耗        调整暴击逻辑，增加随机性          游戏 Tip：</description>
    </item>
    
    <item>
      <title>不可不知的项目推进与团队建设之道</title>
      <link>https://kuhungio.me/2020/pmp/</link>
      <pubDate>Mon, 26 Oct 2020 23:21:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/pmp/</guid>
      <description>项目管理好坏，决定了项目的成败。无论做什么工作，项目地企划、执行、效果评估、复盘，总是必不可少的。
我们可能遇到过如下场景：
 业务方提出需求，扑哧扑哧做个几周后，却发现并不是他们想要的。这样的后果就是：   项目结果被搁置
  几周的开发时间浪费
   业务和开发其乐融融，第一版也顺利交付，而后由于老板或者更高一级负责人的要求，要做的功能点越来越多，以至于现有功能延误。  需求的企划，项目的推进、以及团队的建设，对于结果的影响，是强相关的。做好以上三点，有两个好处。一来，可以减缓项目的失败风险，二来，也有助于团队更高效地产出。
 以下内容，框架节选自书籍《程序员修炼之道》，根据理解有部分删改。《程序员修炼之道》，是软件开发的经典之作。对于软件行业的原则性问题，进行了详细而又到位的探讨，出版二十余年。第二版添加了最新的潮流趋势，由云风翻译，质量上乘，值得推荐给大家。
一般做阅读，都是带着问题来的，为了解决对应问题。项目管理方面，也有经典之作 PMBOK，不过那本书蛮厚的，还没消化完全。以下内容，解答了我对于需求、项目以及团队建设的部分迷思。大部分摘录自《程序员修炼之道》，穿插工作中的心得体会。希望给读者朋友带来帮助。也希望自己，能常读常新，在工作中实践、反馈、进步。
项目启动前 需求——没有人知道自己想要什么 在每个项目启动前，往往是需求的对接。
业务部门想要的是什么？是大老板拍脑袋的需求，还是确切有利于业务问题的解决？
之前的职业经历中，遇到的很多需求，都是大老板拍脑袋，然后层层传递下来。到了执行层，基本无法判断其真实的目的。最后只能和末端的需求人员对接，成了单一的传声筒。
这种情况，十分危险。
根据乔老爷定律：没有人能确切描述自己的需求，直到你把产品摆在他面前。
这样的后果就是，为了缓解高层的焦虑，做了很多脱离实际的功能。而一线，最熟悉用户的人，许多业务中的改进点，却只能搁置。
灯塔——开发人员的职责 作为开发人员，尤其是作为数据开发、数据挖掘人员，我们的职责之一，便是帮助他人了解想要什么。因为，产品数据、模型效果等最直观的感受者，还是我们。只有我们才知道：什么能做、能做到的程度。这也是区分初级和高级工程师的因素之一。
在帮助他人澄清需求时，常见的错误，便是照单全收。这往往会为后续开发，埋下隐患。人们的日常沟通，尚存在许多误解，更别说涉及开发建模的活。
正确的做法，是复述一遍，将自己理解的程度反馈出去，并明确问题的边界。如果，刚好对业务领域了解不深，则更应该通过沉浸体验业务、复述需求等方式，寻求反馈。
什么需求是好需求 与此同时，在需求澄清过程中，应当区分需求与策略。需求，是指功能上的开发，以期望实现某种功能。策略，则是一连串的活动，保证达到某种效果。一般而言，策略抽象自需求。关注更高层面的抽象，为底层需求做好准备，DRY（Do Not Repeat Yourself）。
抽象的，且能简单直接反应业务需求的，才是好需求。
另外，做好需求的文档化。需求文档化，不是说要去交付它；而是说，将其作为开发过程的记录。这种方式，能较为清晰的记录，软件开发过程中的 Eureka 高光。这些点子，兴许是下个需求来源，或是创新的突破口。
为什么项目会失败 查理·芒格说过：如果知道，我会死在哪里，那我就永远不会去那里。
一般而言，项目失败有两个因素导致。一个是：功能的不断膨胀。也许一开始，只是添加了一个小功能，最后却成了臃肿的庞然大物。
另一方面，则是需求的变化。昨天需要的事物，在今天可能就没那么适用。
如何破解该难题：其核心便还是，持续的反馈。
项目进行时 项目难点的处理 项目中的直接阻碍，来源于项目本身需解决的问题。除了自然界的熵增，可自发的进行。逆熵行为，无一例外都会遇到困难。所以，问题并不可怕，特别是当你知道，如何处理时。
那么，如何处理项目中的难点呢？
第一，先检查约束条件。约束条件是指，项目的边界。诸如：时间、资源配给，期望的效果等。审视，项目一开始的条件，和当下条件的差异。时刻检查，条件是否发生了改变。
第二，反问自己。为什么需要解决这个问题，为什么你需要解决这个问题。问题的收益和付出，在不同层面，是都成正比的吗？如果是边界的问题，你能消除边界吗？最后，再问问自己，类似的问题，其解决方案是什么。
处理难题过程中，值得推荐的是：新建一个文档，记录思考和开发的过程。现实生活中，不同于考试做题，没有明确的对与错。记录开发过程，有助于养成主动思考的习惯。
用户共建，敏捷开发 在项目进行时，很重要的一点是：不能脱离用户，而是和用户共建。与直接的用户，形成良好的互动关系。不断提问，不断澄清。决策、实施、演示、反馈。
传统的工作模式，是瀑布流式的工作方式。一切都规划好，然后按部就班实施。瀑布流的好处是，能看到一个大的愿景。但其坏处，也很明显：不够灵活，容易需求延期、特性膨胀。
敏捷方式，则克服了瀑布流的缺点。整个是一个三步走流程。首先，评估当前的处境。然后，朝着预期的方向，做一次最小化的改进。最后，明确事情的边界，让事情先运转起来。敏捷也有其缺点：变更频繁；难以全局最优，常常陷入局部最优。
最后，在项目进行时，不要一个人埋头进去代码。参加代码评审等活动，了解和学习别人的代码优点，也能让自己的代码更鲁棒。同时，也别忘了，遇到问题，求助他人，也是一个解决问题的中上之道。
项目交付 项目的最终目标 项目交付，不是一锤子买卖。这项活动，是类服务业：其最终目的，是解决用户的需求，让用户愉悦。
要记住，用户需求的并不是代码，而是代码逻辑后的解决方案。
所以，过程可能并非那么重要。如何挖掘用户的期望，让用户满意，才更为重要。
以始为终，挖掘期望 如何挖掘期望，不如看看《高效能人士的七个习惯》之二——以始为终。让我们从项目结束的角度，思考和评判如何叫做成功。
一旦我们记住了从期望出发，项目交付就会容易很多。以期望出发，需要确保项目中的每个人都清楚该期望。在做决策时，也尽量选择靠近该期望的路径。根据现有期望，去分析用户的需求。如果有更好的方案，能满足用户期望，则大胆的提出需求变更。最后，随着项目的进行，不断地审视期望。
在项目交付时，签上你的名字。程序创造是一门艺术，留下签名，不仅是责任，同样也是自豪感的体现。
团队建设 以上活动，离不开团队。一个好的的团队，会让事情做起来事半功倍。如何打造优秀团队，使其成为项目的牢固支撑，也是项目推进的重要一环。
优秀团队的定义 首先看，优秀团队的画像。对内，成员及时沟通。DRY 不做重复的工作。对外交流，团队成员是个性独特、心情愉悦的。外界听到的声音，是一致的。这要求团队氛围活跃，同时也要求项目文档清晰、准确、一致。且在会晤前进行了充分的准备。</description>
    </item>
    
    <item>
      <title>数据开发在2020年应当是什么样子的</title>
      <link>https://kuhungio.me/2020/data-engineering-in-2020/</link>
      <pubDate>Thu, 17 Sep 2020 21:51:46 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/data-engineering-in-2020/</guid>
      <description>我的工作是数据挖掘，很大程度依仗数据开发。如果说数据挖掘是在烹饪美食，数据开发就是选食材、清洗食材的过程。没有好的数据开发，就没有好的数据洞察。 恰好，我自身也经历了两家不同规模的公司。由于起点的先后，前者的历史包袱严重。基于惯性，数据挖掘的任何数据，都得从原始log中提取。没有数据治理、数据分层的概念。这不仅增多了重复性的劳动，也增加了服务器集群的压力。数十款 top 游戏，每一款、每个人都这样搞，浪费时间、浪费算力。 目前这家，则大不相同。技术债不多，数据治理做得还不错。没有大谈特谈数据中台，数据开发的每一行代码，都是为下游，而不是晋升服务。数据挖掘也很少碰原始 log，这节约了大量时间，让下游有更多时间集中在业务上。
 同样是数据开发，却产生不一样的结果。这让我对该工作的定位，产生了兴趣。也这篇文章的由来。
言归正传。本文翻译自：https://towardsdatascience.com/data-engineering-in-2020-e46910786eda 结合实际工作，有较大幅度删改。
 随着数据体量的进一步增大，数据处理工具和技术的发展也日新月异。数据开发的工作性质也发生了巨大变化。如今所使用的工具，同十年前已大不相同。
虽然技术在发展变化，但还是存在延续性。除开大数据开发相关技能，一些更基础的技能，也值得学习。例如：版本控制（git，svn），测试驱动（TDD），继续集成和部署（CI，CD）。而这，常常容易被初学者忽略。数据开发与软件开发常常呈现割裂状态。事实上，软件开发的工作流，对数据开发是一种补足。
早期的 ETL 工程师 大数据热潮之前，数据团队常常由 BI 和 ETL 开发组成。
典型的 ETL 开发，就是将数据集从位置 A 移动到位置 B，并使用该数据构建部署到 Web 的仪表板（BI）。除此之外，BI 和 ETL 的开发与软件工程无关，该学科在本世纪初已日趋成熟。（事实上，很多公司这一步都没做好。就开始吹捧数据中台概念，为晋升找噱头。）
随着数据量的增长，以及数据分析需求的增加，在过去十年中，出现了新趋势。更现代的 BI 工具（如付费的 Tableau，免费的 D3.js 等），允许以最小成本创建仪表盘。数据开发已成为一门新学科，它使用一套新工具将软件工程原理应用于 ETL 开发。
如今的数据开发工程师 一般来说，为了使流程更加顺滑，会创建数据管道（data pipeline）。在大规模数据上，这意味着将十多种不同的技术（甚至更多）融合在一起。数据工程师必须深入了解各种技术，选择合适的工具来完成工作。并用 Scala，Java 或 Python 编写代码，才能创建弹性和可扩展的解决方案。数据工程师必须了解他们的数据，才能创建合适的分布式处理作业。数据工程师必须了解基础架构，才能确定作业失败的原因。
从概念上讲，这和典型的 ETL 作业没有区别。都是从许多数据源收集数据，将它们放入集中的数据仓库中以备分析。接着，将其转换为BI报表或机器学习模型。但是，他们之间的唯一区别，就在于数据体量的不同。后者在大规模数据下，面临更多挑战。
数据开发产业现状 在很多文章中，建议数据工程师应具备如下工具使用经验：如Hadoop，Spark，Kafka，Hive，HBase，Cassandra，MongoDB，Oozie，Flink，Zookeeper 等。
了解它们的使用，是最基础的。知其然，更要知其所以然。不仅需要掌握他们的使用，更应该明了：它们旨在解决哪些特定问题，应该或不应该在哪里使用。如果不能使用，还有什么替代方案。
近年来，快速发展的云技术，已经产生了各种各样的云原生应用程序和服务。就像几年前现代 BI 工具的应用，更多的业务可以便捷的进行数据分析。现代的云原生数据技术栈，简化了数据的提取和转换任务。
像 Apache Spark 这样的技术在未来几年仍将流行，因为它们非常适合复杂的数据转换。
尽管如此，Snowflake 和 Google BigQuery 等云数据工具的使用率很高，因为他们简化了数据提取的过程。
而Spark，则需要一定门槛的专业化的技能。
 目前来看，国内的类似产品 MaxCompute，市场接受度似乎还不高？snowflake 前两天上市了，投资人挺喜欢它的故事，巴菲特也跟投了。</description>
    </item>
    
    <item>
      <title>2020高考志愿填报中的数据误导与价值机会</title>
      <link>https://kuhungio.me/2020/statistics-tell-lies/</link>
      <pubDate>Sat, 25 Jul 2020 20:43:52 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/statistics-tell-lies/</guid>
      <description>高考发榜，已经有几日。这篇文章姗姗来迟。还是希望，给各位考生朋友，补充有价值的信息。2020，迟到的高考，落下帷幕。紧接着，就是志愿填报环节。
想起自己当年，突然要选择自己的专业，那是慌得不行。草草的根据自己分数，划了几条线，填了武大、华科、同济、天大。然后又在最后一刻，决定学门手艺。将华科调到了最前面，并且选择了目前的专业，一个名字听起来很酷的专业。于是，就这样来到了华科机械大类下的测控专业。
但是，在度过四年时光后，却没有选择机械，而是选择了互联网。一方面，是原专业的就业环境，与志愿填报时的预期不符；相信每一位机械同学，都是想着做酷炫的机器人、或者是参与“大国重器”的建设中来；但实际上，即使是华科，机械全国前三，可选择的余地也不多。另一方面，是薪资成长性，传统机械，十年磨一剑，适合耐得住寂寞，有家底的同学。而就在刚刚，在专业大群里，惊闻自己这个专业，今年不再招生。
以上，足以见得：志愿填报，和投胎一样，也是个技术活。个人努力，行业趋势，两者不可相悖。选择，某种程度上，比努力重要。有效决策，能放大努力的价值；浮于表面的选择，则会冲淡寒窗苦读的日夜。
 志愿填报，就是个决策问题。决策过程，一般是多方面因素的聚合，最终反应决策体的综合认知。一般来说，会是感性的认知+理性的数据。但是，并不是所有人，都能做出好的决策。即使是年长的父辈，虽然在其他方面，做出了很棒的决策。但受限于其人生经历，在志愿填报上，也可能会做出次优的决策。
好在，人类的长处，就是从别人那里吸取教训。他山之石，可以攻玉。
让我们抽丝剥茧，从不同角度，挖掘志愿填报中的“天坑”与机遇。
 第一个“坑”，获得性偏差。
获得性偏差，是一类感性偏差。通俗来讲，就是：在没看到黑天鹅之前，以为所有天鹅都是白色的。
想自己填报志愿那年，家父说：隔壁村老李的儿子，填了重大（重庆大学）的土木，12年毕业，没两年就重庆买房了。所以，你也去填土木吧。
咱先不说，乡里乡亲的习惯性夸大。看看现在的房价，似乎有道理。但别忘了，中间15年也有一波下挫。回望08年次贷危机，为提振经济，国家拨了大量资金，流向基础建设。那几年，土木着实赚钱。但产能逐渐加码，没有宏观调控，势必过剩。没过几年，商品房库存开始堆积。家父肯定没那么神机妙算，能猜到后面的货币化安置。那么，我看到了当时的产能风险了？也不是，单纯想往机械钻&amp;hellip;
而我想往机械钻的念头，也不是无中生有。来自于众多宣传片的鼓舞。这其中，少不了一只飞虫拍三集的《走近科学》；以及鼓舞人心的《大国工匠》。这些片子的出发点是好的，激发国民的好奇心，弘扬钻研精神。也要感谢他们，社会才不至于太浮躁。但是，同样的，行业的枯燥、重资产轻人工，却没能显露出来。这些问题不暴露，不是说无关轻重，而是默认，每个人都知道。但是对于一个学生，如果没有高人指点，他知道的，只能是他看到的。
上面两个例子，说的就是获得性偏差。这样的例子，不仅出现在志愿填报。想想看，我们的日常决策、企业决策，是不是也有很多？
第二个“坑”，数据误导。
首先是，用有限的小样本，代替整体样本。最有代表性的，就是各类软件培训机构。如今，大家都知道，搞互联网IT，表面上比其他行业挣钱。这催生了大量培训机构。在招生简章中，可以看到：某某学员，以xx万入职xx公司。这一听，好像几个月工资就能回本。但他玩的就是有限样本的把戏。尚且不说，这某某学员是否真实存在；即使他存在，也不能代表真实的期望。数学中的期望，不是拿最好的来说事。一般人，正态分布到两端的概率，十分之小。
其次是，用各种不一的口径，暗示自己很强。没错，这里说的就是各类大学排行榜。今天你出个排行榜，说自己很强；明天xx机构，又出个排行榜，排名一下发生巨大变化。大学排名，可以参考，但也不能全信。评级机构的公信力，很多都无法考证。最近还流行，将各个排名取平均，显得很客观，但实际，其中的加权怎么定，重合的指标有无剔除，混合排名的人，可能自己都不知道。相较而言，各榜水平稳定的高校，买榜的概率更小。比如：清华和北大，稳居前二。如果你不能识别，那就最好不要花太多时间在上面。
第三个“坑”，暗示因果。
暗示因果的最强例子，就是分数了。一般来说，大伙儿都会参考去前年的录取分数、最低录取位次，以此来判断这所学校的价值。这里有一个假设：即分数高的学校，是好学校。分数高的专业，是好专业。其中深层次的假设是，分数高的人，所作的决策是明智的、充分掌握信息的。还有一个，是分数充分反应市场热度。但其实，这几个假设，有相关性、但没有强因果性。因为，分数高的人，他的信息也不全面。他在这场博弈中，掌握的只是先手机会。而与此同时，操作最低录取分数，已经成为了潜规则。冷门专业放提前批，或者换个紧跟潮流的名字，都能大幅提高最低录取分数。
还有暗示因果的，就是名字。这样的情况，多出现于xx大学xx学院，或者是xx大学合作办学。虽然这样的情况，在最近几年有所收敛，但打着其他学校幌子招生，还大有人在。对于这样的学校，其实名字中就已经存在溢价。除非你对该院校很熟悉，做过充分调研，可以选择报考。尽量避免望文生义，根据一些名字上的关联，联想出一些不存在的关联。
 最后，说了这么多，上面是一些坑点。而与此同时，也存在价值机会。其实，不同大学，在不同地区，其录取排名并非一致。这说明，不同地区人，对该大学认知程度不一。在综合考虑地域远近，以及投放招生指标的前提下，寻找在当地被低估的外地学校，是一种值得尝试的方法。因为，据观察，留在大学所在地工作的，占比很小。除了北上广，其余地区的大学，都是给一线输送人才。选大学，不等于选择了后半生的定居地。
另一个方面，建议在自由度上多花功夫。这里的自由，并不是指自由逃课、管理松散。自由度，在机械机构中，往往指机构可能的运行的空间。在机械设计中，越多的自由度，代表能做越多的事情。在选择专业上，我的看法类似：应当保证充分的自由度。原因如下：
 学生对于专业的认知，多源于综合信息，本身的匹配程度不可知。 充分的专业自由，学习自由，有助于帮助学生认识自我。  自由度在专业上的体现，就在于：提供机会转专业、能够跨专业大类选择。可能有些高分考生不认同这点，认为：考这么高，还去选择通识大类，不是浪费机会吗？确实如此。但如果选的专业，不是理想的那样，再高的分数，也只是过去式。
其实，自由度还在其他方面有体现。北上广的火热，究其原因，还是提供了视野的自由度。更前沿的市场环境、更多的就业机会。这些都是在提供自由度。与此同时，综合类院校、大力发展文科的理工科院校，也是在保证思想的自由度。巴菲特的得力投资伙伴，查理曾说过，跨学科的思维，帮助他赢得了投资的成功。
 最后，无论填报结果如何，这都不是一锤子的买卖。进入好的大学、好的专业，不代表后半生就安稳了。进入不理想的专业，也不代表，后半生就玩完。没有永远的避风港，坚持刻意练习，积累职场竞争力，才是最优方案。</description>
    </item>
    
    <item>
      <title>云游戏，会是反作弊的银弹吗？</title>
      <link>https://kuhungio.me/2020/game_anti-cheat/</link>
      <pubDate>Thu, 18 Jun 2020 23:18:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/game_anti-cheat/</guid>
      <description>游戏反作弊，一直是各大游戏厂商头疼的问题。究其根本，游戏，本身是一种软件产品。交付到用户侧时，你永远无法穷举，玩家会怎么使用它。只要有利可图，就会有人去钻空子。
为了反作弊，各大厂商，也是用尽各种手段。除了内部的反作弊团队，还有法务团队的律师函警告，甚至直接招安外挂开发者。说到底，游戏反作弊，有没有一个终极方案呢？
 数据挖掘，说是近5年的火热技术，没得跑的，甚至连电视剧里，都开始出现这个职业的主配角。
这个职业，被寄希望于做炫酷的事：**在庞杂的用户数据中，找到其特有的规律，找到导致现状的原因、预测未来的发展。**数据挖掘，在游戏反作弊，可以做些什么吗？
数据挖掘 整体行业概况 数据挖掘行业，如今有如下两个趋势：一个是计算广告，及其相关的推荐系统。这套东西，是信息流产品的核心。扩展开来，包括用户画像、用户生命周期等内容。
另一个，集中在敏感内容、反欺诈的识别上。这个方向，只要用户生产内容，就不可避免。换而言之，是 UGC 内容平台、活动平台的刚需。同时他又是一个劳动密集型工作，很适合用机器节省人力。
游戏中的数据挖掘 在游戏领域，数据挖掘又分为两个大方向。各个公司的AI lab，会去研究一些前沿技术。诸如强化学习、或者是迁移学习的事。满足玩家个性化的需求。其特点是：前瞻性强，复用性高，但落地困难。
而在业务侧，围绕玩家生命周期展开：渠道转化预估，异常渠道的识别、高潜玩家发现、流失的预测等。其特点：复杂多样、垂直性强，常需要单独建模。
游戏内，对于一个用户的刻画，十分具体。从基本的在线、消费；到玩法偏好、好友关系，都会有专门的标签画像。这些画像，帮助企业更好理解玩家，提供更细致的服务，达到 win-win 的目的。
对于多产品的公司（如：网易），数据互通，是其最迫切的需求。各产品数据独立，制约了它的社交属性，虽然在“洗用户”上表现克制，但数据资源白白浪费。如果是一家正在扩张业务线的公司，需提早防范：数据壁垒的出现。
 如果把游戏反作弊抽象，实际也是风险控制的一个环节。风险控制有哪些注意事项？它的核心是什么，又该如何去应对挑战呢？理解风控的这些知识，有助于我们做好反作弊。
近现代风控，起源于二战后。而后迅速发展，形成以：金融业风控为代表的垂直学科。而随着80年代互联网的发展壮大，各类风险，也随之而至。
如今，互联网上的羊毛党，垃圾信息、黑产随处可见。和正常内容，争夺着用户的注意力。同时也影响着业务安全。在业务侧，安全业务可分为两类：一类是静态的账号、内容安全；另一类则是动态的行为安全，诸如活动安全等。
风控领域浅析 风控的核心 谈起金融的核心，大家的第一个念头，一定是风控。而风控的核心，则是成本控制。而成本，则不是简单的金钱成本。除了财力、物力、人力，这样的企业端成本，还应该注意，用户侧的成本。比如：用户体验的成本。
如今，互联网上，打开app前10s流失的用户，其数量之大，很可能超乎你的想象。如果为了风险控制，而过分牺牲用户体验，其实是得不偿失的。如12306的验证码，它的本意是防范刷票风险，若图库的区分度小到极端，则是过分牺牲了用户体验。
除了资源成本和用户体验成本，还有一个容易忽视的，是企业的信用成本。虽然互联网的记忆，只有短短7天；玩弄话术，运用公关手段，能够消除一时的风险。但对企业长期的公信力，其实是一种消磨。
产品出问题了，还可以修补。信用丢了，那就找不回了。
风控的挑战与应对 风控，显著性地，不同于其他业务。其他业务，存在的业务逻辑失效，是来自场景、数据、时间的漂移。即，随着时间、事态的发展，运用场景、数据表现产生了分布上的改变。而风控，则来自于强烈的对抗。道高一尺，魔高一丈。
传统意义上，为了应对风险，衍生出4种模式：
 回避风险 控制风险 转移风险 承受风险  一般来说，企业主要精力，花在控制风险上。不是所有风险，都可以回避。在控制风险的同时，也可转移部分风险，最后准备承受风险。这部分，在之前的文章《浅谈互联网风控——从策略到技术》有详细介绍。
策略上，分为前中后。前：打标签，标记风险用户、风险内容。中：拦截风险，对高危操作进行干预。后：回顾每个环节，堵住漏洞。同时辅以核心指标的监控，在所有措施失效时，留一手兜底措施。
技术上，给用户准备丰富的画像，从自然人、设备、账号等角度，刻画用户。用以支持风险的识别，策略的实施。
最后，别忘了它的对抗特性。这要求我们，持续不断的演进技术、策略和手段。
 游戏作弊，其实就是游戏内的风险。它不仅会影响游戏产品的体验，使产品走向，偏离策划的初衷。更会影响玩家间的平衡，进而影响产品的营收。更进一步的，让游戏失去吸引力，导致产品失败。
游戏反作弊 作弊的形式及手法 谈到作弊的形式，不妨从一个玩家的角度出发。为了获得碾压感，满足感，玩家会从以下方面入手：
  为了获得满足感，玩家会修改道具获取逻辑，不付费、或者修改货币值，获得道具和服饰。
  为了获得数值上的优势，调高伤害、减轻承伤。诸如“无敌”或者“锁血”，可属于这一类。
  而对于时间换物资的“肝”玩法，则通过修改产出逻辑、或改变游戏内的时间节奏获取。
  而在信息不对称玩法中，则通过读取数据，以此获得优势。例如：吃鸡游戏中的透视。
  上述的种种作弊，其核心在于数值，其次在于程序逻辑。因此，在客户端，玩家可通过注入代码、读取内存实现。在客户端与服务端通信过程中，还可伪造中间人，截取、修改数据。更甚至，反编译游戏包体，生成一个看似一样的安装包。修改内在逻辑，重新打包。
游戏反作弊的业务逻辑 反作弊业务逻辑中，最重要的一环，是误判的处理。在作弊识别上，我们可以达到99.99%的准确率。但那万分之一，也是一个鲜活的玩家。如果误判了玩家，怎么办？除了提高准确率外，还应健全机制，预留申诉、回旋的空间。不至于，因为莫须有的判罚，让忠实玩家流失。
在技术层面，游戏开发时，会有两个地方进行校验——客户端与服务端。客户端，通过基本的签名校验，保证不被篡改。服务端，则对发回的数据，再次校验，综合其它数据，进行判断。数据挖掘起的作用，则是发现、总结作弊模式。在进行业务处罚的同时，反馈到开发过程中。
效果检查方面，游戏反作弊，又有其特殊性——不可证伪。不同于广告的点击，有明确的反馈。如果一个玩家，模型说他作弊，但他声称自己没作弊。那到底，是谁有问题？
在其它业务，会用客户投诉率，作为服务质量的考核。但客诉率在这里，不是一个好指标。因为，对作弊的处罚，势必引起玩家的不瞒，投诉中真假参合。
真正应当关心的，是核心指标的变化。比如，作弊让游戏内某项资源，产出大幅加倍，我们的效果指标，则应该是该资源的产出率。
而对于实锤作弊玩家，作弊的处罚，也不仅仅局限于封禁。在强社交游戏中，封禁他的社交行为，也是一种惩罚——即能警示其它玩家，又不至于影响正常游戏行为。除此之外，对于对抗类游戏，play with cheater，也是可行的思路。</description>
    </item>
    
    <item>
      <title>我为何离开网易游戏</title>
      <link>https://kuhungio.me/2020/why-i-left-netease-games/</link>
      <pubDate>Wed, 13 May 2020 00:41:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/why-i-left-netease-games/</guid>
      <description>前言 网易游戏是我毕业后的第一家公司，说没有感情，那是不可能的。当然，这感情主要针对那里的同事和朋友。
网易又叫猪场，猪场曾一度有最好吃的免费食堂，一度给名校毕业生开最高的工资。
在数年前，大话西游2帮助公司起死回生。
而后开发的梦幻西游，成了公司最强的现金流来源。
2016年阴阳师爆款，几乎成了全民游戏。
2018年，加入网易游戏，带着自豪感。因为它说：用心做游戏。
2020年，离开网易游戏，矛盾夹杂着解脱。
 当知道我离开网易游戏时，许久没联系的朋友，都感到十分吃惊：这可是头部互联网公司，好多学校的人根本没资格进入；但熟悉我的朋友都知道，这件事已经“蓄谋已久”。
这其实源于一些观念的冲突。
我本人关于工作的信念是：个人以一定价钱出售其劳动产出。个体与组织的关系，是合作而不是卖身。
正如《软技能》一书所言，改变打工心态，把自己当公司经营，现在的公司是个大客户，仅此而已。
下面，从商业模式，特别是个人角度，来谈谈离开网易游戏的原因。
商业模式个人篇 核心资源 商业模式中，很重要的一点便是：核心资源。即我是谁，我拥有什么。这个问题颇有——我是谁，我从哪里来，我要到哪里去的意味。
一般年轻人认为，我拥有用不完的精力，因而相较于更年长的员工，我的核心竞争力在于可以加班。
这样的想法大错特错。年轻是试错的机会，而不是让人无故内卷。没错，这样的“一般年轻人”便是两年前的我。
什么是核心资源呢？稀缺的是核心资源。人无我有、人有我精的，才是核心资源。
从这个角度想下去，所具备的技术技能、行业积累，以及对新事物的热情，才是真正的核心资源。
关键业务 关键业务，简单来说，就是每天所从事的事情。
但这里，根据28定律，20%的工作，产生80%的绩效；所以这里的关键业务并非指剩下80%的工作。
什么是80%的工作呢？在数据挖掘这个领域，80%的时间是在产出数据，保证数据的及时响应。
每天的取数工作，这个岗位的从业者有了新的绰号——取数男孩（茶树菇）。
剩下20%的工作，在提供数据的洞察。关于数据的过去与未来，溯因与预测，提供基于数据模型的决策方向，才是岗位的关键业务。
而80%的非关键业务，应当想方法标准化、自动化，以提高效率。而不是每天用 excel 做各种变换，洋洋洒洒写一份无人执行的分析报告。
客户群体 客户群体，是商业模式中的概念。正如一开始所言：公司，其实就是我们的大客户。
公司内的直接上级、boss、或者其它部门的人，都可以是我们的客户群体。
在这些客户群中，有人认为，向上管理是第一位的。即：做好上级和上上级的需求，服务好他们，才是升职加薪的正确之道。
这点上，我只同意一半。哪一半，后一半。即服务好我们的客户，才能赢得信任，才能得到更高的回报。
向上管理没问题，但向上管理很多时候成了唯上。我们的客户，是上级、是团队、更是整个公司。服务好每个部分，同等重要。
价值服务 这个概念是商业模式中，最重要的，因为它决定了你的定价区间。
简单来讲，我给客户提供的服务，帮助客户完成事情，其背后的价值，才是真正的价值服务。
价值服务和关键业务容易混淆。关键业务是干的活，而价值服务则是干的活所产生的价值意义。
同样的，有人认为，公司招聘我，就是买断了我的时间。而不去进行更深层次的思考。
实际上，买断一天8小时的时间，只是表象。客户期望的是能产出有价值的东西。如果这样想，就会明白，时间不是关键，给公司带来的价值才是。
渠道通路 渠道通路，简单来讲就是，如何宣传自己、以及如何交付服务。让别人知道自己能做的事情，且能够交付服务。
这里关键的问题在于，潜在客户如何知道你能帮助他们、是如何下定决心的、是如何购买的；以及如何交付及售后。
酒香不怕巷子深，这是很多技术型同事的想法。会觉得有了自己的东西，才能更好让客户接纳自己。
这个观点没错，是一种踏实务实的想法。但仔细想想，宣传服务和打造服务之间互斥吗，并不互斥。
只有找准自己的价值服务，并进行宣传，才会有买家认账。不管这个买家是领导或是别的团队。只有卖出去了，才会有实际的回报。
客户关系 客户关系讲的是如何和客户打交道。
是直接沟通，还是远程服务。
是一锤子买卖，还是长期性的维护。
是拓展新客户，还是维系老客户。
一般来说，公司招聘员工，希望的是能做持续性的项目。
但某些考核标准下，如按项目分成模式，持续性项目就少有生存空间。
自上而下，希望立足够多的项目，借此来分得一杯羹，因而出现了炒冷饭的情况。
最后面向晋升编程，晋升过后无人维护、一地鸡毛。n年过后，该项目又被下一个人立项。
项目失败不可怕，因为可以从失败中总结教训。可怕的是不断的立项，在公司内做一锤子买卖，造成无端的资源浪费。
重要合作 合作一般基于交换，这里的合作，指的是谁可以帮我。
他们可以是家人、同事、是导师、也可以是同一职业的其他人。他们提供帮助、建议和成长机会；提供必要的资源。
作为互联网新生代，信息不像之前闭塞。虽然信息茧房确实存在，但互联网确实是重要的合作对象。
而在公司中，提供资源和方向的一般是直接上级。
收入来源 简单来讲，大伙儿的收入来源是工资；其次，少部分收入可能来自于股票、基金或者房屋出租。
打工的主要收入来源便是工资。这里存在两个问题：
一是，工资奖金上涨带来的愉悦，存在边际递减效应。即同样的涨幅，越到后面越没感觉。更别说大部分人薪水几乎无变化。
其次，单一的收入来源伴随着风险。不管和领导关系多么密切，公司现金流多么充沛。小概率事件必然发生。
破解这两个问题的方法在于：
工资到了一定水平后，需要关注精神的满足。工作的成就感和社会贡献，就显得尤为重要。</description>
    </item>
    
    <item>
      <title>数据分析思维导图</title>
      <link>https://kuhungio.me/2020/data_analytics_mindmap/</link>
      <pubDate>Wed, 06 May 2020 22:18:50 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/data_analytics_mindmap/</guid>
      <description>思维导图获取  .xmind .pdf .png    关于作者</description>
    </item>
    
    <item>
      <title>结构化知识整理——以15张思维导图为例</title>
      <link>https://kuhungio.me/2020/mindmap_2020/</link>
      <pubDate>Sat, 25 Apr 2020 17:22:57 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/mindmap_2020/</guid>
      <description>思维导图，是结构化思维的具体表现形式。最鲜明的例子，就是当你和一个人聊天时，可以很明确的感觉到，拥有结构化思维的人，他的语言组织能力很强，且很有层次感。简单来说，就是和他沟通，简单高效、有收获，有层次感。
在过去几年里，也整理了一些场景的思维导图。大约是从15年，上大学的第二年，第一次接触到这个东西。不过略微遗憾的是，早期是一些手绘的内容，没能保存在身边。以下是电子化的内容，分享给到大家。
这里，不仅有思维导图 png 格式，同时也有其 xmind 源文件。授人以鱼不如授人以渔嘛，可以参照之前的文件进行修改（xmind 公司，看到后请给我打钱）。
 免费获取思维导图  沟通与整理 沟通的艺术 要说人类在哪一点优于其它物种，当属语言沟通。但沟通也不是与生俱来的本能，不然就不会有这么多的冲突了。沟通是一门艺术。
沟通的艺术，是一本15年在图书馆看的书。这里就不得不夸奖一下华科的图书馆，人文社科和财经类的很齐全，F开头的书基本都能找到。
沟通的艺术从理论层面，给出了沟通的原理，同时也指出了很多解决办法。类似的《非暴力沟通》也是一本不错的书。
超整理术 超整理术也是一本在图书馆看的书，书的设计感很强，贴合了他的标题。
整理对象分为了三个部分：包括物理空间的整理，交流思绪的整理以及信息的整理。
整理的过程，也是思维重建的过程，这和思维导图的建立相得益彰。
思维与学习 批判性思维指南 了解这个领域的动机是，大学参加的数场讲座。在讲座过程中，都会有提问环节。
但是这个环节，明显可以感觉出不同的人有不同的思维敏锐度。有的人提问水平非常高，有的就是复读机，问的问题不痛不痒。
学会提问，个人认为是现代人比较稀缺的技能，特别是高等教育的大学校园。
金字塔原理 麦肯锡都在用的金字塔原理。简单来说，就是独立穷举（MECE）的分组、层次化的表达。
其实实不相瞒，咱们高中的议论文写作也是这个套路。
在工作中，这也是一项极大的加成。利用金字塔原理，让你的观点更容易推销出去。
学习之道 学习之道（the way to learn）是 Coursera 上的著名课程，广受喜爱。如果能更早看到，也许北大清华就不是梦了。
学习的方式因人而异，但其背后的原理却差不多。对知识点重构组块，反复练习，是学习绕不过的弯子。
经过思维导图整理后，学习之道被应用到了学习之道的理解上面（无限套娃）。
写作与演说 演说之禅 演说之禅，略微带些哲学意味。别看展开了这么多，实际是为了方便理解。
演讲是每个人在人生阶段都必经的道路，无论是做面试推销、还是追求异性，都是某种形式的演说。
千言万语归为一句，演讲要关心的是：想推销的核心观念是什么，如果只能用一句描述，该会是什么？
文案写作 写文章，最头疼的还不是素材，不是写什么的问题，而是怎么写。
素材随处可见，再不济跟热点也行。但不是每个人都能写出好的文案。
写文案也是有套路可言的。例如：以情感卖出产品，以理性阐述购买。
时评写作十讲 时评写作是被新闻学院的一个朋友带入门的，曾经的我也是个网络喷子兼键盘侠——“意见不合就是干”。
和他交锋几次后，发现自己简直就是菜鸡。于是他顺势给我推荐了这本书。
在大环境作用下，加上推荐引擎的加持，你所见的，未必是真实全面的。所以，下次就时事开喷前，不妨看看《时评写作十讲》。
技术体系 机器学习 如果问最近5年什么概念最火，机器学习肯定得有一个席位。本人也在15-16年左右，借猫狗分类比赛进入该领域。
随着这一行的火爆，进入的人越来越多，竞争加剧的同时，越来越多的项目也得到落地。
落地越多，成体系的方法经验也得到了总结。机器学习系统设计，梳理了机器学习项目的整个生命周期。
计算广告 谷歌是一个科技公司，但反垄断调查时，它会说自己是家广告公司，以此来逃避反垄断调查。
它能得逞的原因在于，广告占据了谷歌的大部分收入。而广告商又确实不止谷歌一家独大。
计算广告和推荐系统一样，可以说是机器学习的主要应用，对其有一个整体的了解还是很有必要。
测试驱动 TTD 测试驱动，之前被用在软件开发领域。
随着机器学习的工程化推进，测试驱动机器学习也值得关注。
简单来说，测试驱动就类似于：“先出考纲再教学”，让软件开发更有效率。
互联网风控 人类从诞生之初，就一直面临着各式各样的风险。而上世纪80年代兴起的互联网，当下也面临各式各样的风险。
羊毛党、黑产肆虐，一不小心可能老本都被薅没。同时在PUGC平台，用户上传的内容也有各种风险。
但好在，其它领域的风控经验，对于互联网同样有借鉴意义。通过多种策略手段，能在一定程度上控制风险。
其它 敏捷 敏捷（Scrum），简单的来说就是赶紧上，先跑通流程，再去迭代。</description>
    </item>
    
    <item>
      <title>自制以图搜图引擎，居家学习必备</title>
      <link>https://kuhungio.me/2020/simple-image-search/</link>
      <pubDate>Mon, 13 Apr 2020 21:17:08 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/simple-image-search/</guid>
      <description>最近宅在家，消遣时间之际，总会遇到一个让我困扰的事情。比如随手刷到的一个GIF，总想找到它的原片。
各位绅士可别想歪，我说的是动漫。
这个问题本质是一个相似度的检索问题。
说到视频找视频，其实可以分解为以图搜图。以图搜图这项技术，已经十分成熟，且已产品化。尤其在主流搜索引擎，很难找到一个不能搜图的引擎。连淘宝都有自己的时尚搜图功能。
但是当你满怀期待上传一张图时，你会发现，他返回的结果要么是同风格作品，要么是图片的描述。摔，我不是让你做抽象阅读理解哇。
这样的现象，实际是个性化需求与规模化需求的矛盾。对于公司，能规模化的，成本越低；定制带来存储成本，远高于能带来的回报。
这样的问题难不倒我们广大的人民群众，如果没有现成的，那我们就造一个。
 以图搜图，可以理解为图像的检索，图像和其它信息一样，是可以被索引，被检索的。
于是乎，可以将整个工程抽象为3个部分。
 图像预处理 图像特征表征 图像检索  图像预处理，一般是尺寸、色调的调整、以及去除明显的噪声。
索引建立有很多种方法，其核心是构造图像的特征表征。
这里先用简单的，构建一个 MVP（最小可行性产品），就采用谷歌的 MobileNet 啦。
该模型尺寸仅数十M，放在服务器或是部署到手机移动端，完全绰绰有余。（实不相瞒，其实一开始上的VGG16，但是模型太大了，服务器放不下。）
最后，图像检索，当一张新图来到时，对其进行特征提取，然后去索引库中查询，返回特征表征最近的 TopN，一个简单的以图搜图就完成了。
 迫不及待想尝试了，但是发现一个大问题，咱们的索引图从哪儿来？总不能凭空捏造噻。
嗯，这也不是什么大问题，之前浏览某P开头，哦不对是G开头的学习网站，发现了知乎问题的爬虫。
这可是个好东西，恰好知乎时间线上，总有一个问题干扰学习——#什么样的腿才叫好看的腿#
就拿这个问题为例，将图片在离线创建索引，随后通过服务端部署。（服务端部署也可以讲一集，但不在这里，别挡住我看腿。）
当当当，随着周末两天的操作，舍弃了俺在的 pubg mobile 战友，谷粒粒的第一个搜图app上线咯。喜大普奔。
让我们赶紧试试，
嗯，还不错
再来一张，
原图秒匹配好吗，还给配上了类似风格的照片。
到这里，咱们的以图搜图小应用，就算开发上线完毕啦。
学习效率上升N个档次有没有⬆
链接地址：以图搜图之#什么样的腿才叫好看的腿# http://img-search.kuhungio.cn/
相关文章：
谷粒：机器学习模型部署&amp;ndash;打通前后端任督二脉
谷粒：机器学习落地需攻破的9个难题
声明：该应用仅供学习，禁止用于其它用途。</description>
    </item>
    
    <item>
      <title>计算广告思维导图</title>
      <link>https://kuhungio.me/2020/computational-advertising/</link>
      <pubDate>Sun, 05 Apr 2020 17:42:17 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/computational-advertising/</guid>
      <description> 思维导图获取  .xmind .pdf .png   关于作者  </description>
    </item>
    
    <item>
      <title>互联网风控思维导图</title>
      <link>https://kuhungio.me/2020/risk_management_mind_map/</link>
      <pubDate>Wed, 25 Mar 2020 00:12:28 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/risk_management_mind_map/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>浅谈互联网风控--从策略到技术</title>
      <link>https://kuhungio.me/2020/risk_management/</link>
      <pubDate>Sun, 22 Mar 2020 14:34:33 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/risk_management/</guid>
      <description>风控，全称风险控制，英文名 risk management。风控的研究起于二战结束后，主要集中在个人或企业的商业保险领域，用于减少突发事物带来的损失。金融行业的核心，乃是风险控制。
但今天，我们这里不谈金融的风控。金融风控已经演化了多年，众多顶尖学者已对其进行了研究，各种模型层出不穷，自有人去分析。我们这里说一说，互联网的风控。
风控的核心 如果你在网上检索，一定会发现很多人，谈到风控，必加智能，似乎不智能就不风控了一般。有人说，风控的核心是智能；也有人说，风控的核心是数据。这些老生常谈，将数据智能看成了银弹，看成了哆啦A梦的百宝袋，能解决一切问题，但其实这种说法忽略了现实。
那现实是什么呢？如果你问，风控的核心是什么。很多人可能回答不上。但你问，为什么你要买保险，很多人的回答会是，不怕一万、就怕万一，保险能够兜底未来可能的大额支出。用小额保费对冲小概率但大支出的以外，换而言之，就是一场成本核算。
成本控制的两个方面 风控对于成本的控制，在互联网主要体现在两个方面。一个是资金成本。搞活动，不能被薅羊毛的搞破产了。或者搞个特牛的模型，能识别所有的风险，有且只有一个缺点，要用上全球一半的计算机（费钱）。另一方面，是体验成本。互联网风控，免不了嵌入业务，但如果过于突兀，很可能影响用户体验。这方面的典型，极端就是恶搞的12306验证码识别。
风控与信息安全的异同 风控这个业务，和信息安全中的加密很像。当破译的难度大于潜在的收益时，加密方式其实就安全了。没有不计成本的密码破译，也没有不计成本的风险控制。风控要做的，也是某种程度的平衡。
但同时，风控和信息安全也有不同之处。
在互联网业务中，风控的对象一般会有两种形式存在。一类是静态的账号，比如恶意的初始号，或者是盗用、冒用的他人账号。另一类，是其动态的活动。具体表现为账号主题生产的内容，或是其参与的活动。而信息安全，主要是软硬件的漏洞，再加上社会工程中人性的漏洞。
风控的挑战与应对 最明显的挑战在于，敌在明我在暗，同时由于对抗手段的加码，对方会找到规避的手段，或是找到风控的系统漏洞。
风控策略与技术 在传统风控中，应对风险有4种基本思路。
 回避风险。即如果我知道你有风险，我就回避掉你。这会带来一定的损失，俗话说，风险伴随着收益，回避风险，在互联网业务中，有些能回避，有些则不能。对于政策风险，法律风险，该回避的则回避。对于不能回避的风险，我们采取下面的措施。 控制风险。这是互联网风控的主要内容。如果控制风险，从风险的酝酿、到风险的暴露，再到风险的控制，每一个环节都有可为。 转移风险。这个措施更靠近业务。通过将风险转嫁，或是共摊，来实现风险的控制。举个例子：平台将风险分散到平台与商家之间，或是将风险在声明中转移到UGC内容的用户上。 风险承受。最后这个措施，是风险的兜底措施。即承担风险带来的损失。这一般要求有资金的预留或是退路的预留。  策略 互联网的风控策略，可分为两部分。一部分是业务侧，通过一系列手段，去削弱风险。另一方面，则是宏观侧，通过数据监控整体的业务情况，进行风险的宏观判断。
在嵌入业务的一侧，可按风险行为分为前、中、后三个阶段进行。
 风险发生前：通过技术手段或用户引导，完善用户资料。同时对用户的基本信息进行分析，将明显特征的账号进行标记。该部分，成本和复杂度都较低，适合作为风控策略的主要部分。同时，可通过关联分析，将问题范围缩小，从账号、自然人、到工作室，集中处理。 风险进行中：这部分一般和用户的行为有关，也常常嵌入业务中。常见的如 UGC 的违规内容，色情、暴恐信息等。这部分，像豆瓣，在检测到关键词后，会进行先审在放行。另一个例子则是，12306的验证码，通过人机验证，规避机器人。 风险已发生：尽管手段丰富，但仍有“漏网之鱼”。一旦风险成为既定事实，则需要采取措施应对。一方面，是做好风险的应对，另一方面，则是及时复盘，对现有体系进行审视，避免机制上再出问题。  最后的，无论无论风控做得多好，总会有黑天鹅发生。做好应急预案，有兜底的策略，都十分重要。小概率事件必然发生。风险的发生是常态，无风险其实才是少有的异常状态。要做的就是，在风险发生后，减少风险造成的损失，让系统及时重上线。
技术 策略看起来很简单，但实际操作起来，困难重重。很重要的一个原因是，信息不对等。举个例子，知道该对问题账号处理，但是不知道哪些是问题账号。这里就需要技术来消除信息不对等。
这里就要请出用户画像。一般的，用户画像被用来理解用户，做更好（更上瘾）的视频推荐，做更精准的广告投放。而在风控领域，用户画像的作用，同样显著。
用户画像背后的技术，除了实打实的工程技术外，产品引导也十分重要。对于冷启动策略，通过引导，完善用户信息。更一般的，则是通过标签规则，通过一系列 if else 判断，生成用户标签。同时，对于社交产品，还会有好友关系链，通过社交图网络的挖掘，也可得到有用的信息。
在风险进行中，采用嵌入业务的干预手段，需要实时流计算，这方面有很多好的开源软件，或者是采用像 Prometheus 一类的开源监控软件。如果资源允许，还可做一些时序上的预测。对未来一段时间的数据，给出预测的上下区间，一旦超过，即调起报警。
在风险发生后，对样本的复盘，实际是异常检测。异常检测一般分为两类，孤立状态的点或块异常，或者是上下文相关的时序异常。其核心，是不平衡样本下的分类。这里的检测可以是对用户行为数据的检测，也可以是用户产出内容的检测，如图片检测、文本检测，这方面的技术已经很成熟，数据量足够，质量够高，即可保证高的准确率和召回率。
最后，在泛化能力外，技术还应注意其可解释性，以及可更新的能力。即模型越简单越好，如奥卡姆剃刀所言：“如无必要，勿增实体”。同时，减少数据中的噪声。在上模型或规则前，探索数据、剔除常变量、剔除离群点，通过xgboost等获得特征有效性、对关键有效特征进行筛选。
总结 互联网风控，是风控的一处延申。除风控的基本特点外，也带有其自身的特点。策略上，需要嵌入整个业务流程，同时准备兜底策略。技术上，有数据挖掘的手段，增加风控的效力。
以上总结来自于工作实践和阅读思考，难免受自身局限，如有疏漏，还请读者批判指正。
互联网风控思维导图
关于作者
 参考资料：
  QCon 阿里毫秒级实时风控引擎
  Risk Management: History, Definition, and Critique &amp;ndash; Georges Dionne
  风控算法大赛解决方案&amp;ndash;不得仰视本王</description>
    </item>
    
    <item>
      <title>更高效的远程工作之道--REMOTE 手册精要</title>
      <link>https://kuhungio.me/2020/remote/</link>
      <pubDate>Sat, 07 Mar 2020 17:43:44 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/remote/</guid>
      <description>大规模远程工作实践 远程工作，一个之前都没怎么考虑的事情，在2020年的春节过后，中国大陆进行了一次大规模实验。WFH（work from home），一个在外企很常见的操作，在国内却鲜有生存环境。
虽然朋友圈已经有人发帖，渴望在办公室中办公，但是，也不能因此，就放弃思考远程工作的这么个事物。一成不变往往很简单，但变化之中，才有契机。
远程工作契机 什么阻挡了远程工作的推行，我们无从说起。但何不把这次当作一种契机，去学习其中的脉络。
关于远程工作，找到了一本小册子《Remote》，专门介绍远程工作的。作者也写过另一本书《Rework》，中文名重来 。写书虽说门槛不高，但是写出有说服力的书，具备条件的人往往很少。作者以其自己的公司 Basecamp 为例，说明了远程工作的优点，也向我们介绍了远程工作的注意事项。读懂它，你的远程工作事半功倍。
远程工作迷思 在书中，你可能看到自己的影子，也可以看到老板的影子。无论你是老板，还是打工者，其中的内容都值得细细理解。
拒绝远程工作的理由 只有在办公室，办公时间才是有限的 远程工作，不是一个新鲜事物。至少在作者这个书出版之时，到2020年，已经过去了7年。远程工作改变了集中式办公的缺点，时间被切割，无穷无尽的会议。但其自身也有适用范围，比如写作、编程、设计和客户支持等工作。像制造业，可能就不太现实。很多人对远程工作嗤之以鼻，常抱着努力干活，等我退休了，再来享受生活的态度。老板们顾及远程工作，很可能是担心没了约束，员工的拖延症很可能无限放大，毕竟谁都有拖延的时候。做好工作，而不是死守工作时间。
如果我能看见他，我才能控制他 远程工作，在2020春节之前，一定是有很多反对声音的。比如，缺乏讨论的氛围，公司没有源源不断的点子，这怎么行。没准下一个点子就能颠覆乔布斯。但实际上，我们知道，很多人还在执行几个月甚至几年前的一个点子。有员工认为，家里的干扰太多，琐事不断打扰。但实际上一份有成就感的工作，不会让你轻易被打断。而管理者，会觉得，没有盯着他们，怎么知道他们是在干活，还是躺在床上玩手机。但实际上，就在眼皮子底下，员工也有无数种方法摸鱼。如果不信任他，一开始就不该雇佣他。
别的公司都没这样做，我为什么要做 在团队内部，一个组这样做了，另一个组会嫉妒。但跳出这个逻辑，整个组织目标一致，效率最高才是最终的赢家。再一个，业务部门或者上级会觉得，我现在就要答案，现场能有更高的压迫感。但实际上，并不是所有事情同等重要。再一个，中小型企业会认为，BAT 大公司都没远程工作，肯定有他的不好，马某人都是聪明人，不可能没调研过。但实际上，你跟着大公司的脚步，永远成不了第二个马某人。远程工作能不受地域限制，网罗到世界各地的人才；有些时候，性价比更高。
远程工作精要 远程工作，在2020春节之后，大伙儿已经有了足够多体会。作者的公司长期远程且稳定盈利，他总结了以下内容。
及时同步进度 重要资料公开，而不是让人到处询问，让被询问人工作量加倍。展现工作进度，以成果导向。及时向团队内部公开。承诺往往有更高的约束力，而且，同行肯定比非技术领导更懂所需的工作时长。于此同时，做防灾的准备，诸如数据备份等工作。如果工作需要同客户合作，还需注意，及时将进度同步给客户。
打造良好团队氛围 对于团队内部，保持正向的氛围，阻止消极负面的情绪在团队内部蔓延。聪明且及完成任务，才是合适的好员工。用当地最好的薪水留住他们，而不是因地施策。关心员工的身心健康，担心过度劳累，而不是懒惰，因为可持续才能走更远。最后，保持一个强劲的动力，鼓励员工从事自己喜欢的事物。
员工如何出众 而对于员工，如果你想在团队内出众，往往有两种方法。一个是在保持活跃，另一个就是高质量的交付任务。
关于作者</description>
    </item>
    
    <item>
      <title>人声提取两大步骤：分离音频背景声&#43;过滤空白</title>
      <link>https://kuhungio.me/2020/audio_progress/</link>
      <pubDate>Sun, 12 Jan 2020 23:52:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/audio_progress/</guid>
      <description>背景需求 在处理音频中，我们可能会有这样的场景：随着语音设备的能力越来越强，音频数据越来越大。但实际上，音频中的有效部分却很少，抑或是音频的背景声过大，非目标声音。在这样的场景下，我们希望得到人声，去掉噪声，提高信噪比。
问题界定 这里将问题进行界定，进行子任务拆分：
 将音频的背景声音去除， 去除“无声”阶段。  解决方案 要提高信噪比，这需求在很多场景中有见：比如课堂录音的提取，或者是录音笔的数据存储。
在使用本领域“高深”的技术前，一定要思考，切莫手上有锤子，就看啥都像钉子。想想该领域的专家会怎么做，如何从专业角度看待该问题；其次想想普通人会怎么做，防止落入经验主义陷阱。
背景声音的剥离，最简单的其实是音轨分离。其前提是两种声音存为了不同的音轨，在一些场景很合适。比如电话录音。
背景声分离 但是若只有一个音轨呢？别担心，机器学习来帮助你。spleeter 基于 tensorflow，训练了一套音乐检索系统，能够有效的分离人声和背景音乐声。
该工具已经进行封装，对于简单的人声分离，采用直接调取的方式即可。代码如下
# Use audio loader explicitly for loading audio waveform : from spleeter.audio.adapter import get_default_audio_adapter audio_loader = get_default_audio_adapter() sample_rate = 44100 waveform, _ = audio_loader.load(&amp;#39;/path/to/audio/file&amp;#39;, sample_rate=sample_rate) # Perform the separation : prediction = separator.separate(waveform) 空白切割 在分离之后，得到人声和背景声。人声分离后，仔细听，就会发现里面有很多空白。对于空白部分，进行切割分离。
这里参考 stackoverflow 的代码
from pydub import AudioSegment from pydub.utils import db_to_float # Let&amp;#39;s load up the audio we need.</description>
    </item>
    
    <item>
      <title>如何计算用户生命周期价值（CLV）</title>
      <link>https://kuhungio.me/2019/lifetimes/</link>
      <pubDate>Wed, 25 Dec 2019 23:28:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/lifetimes/</guid>
      <description>在用户关系管理中，常会遇到些直击灵魂的问题：
  这批用户到底价值几何？
  为什么要用这种措施去干预用户，而不是另一种方式。
  为什么干预这类用户，而不去干预另一类，他们的划分标准是什么。
  有这些问题，实质是因为对客户价值不够了解，缺乏行之有效的划分方式。
用户精细化运营价值巨大 随着人口红利的消失，增长逐渐见顶，急需在现有用户池做学问。过去粗放式的买量策略已经不再生效，一是买量成本逐渐高企，二是买量带来的用户忠诚度极低。对现有客户群体的划分和互相倒流，成为重中之重。行业中的黑话“洗用户”，即是讲的这一策略。
对于如何划分用户，不用的职能会有不同的看法。产品有产品的看法，可能基于某项功能偏好；运营有运营的看法，是各种活动玩法的定义；甚至领导还有他的一套看法。但是，无论怎么切入，商业的核心拿捏住，才会八九不离十。
什么是商业的本质：商业的本质是获利。因此，我们从用户的货币价值切入，评估和划分用户的生命周期。
用户生命周期价值，这并不是学界的新鲜产物，该理论在上世纪80年代就已经提出。但对于互联网，网上可搜寻到的资料少之又少。可能的原因有两个：一是互联网在过去20年快速爆发，风口上躺着也能赚钱；二是各家的策略内部不统一，无法形成统一的口径。
但这些都不是不去应用他的理由，反而说明其中价值巨大。这里，我们剥离开复杂的商业逻辑，仅从交易入手，分析用户的生命周期价值，以及用户所处的状态。
用户生命周期价值（CLV） 随着精细化运营的铺开，过去粗放式的、买量用户已经不再买账。每个用户所能接受的最低服务各不相同。如何根据用户价值，进行资源的有效利用。最大化杠杆的使用，成为企业生死的关键。
过去，没有统一的理论出现在互联网应用或是游戏中。但是，运用跨学科的思维，就可以发现：市场营销领域已进行过研究，并给出了精度极高、可解释性强的模型方法。
这种方法，就叫做用户生命周期价值，英文名称 Customer Life Time Value，简称 CLV 或者 LTV。
CLV 是什么 用户生命周期，是一种刻画用户的方法。一般用来解决两类问题：
 用户还有多少价值、用以衡量投入产出比 在干预用户后，根据用户生命周期价值的变化，优化资源的投放。  即用户管理的两个核心问题：用户所具备的价值以及策略的有效性。
需要注意的是，CLV 的产品形态要求非合约。合约在国内最有代表的是合约手机。一般互联网产品，合约形态较为少见。
CLV 的用户群体需已经产生交易，未付费用户不纳入考量。当然，概念迁移，将付费换成活跃或内容消费，该模型也能处理。
CLV 回答哪些问题 用户活跃还是流失，用户还有多少付费潜力，用户在未来某段时间会否再次购买。这三个问题，是用户生命周期价值能够回答的。
如何在自家产品中引入 CLV 应用场景  判断用户所处生命周期阶段 预测用户指定周期内购买概率 预测用户的生命周期价值 通过历史付费数据，预测未来付费  活跃与流失的定义 定义：
用户有交互为活跃
用户一段时间不交互，即为流失
lifetims 工具包引入 安装 python 的工具包：
pip install lifetimes CLV 数据挖掘 用户生命周期判定，需要三个指标
 frequency 用户登录的频率，这里为周期内的天数 recency 用户的最大周期，即第一次活跃到最后一次活跃 T 用户所处阶段，第一次活跃到观察周期结束  对于付费预测，还需要用户的平均付费金额。</description>
    </item>
    
    <item>
      <title>机器学习系统设计 Machine learning system design</title>
      <link>https://kuhungio.me/2019/machine_learning_system_design/</link>
      <pubDate>Sun, 01 Dec 2019 18:26:43 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/machine_learning_system_design/</guid>
      <description>导读 Web app：https://kuhungio.me/machine-learning-systems-design/
 机器学习系统设计 系统设计题，顾名思义，就是考察一个人设计系统的能力。它是一种国外很喜欢的题型，特别是中高级职位，在算法手撕结束后，一般就是系统设计题。
国外的算法工程师，被称之为 Machine Learning Engineer。国内的名头比较多，算法工程师、数据挖掘工程师、机器学习工程师、深度学习工程师都指的这个。
这一岗位同开发岗位，SDE 一样，也需要足够的系统设计经验。
国外的大佬 github.com/chiphuyen 总结了一份机器学习设计的资料，我在这里做本地化整理，同时增加一些自己的从业体会。
内容分为3个部分，分别是：
  机器学习的系统设计部分，这里做了核心概念的摘录；
  系统设计的案例，由于众所周知的原因，很多文章看不了，我这里将其整理放入了 github，同时笔记标注版的放在了公众号：谷粒说数。
  练习部分，作者列了27道系统设计题。我这里将其布置在了网页上，方便自查，后续会上评论进行答案收集。
  系统设计应关注的点 系统设计题，如果没有完整的方案也没关系，主要看表现的思想，着重从以下三个方面考察：
  项目有哪些约束条件，哪些能做，哪些不能做。
  方案的利弊，选择方案时，思考方案利弊的过程。
  主要的功能，最后达成什么样的效果。
  系统设计往往很难，这是因为两方面的原因。1. 缺乏有效的评估手段。2. 问题往往模棱两可。面试中的理想候选人应该是这样子的：1. 能够有效的拆解问题，将复杂问题简单化。2. 能够区分该场景是否需要机器学习方案。第二点很重要，因为在当下，受媒体大环境影响，很多人会选择无脑上机器学习，殊不知某些场景简单的方法更有效。
 Machine learning methods change every year, solving problems stays the same.
 生产环境不同于学术环境 学术研究的一般有以下两个特点：
 想法设法比上一代模型效果更好，而不用思考怎么落地使用它。 由于效果是第一要务，所以算力没有限制，加钱堆机器即可。  而生产环境不同，它的特点如下：
 效果并非越好才好 算力资源常常有限  作为开发者，要始终牢记生产环境是我们的目标。</description>
    </item>
    
    <item>
      <title>Dataops 数据化运维实践</title>
      <link>https://kuhungio.me/2019/dataops/</link>
      <pubDate>Sat, 19 Oct 2019 11:33:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/dataops/</guid>
      <description>翻译自：《What is DataOps? Everything You Need to Know》 From Oracle Data Science Blog
图片自：《DataOps is Not Just DevOps for Data》By DataKitchen in Medium
 DataOps, 看到它的第一眼，大多数人会觉得陌生。但是提到另一个词——DevOps，做开发的同学可能会有些熟悉。DataOps 的理念与 DevOps 类似：将开发或者说是数据，与运维、测试相结合，自动化业务的交付以及架构的变更，使得构建、测试和发布能够更加快捷、频繁且可靠。
DataOps，全称 Data Operations，是一种敏捷运维方法，无感知地将IT基础设施和大数据分析技术结合起来。它的目的是通过结合数据管理的目标与过程，加快分析的速度与准确度。而这一过程，通常会涉及数据的多个流程：数据获取、数据质量检查、自动化、集成，以及最终的模型部署与管理。
最核心的，DataOps 是为了方便管理数据、特别是当你有了一个特定的数据目标的时候。举个例子：为了降低客户的流失率，可以通过利用客户数据构建一个推荐引擎，推荐客户相关的东西，以此来减少浏览到下单的时间，减少客户流失。
这是一个很自然的想法，但是却并不是一件容易的事情。上面的设想需要以下条件：
 你的数据科学团队能够获取到他们需要的数据，同时能够有工具去部署模型。 除此之外，还需要能够将模型集成到你的网站中去，在新数据上训练以持续的改进。 最后，需要一套报表系统来监控其表现。  现在比较流行的做法，做好上面的事情，需要多个部门的合作，包括工程师、IT运维人员以及业务团队。
谁能从 DataOps 中获利？ 总的来说，几乎所有人都会从 DataOps 中获利。
 更好的数据管理将会带来更多可利用的数据； 越好的数据质量会有更准确的分析，与之相伴的就是更好的 insights、商业策略以及更高的利润。  DataOps 起一个润滑剂的作用，使数据团队、工程师团队和技术专家之间的工作更加紧密、更加自动化，以此来充分发掘数据价值、减少时间。
Ashish Thusoo，Qubole 的联合创始人曾在书籍《Creating a Data-Driven Enterprise with DataOps》写道：我在2007年的夏天加入 FaceBook 的数据团队。像平常一样，公司里的任何人想获取无论多小的数据，都不得不找到数据团队，并发起流程。我们的数据团队很优秀，但是他们的精力也有上限。很明显，这是一个瓶颈。
DataOps 这一概念从何而来？ DataOps 起源于 DevOps 这一概念。据了解，财富1000强的公司里，80%的公司已经采用了 DevOps 这一方法。DevOps 的成功主要仰仗于：它把之前独立的两个部门联合在了一起——开发和运维。在 DevOps 的世界里，软件的发布是迅速且持续的，因为整个团队都被整合在了一起，用来检查并处理当下的问题。</description>
    </item>
    
    <item>
      <title>《学习之道》笔记思维导图</title>
      <link>https://kuhungio.me/2019/the_way_to_learn/</link>
      <pubDate>Wed, 16 Oct 2019 07:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the_way_to_learn/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>机器学习实践--测试驱动开发</title>
      <link>https://kuhungio.me/2019/tdd_drive_ml/</link>
      <pubDate>Sun, 25 Aug 2019 00:22:07 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_drive_ml/</guid>
      <description>机器学习现状与问题 2012年，数据科学击败生命科学，成为”21世界最性感的职业“。2016年，AlphaGo 战胜人类顶尖围棋手，深度学习、人工智能一度占领新闻头版头条，并引起一股机器学习新热潮。
这一效应，一直持续到今年：在2019这一年，高考志愿填报金融遇冷，计算机一跃成为抢手专业，在各大工科院校中，有取代传统电气、机械之势；各学院的研究生院，纷纷开始往人工智能、深度学习上贴近。
这从一个侧面，反应了民众对于计算机、人工智能、机器学习的就业预期。但是，随着原来越多的从业者涌入，项目落地越来越多，机器学习这一领域的问题也开始暴露，亟需解决。
机器学习中的常见问题 机器学习的问题，由其特性所致。众所周知，机器学习的发展，离不开大数据技术。海量数据的收集、存储，让算法有了更强大的生命力。通过对大量数据的挖掘、学习，机器学习能够猜你所想，提升购物网站的转化率；能够识别障碍，让自动驾驶成为可能；能够识别风险，扩大业务同时减轻坏账。
由此，针对模型和数据的关系，大致可以分为三类问题。第一种：数据量不足，模型过拟合。算法学习的过程就犹如考前刷题，过拟合相当于只刷一套题，这样的后果就是上一套不同的卷子，算法就懵逼了。第二种：数据量充足，模型欠拟合。欠拟合的算法就像是心思不在学习上的孩子，报再多的补习班，结果也不会太好。最后一种：数据不稳定。算法前期可能很好的学到精髓，但是随着数据的变化，时间的流逝，模型很可能将变得不可预测。
测试驱动开发的解决之道 机器学习的实现方式还是通过软件工程、代码实现，既然是代码，那就存在应对范式。这里，就不得不提 Test Driven Development（测试驱动开发），简称 TDD。TDD 是一种很朴实的想法，在编码开始前，评估需要交付的功能点并写测试用例，一开始的时候测试会失败，接着编写代码修复测试，最后测试通过，修复代码。这里的方式，通俗来讲就是：目标导向，先成事，再迭代。
测试驱动有一个明显的好处就是，能够加快产品发布速度。以往的项目，需求讨论会占据很大时间，讨论完之后，开发方案一旦定下来，后续变更就很难。而现实却是需求常常变更，这往往会导致产品发布的延期。而在机器学习上，测试驱动好处更多体现在保证模型质量上。具体来讲，常通过以下办法：
 交叉验证 通过交叉验证来验证拟合效果 运行速度测试 根据奥卡姆剃刀原则：”如无必要，勿增实体“；简单模型胜过复杂模型 衔接测试 对数据的输入输入进行检测，以防止数据异常波动对模型影响 指标追踪 监控关键指标，不断追踪模型的性能，防止失效模型继续运行  机器学习的债务危机 测试驱动开发一定程度上能减轻机器学习中的问题，但是它只是一种表象。测试通过了，不代表算法模型就没有问题了。魔鬼藏在细节中。机器学习目前仍存在一些技术债务，仍需按特定原则对代码修复，迭代演进。
什么是技术债务 技术债务是一个比方，类比的金融领域的债务。一般指为了加快软件开发速度，折中妥协，选择易于实现的方式，结果是短期加速了软件开发，但长期来讲，开发负担累计，发布逐渐停滞。债务不都是有害的。在业务扩张，市场抢占时期，适当的债务有助于公司扩张。但是若一直不管不顾，最后只能花更大的成本去维护它，直至无法维护。
机器学习中的技术债务 机器学习项目中同样存在债务危机，Google 还就此写了篇文章 《Machine Learning: The High interest Credit Card of Technical Debt》。总结起来有三种：一、边界模糊，数据之间彼此依赖关联。二、没有系统级别代码分离，胶水代码处理一切。三、机器学习系统随着外部世界的改变而彻底改变。
偿还债务 代码重构，就犹如对你的资产进行一次清点盘算：清除不良资产、偿还债务、进行资产上的重新配置。重构能够有效减缓技术债务带来的负面影响。
面向对象的 SOLID 原则 SOLID 原则由罗伯特·C·马丁提出，是五项原则&amp;ndash;单一职责、开闭原则、替换原则、接口隔离、依赖倒置的缩写，是面向对象设计与开发的五个基本原则。通过这五项原则，写出来的程序可读性、可扩展性都大大提高，软件维护和系统扩展变得更加容易。
 SRP 单一职责原则：一片代码只做一件事，及一块代码只实现某一特定功能，尽量减少逻辑的交叉堆叠。 OCP 开闭原则：对象对于扩展开放，对于修改关闭。即保持最小单元，写完后不去修改它，而是通过扩展或者配置的方式补充功能。 LSP 替换原则：任何的子类应该轻松由同一对象树的其它对象替代。 ISP 接口隔离原则：不同的接口做不同的事，软件开发没有银弹，接口也是。解耦能解决掉开发过程中“牵一发而动全身”的情况。 DIP 依赖倒置原则：抽象来自于细节、来自于底层，开发依赖抽象。  机器学习与 SOLID 原则 将 SOLID 原则应用于机器学习，会发现：机器学习与 SOLID 原则相互交织。诸如机器学习中的降维，是在减少耦合；胶水代码、数据依赖又与 SOLID 原则相抵触。</description>
    </item>
    
    <item>
      <title>测试驱动的机器学习思维导图</title>
      <link>https://kuhungio.me/2019/tdd_with_ml/</link>
      <pubDate>Thu, 22 Aug 2019 00:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_with_ml/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>金字塔原理思维导图</title>
      <link>https://kuhungio.me/2019/pyramid/</link>
      <pubDate>Thu, 15 Aug 2019 00:47:36 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/pyramid/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>敏捷革命思维导图</title>
      <link>https://kuhungio.me/2019/scrum/</link>
      <pubDate>Sat, 10 Aug 2019 00:54:34 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/scrum/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>系统思考与卓有成效的管理者</title>
      <link>https://kuhungio.me/2019/manadement/</link>
      <pubDate>Wed, 17 Jul 2019 17:02:56 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/manadement/</guid>
      <description>在老一辈的眼中，学而优则仕。学习好了就去当官从政，去服务别人。而在父母这一辈人的眼中，不论你干啥，当“老实人”被人管是不行的，他们的观点有一定的时代背景，但仍然在潜移默化影响着每个人。
而对于初入职场的新人来说，虽然暂时当不上管理者，但被管理时却也会思考：“如果是自己，将会怎样去做管理？” 对于这一批新的90后甚至00后来说，管理并不再是一场服从性测试，权威性的组织管理方法或不再有效。
什么是这些年轻人喜欢的管理风格呢？ 如果稍微读过一些管理学的书籍，就会发现，管理其实在近现代发生了较大的变化。厚黑学受人推崇，有它的一定意义，但是小年轻们对里面的技巧似乎并不买账。这点在酒桌或者聚餐时就可以看得出来。这批年轻人有自己的想法，有独立的意识，甚至有些“不懂”人情世故。
回顾历史，近现代企业管理做得比较好的，要当属日本。日本凭借其精益管理思路，在汽车制造业一举占领美国市场，打得美国的传统汽车巨头没有还手之力。在大学里，作为机械大类的学生，一定多少接触过精益生产。
这套理念，帮助日本一跃成为制造业强国。而反观国内，作为一个机械大类出身的同学，你一定知道国内的“中国制造”现状是什么。而作为一个跨行的 IT 向工程师，在实践中，也发现，以信息互联标榜自己的互联网，除了开源的代码复制粘贴得挺快，管理模式其实并没有跟上节奏。
今天，在当下环境中，还有很多管理者是靠着本能在管理，而不是一套系统科学的方法。一个程序员，或者是 IT 企业的中层管理，有时间去研究业务，却少有时间去研究管理。项目短平快上线、管理粗糙莽随意。像极了早期国内自然资源开采，先污染后治理的样子。
IT 工程师眼中的现代管理究竟应该是什么样的呢？ 我们接着从上面的日本制造业说起。在当时，他们推崇一种见 kanban 的工作法。即在看板上列出工作事项，工作流公开透明。而在当下，国内头条、国外谷歌都在推崇 OKR。这里两者的本质是相通的，即：公开透明公司的业务流，每个人都能参与到目标设定里面来。
低效的管理者 在执行这套的同学可能会说，这其实只是形式主义，到头来还是 KPI 导向，面向 PPT 晋升。这在企业中确实存在，而其中的缘由，有以下5点：
 管理者不能良好的安排自己的时间，自己的时间属于别人&amp;ndash;无尽的会议、向上汇报、向下沟通 眼光受限于岗位，注意力集中在流程、规范与控制上，而不是贡献 没能充分发挥人的长处，无论是自己、上司抑或是下属。总认为下属不能很好地完成工作。从职位出发去设定一个人能做什么、不能做什么。不能容忍人之短。 零碎容易完成的优先做，根据和需求方的亲疏远近安排优先级，而不是要事优先 无法有效决策，没有流程，不愿放权。决策没有边界，不设立反馈机制，任由自己的“偏见”主导决策  做好了上面的5点，企业就能蒸蒸日上了吗？其实也不是，如果没有一个学习型的组织，单靠个人也是难以推动的。千里马常有，而伯乐不常有。运气好，遇到一个放权给你的领导，做起来是运气，做不起来是常态。企业中的死海效应，“劣币驱逐良币”也同样常见。
螺旋沉默的组织团队 也就是说，还需要一个良好的组织氛围。而变成一个死海的组织氛围常有以下特征：
 安于现状，封闭思想。更愿以主观的视角观察现实，而不是客观。 心智模式不成熟。对已有的成功盲目崇拜模仿，而忽视掉其潜在的天时地利人和背景。 各自有各自的小算盘，没有共同的愿景。 团队内部给自为战，几乎不存在团队学习。 局部思考而不是系统思考。认为危机的主因是人或事，而不是系统机制的问题。从未留意过系统如何塑造自己的行为。不清楚系统的边界、增长极限、反馈回路以及压力是如何转移的 。  如果是想做一个失败的管理者，营造一种糟糕的团队氛围，按照上面做准没错。
短期利益驱动的变革  学校教育告诉我们：永远不能承认我们不知道的答案。而大多数公司还在强化这种训练，奖励善于推销自己观点的人，却忽视对复杂问题的探寻。（还记得上一次你的组织给对公司现行政策提出难题的人——而不是解决某个紧迫问题的人——颁发奖励是什么时候吗？）&amp;ndash; 《第五项修炼》
 别急，是不是准备收藏，并在组织中逆向推行以上措施呢？那你可能又陷入了组织变革中的另一个陷阱：在变革过程中，我们不仅难以看到整片森林；甚至，我们还会挑出一两棵我们认为最看好的树，然后就全神贯注在它们身上，为它们而倾注全部的变革努力。
为什么目前还有很多的 IT 企业管理者，在靠着本能管理呢？一个字：利。 无利不起早。 概念发明以后，还要在有实用价值的成本范围内，以一定的规模进行可靠的复制，它才能够真正落地。
为什么大家都觉得修正以上的问题是不符合利益的呢？因为很多时候，都是想短期梭哈一波，先用着后面再说，先这样管理出问题了再说。即忽视了系统性的东西，而仅专注于眼前的事物。
系统思考 如果想在组织中构建学习型组织，成为一个卓有成效的管理者，那肯定不是忽视系统思考的力量。
关注长期的行为和系统内部的结构，而不是表象和短期事件；世界非线性，不要用线性的思维思考；恰当的划分系统的边界；充分考虑多方的限制因素及相对强弱。
通过实际行为来推断系统目标，而不能只看表面的言辞或其标榜的目标。时间延迟无所不在，当下的干预很可能一段时间后才会产生影响。没有人能做到充分理性，每个人的理性都是有限的。
总结 在最近和实习生同事的合作过程中，深切的感受到信息差带来的权力膨胀感。实际上，管理也是一门实践课程。一开始可能会走偏，但只要有回顾、有反思，也终究会上正轨。系统思考、长远为重。不仅要问这些年轻人想要什么、也要问自己想要什么。</description>
    </item>
    
    <item>
      <title>A/B test 评价指标的选择</title>
      <link>https://kuhungio.me/2019/abtest-2/</link>
      <pubDate>Sat, 22 Jun 2019 15:28:01 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest-2/</guid>
      <description>如何定义一个评价指标 这是上一篇文章什么是 A/B test的续集，上一篇主要讲述 A/B 测试的历史，这里接着讲如何选择指标。
从本人的经验来看，一个指标怎么选择确实重要，但更重要的是需要自上而下理解且落实科学实验。而不是拍脑袋想指标，中途随意更换指标，汇报时仅罗列有利的指标。
如果要用一句话解释，如何定义一个评价指标，那一定是“以始为终”。在定义一个指标的时候，要想一想为什么要定义这个指标，这个指标的定义是为了说明什么情况，如果这个指标发生变化，将需要怎么去解释它。
指标定义的两种情况 在这里，定义指标的时候有两类：一是不变量，即变量组和对照组的都应该相同；另一个是变量，即需要观察改变的量。
对于不变量，需要注意两者的总量是否相同，数据的分布是否相同。以上保证实验的正常进行。对于变量，首先思考高层次的商业指标。诸如收益、市场份额、用户量等。接下来就是细节的指标，如用户体验，网页停留时长。
 例如，在游戏中，新手教程没完成的玩家，虽然不能直接知道原因，但根据经验，可能是引导时间太长、网络卡顿或者是别的原因。类似这样的情况，是用户体验上的问题。后面也会有一些方法提到如何去评估它。
 在实验中，可能得到的不是想要的信息、或者实验时间太短，得到的结果不准确。甚至有些东西无法衡量，这种情况又该如何去评估它呢。别急，下面的内容会给你回答。
自顶向下设计评价指标 如何确定指标
 高层次的指标（如：活跃用户数、点击转化率 CTR） 指标细节（如：如何定义用户活跃） 使用一组指标，并将他们整合为一个单一指标（如：总体评价指标（OEC））  对于评估，可以选择一个指标或一套指标。如果是使用一套指标，可以把他们聚合成一个指标，比如构造一个目标函数，或者是简单的加权指标。
最后一点需要考虑的是：指标的普适性有多少。如果你在运用 A/B 测试，最好能有一个指标能够贯穿整个体系。
 举个例子：用户漏斗。
它表示用户通过站点执行的一系列步骤。 之所以被称为漏斗，是因为每个后续阶段的用户数都少于上面的阶段。 每个阶段都是一个指标——总数，比率和概率。
 数据不足怎么办 有些数据可能难以获得，主要原因如下：
 没有数据的权限 需要较长时间去收集数据  使用外部数据 其它数据收集的技巧：3种公司常用的方法
 数据中间商 调研公司 学术文章  以上能够帮助你依照整个行业设定指标。
额外的内部数据 额外的内部数据也可被使用，例如：
 回溯性分析：查看历史数据以找寻改变并进行评估 调研与用户研究：这个帮助你找到你想研究的点  以上办法的缺点是它只告诉了你相关性、没有告诉你因果性，而实验一定程度上可以解释因果。
最后，别忘了与你的同事交换意见，看看他们认为重要的指标有哪些。
附：[其它获得额外数据的方法](&amp;lt;https://s3-us-west-2.amazonaws.com/gae-supplemental-media/additional-techniquespdf/additional_techniques.pdf)：
 用户体验研究（UER）——高深度少用户。这也适用于头脑风暴，在 UER 中也可以使用诸如眼动相机的设备，同时回溯历史进行分析。 焦点小组——中等深度中等规模用户。能够在一些假设上获得反馈，但也容易陷入集体思想的情况（即真正的个人意见难以获得表达） 调研报告——深度较低但用户规模大。对于一些难以直接衡量的指标很有用。不能用于直接和其它指标比较，因为调研的对象和指标很可能与大盘不同。  指标的实际例子 高层次指标：点击率
 定义一：Cookie 的总点击次数除以 Cookie 去重后的总数 定义二：被点击的页面数除以总页面数 定义三：总的页面点击次数除以总页面数  可能还需要过滤爬虫、牟利等行为以消除数据偏差。通过切片来判断数据是需要偏置还是过分偏置。在过滤掉数据后，计算每个切片的评价指标表现。如果数据表现有偏差，那说明数据里可能还需要调整。</description>
    </item>
    
    <item>
      <title>HIVE 技巧积累之合并重叠日期</title>
      <link>https://kuhungio.me/2019/merge_overlapping_date/</link>
      <pubDate>Sun, 09 Jun 2019 00:17:05 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/merge_overlapping_date/</guid>
      <description>目前网上流传着一个段子，说算法工程师实际上就是 SQL boy，数据分析师是 PPT boy。艺术来源于现实，实际上的我们真的有很多时间在写 SQL 出数据，或者是针对 bad case 做数据的进一步分析。
这不，近期这边接到的一个需求就是对玩家的某项行为进行统计。一般来讲，掌握基本 SQL 的技巧，这些需求的难度都不大。但是这个需求需要将玩家用户的多个重叠日期进行拉伸去重。这一下可难到大伙儿。在自个儿思考无果，团队讨论之后也没啥直接的办法。
在网上搜索一番后，很多都不是很对应。不过好在几轮筛选，找到了一个类似的需求。原文链接在这里：🔗。为了方便后来的人，在这里做个分析记录，以及后面举一反三该怎么做。毕竟这些东西很少出现在教程和课本里，但是当业务方有这个需求的时候，常常又很紧急，容不得细思慢想。
问题定义： 在解决一个问题之前，我们需要先明确定义问题。这里的问题是对多个重叠日期，用 SQL 将其进行去重，并在 HIVE 环境中使用。
对于日期情况的定义 这里采用穷举法，可以得出以下13类情况：
问题简化 解决问题的核心是简化问题。这个问题看起来情况众多，实际上，对于我们的任务，只有两种情况：一个是两个日期有重叠；一个是两个日期没有重叠。
对于不同的情况，要做不同的处理。重叠日期取最大最小日期即可，非重叠的分段取。剩下的即是通过工具去实现逻辑。
数据准备 这里采用原作的方式定义数据，创建出上面的13中情况。实际上，如果你的格式和下面的类似，做出对应的调整即可。
drop table t purge; create table t ( test_case varchar2(32) not null, start_date date not null, end_date date not null ); Insert into t values (&amp;#39;01:precedes&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;01:precedes&amp;#39;,to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;02:meets&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;02:meets&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;03:overlaps&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;03:overlaps&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;04:finished by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;04:finished by&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;05:contains&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;05:contains&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;06:starts&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;06:starts&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;07:equals&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;07:equals&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;08:started by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;08:started by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;09:during&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;09:during&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;10:finishes&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;10:finishes&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;11:overlapped by&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;11:overlapped by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;12:met by&amp;#39;,to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;12:met by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;13:preceded by&amp;#39;,to_date(&amp;#39;03&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;04&amp;#39;,&amp;#39;DD&amp;#39;)); Insert into t values (&amp;#39;13:preceded by&amp;#39;,to_date(&amp;#39;01&amp;#39;,&amp;#39;DD&amp;#39;),to_date(&amp;#39;02&amp;#39;,&amp;#39;DD&amp;#39;)); commit; 定义出来的数据如下</description>
    </item>
    
    <item>
      <title>A/B test 揭秘之什么是 A/B test</title>
      <link>https://kuhungio.me/2019/abtest/</link>
      <pubDate>Fri, 24 May 2019 09:02:00 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest/</guid>
      <description>此文总结自 Udacity 的课程：A/B test，详细而系统地讲述了 Google，Amazon 以及 Netflix 等公司是如何在商业问题中设计 A/B test 并评估效果的，对于国内的业务也有很强的参考意义。这里是总结的的一部分：什么是 A/B test，讲述 A/B Test 的定义、适用范围以及和传统方法的异同。指标选择、实验设计与评估将在后面陆续放出。
A/B 概览 Q：什么是 A/B test？ A：A/B test 是一种用来测试新产品或新功能的在线测试常规方法。一般分为两组用户，一组对照组，一组实验组。对照组采用已有的产品或功能，实验组采用新功能。要做的是找到他们的不同反应，并以此确定哪个版本更好。
Q：A/B test 是否有适用范围，还是说所有情况都适用？ A：A/B test 能帮助你爬上前面的山峰，但如果想弄清楚是爬这座还是另一座，A/B test 可能不太有效。A/B test 能对很大范围的事情进行测试。
 例如：  亚马逊个性化推荐的 A/B test，发现个推能显著提升收益。 领英对首页流排序的测试，谷歌的搜索广告排名。 此外还可以对用户难以察觉的东西进行测试，如网站响应速度。亚马逊在07年发现：页面每增加100ms延迟，收入将会下降1个百分点。    Q：A/B test 不能做什么事情？ A：上线新的版本，带来完全不同的交互体验；或是低频长周期的产品；以及 A/B test 并不能发现被遗漏了什么。
测试新的交互体验时，A/B test 可能不太奏效。原因有两个：一、厌恶改变，不是每个人都喜欢改变，这可能导致用户的厌恶和抵触情绪。二、新奇效应，对于新鲜事物，用户可能会挨个尝试所有东西。
于此同时，这里会有两个问题，一个是你的比较基准是什么？另一个是需要花多少时间得出结论？举个例子：像低频的房屋租赁，在测试推荐流的时候，很难确定用户是为啥回来的。因为这要花的时间太长了，也许是半年，甚至是更久。
A/B test 无法告诉你是否有遗漏。当我们在某个产品测试信息推荐流时，仅凭 A/B test，无法知道是否该给这个用户推荐地理信息的资讯。于此同时，也无法确定别的产品是否需要推荐流。
Q：对于 A/B test 难以胜任的事情，该如何解决？ A：通过其它数据源来补充，对日志进行分析假设验证。或是通过其它技术，如用户研究来定性分析。
Q：A/B test 的历史是什么样的？ A：最先使用 A/B test 的，可能是农业领域。人们将土地分为不同部分，测试哪块地适合哪种作物作物或是作物如何生长。在科研领域。假设检验是确定创新的关键方法。医学上的 A/B test 被称为临床试验，通过此种方法来确定新的治疗方法是否有效。</description>
    </item>
    
    <item>
      <title>数据从业者必读的7本书 Booklist for DE</title>
      <link>https://kuhungio.me/2019/book-list-for-ds/</link>
      <pubDate>Tue, 07 May 2019 23:34:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/book-list-for-ds/</guid>
      <description>之前逛论坛，或者学习网站，看到很多人喜欢推荐书。自己早些时候也是这样，但是只 mark，却很少去看。如今作为一名社会人，虽说工作之余时间少了很多，但业余仍在坚持阅读。其中，支撑学习动力的一本书便是：《穷查理宝典》。书中查理·芒格提到的多学科思维，以及复利思维，一直在影响我的交友、做事和看问题的方式。
有关注某校友的公众号，他是做爬虫和可视乎的。某天在推荐 Python 学习资料。封面看着挺美，点开一看，书单质量实属一般。倒像是接的推广，很多估计他自己都没有看过，不太负责任。于是乎，便萌生了出一期书单的想法。而定位，便是数据科学家、数据挖掘工程师、算法工程师的书单。
首先声明，这份书单不是单纯的技术向书籍，不会有什么西瓜书或是算法导论之类的。他们也是好书，但不会出现在这里。因为在工作中大家就会发现，技术只是工具，好的工匠 != 熟练使用工具的熟练工。看见大局，同时有跨学科的思维，能够从事物的本质去出发，理解和思考它，也很重要。
作为一个数据挖掘工程师，以下是推荐的核心7本书单。为什么是7本呢？因为人一下子能记住的东西是有限的，记不住就忍不住收藏。收藏了就几乎等于很少看了。收藏一时爽，一直收藏一直爽。所以，书单从原来的二十几本变为了现在的7本。
这7本书的逻辑是从底层到高层。底层是构成我们一部分的东西，是我们的认知。中间则是我们的技能。而高层，则是我们的自我实现。最终又回到我们的认知。简单来说，就是从软技能到硬实力，再到软实力。
通识与概念  Top 7  通识趣味读本&amp;ndash;《赤裸裸的统计学》
该书讲了很多身边的例子，让人对统计学的应用有一个初步认识。且是一个检验兴趣点的很好方式。如果你对这些东西都不是很感冒，那么可能这行除了薪水，没有别的能吸引你。后面的内容也就没有读的必要了。
除了例子以外，本书也有很多反常识反直觉的东西。诸如统计数字会撒谎、因果关系与相关关系的混淆。黑天鹅、三门问题等地很考验一个人的智商。看完之后有醍醐灌顶的感觉。
与之类似的书还有《大教堂与旧集市》、《编码》等。
 Top 6  大而全&amp;ndash;《信息论、推理与学习算法》
如果你对第一本书的内容感兴趣，想要深入了解背后的原理，那么这本书不容错过。这本书更像是一本大百科全书，涵盖了传统信息论到最新算法的大部分内容。从熵、到编码、再到概率与推理，最后到常见的模型和神经网络。是一本适合高年级学生或者专人人员的查阅宝典。
这本书说实话有些厚重，限于版面，如果只推荐一本，会推荐它。当然如果想看更多元的内容，附加的书籍📚可不容错过。由于本身的专业偏传统工科，编码、信息压缩也有接触，因而过渡起来不会很困难。
与之互补的书还有《推荐系统实战》、《信息检索导论》、《集异壁》等。
工具与思想  top 5  吃饭工具&amp;ndash;《SQL 必知必会》
作为一个工程师，常自嘲自己是 sql boy。那是因为，在实际生产环境中，数据处理花了很大事件。大部分时间都是和sql 打交道。做过比赛的同学可能知道，数据处理、特征提取是很关键的一步。
在企业中，这一情况越发突出。有时候原始数据分散在各个地方，连规整的数据都没有。因而需要掌握一定的 sql 技能。虽然有些专业会学习数据库这一门课程，但这本书可以起到一个梳理作用，同时也有一些小的注意点。
掌握了这本书的同学，推荐《 SQL 反模式》，讲 sql 范式更进一步。虽说是给数据库开发人员看的，但是知其然并知其所以然，也是很好的。
如果想看到更大的图景，那么 ddia 一定不容错过。ddia 在一年前就很火，网上也有他的公开中文翻译。讲解整个数据系统很透彻。适合各类程序开发人员阅读。
 top 4  《利用 python 进行数据分析》
这本书也算是启蒙书。涉及的内容基本面很广，该有的都有了。介绍了 python 在数据科学领域的基础知识，同时也有案例解析。
读完这本书，参加小型的数据挖掘、机器学习类的比赛不会存在门槛了。与此类似的书还有《集体智慧编程》，以及近期比较火的 hands on ml。
思考与呈现 前面都是技术向、原理向的内容。是不是掌握了以上内容，就可以美滋滋的享受生活了呢？其实这是很多软件从业人员、甚至是工科同学的一个共同误区。觉得把我的技术学好了，就万事大吉，酒香不怕巷子深了。在这里千万不要忽略掉你的软实力。
在某些头部公司、ppt 文化盛行。虽然有些走极端，这其实也是一种现状。从原则上来讲，只讲 PPT 画大饼而不做事是不对的，所以他们被放在最后讲。与此同时要记住，硬币的反面也是不对的，只埋头苦干，而不去扩大影响力，事情的价值就很可能被低估。</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>深度强化学习技巧 hacks for training deep RL 这是一篇旧文，John Schulman 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。 测试新算法的技巧  简化问题，使用低维变量。   使用类似只有角度和速度两个变量的 Pendulum problem 问题。  这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。 当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。     构造一个 demo 来测试你的算法   比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。  这样能够轻易地发现那里出了问题。 注意：不要在这样的小问题上过分的尝试。    在熟悉的场景中测试   随着时间的推移，你将能预估训练所需的时间。 明白你的奖赏是如何变化的。 能够设定一个基线，以便让你知道相对过去改进了多少。 作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。  快速上手新任务的技巧  简化问题   从简单的开始，直到回到问题。 途径1： 简化特征空间  举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。 一旦起步，逐步还原问题直到解决问题。   途径2：简化奖赏函数  简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。 比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。    将一个问题转化为强化学习的技巧 可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。</description>
    </item>
    
    <item>
      <title>机器学习建模与部署--以垃圾消息识别为例</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>前言 学历与定位 近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。
如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个本科就业的人，如果没有较为丰富的实战经验；有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。
模型算法的实用主义 机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。
这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 kuhung/flask_vue_ML
后端 flask 相关依赖的安装 pip install -r requirements.txt
核心函数  导入函数包  from flask import Flask, jsonify, request from flask_cors import CORS # 做跨域的准备 from flask import session # 追踪客户端会话 from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类 from flair.data import Sentence 准备工作  app = Flask(__name__) # 声明准备 app.secret_key = &amp;#34;super_secret_key&amp;#34; CORS(app) classifier = TextClassifier.</description>
    </item>
    
    <item>
      <title>如何设计一套类似视觉中国“鹰眼”的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”
 2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。
![](/images/vgc/vgc 不敢配图.jpg)
 “鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。
爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。
首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。
![](/images/vgc/vgc 图像工程与相关学科领域的联系与区别.jpg)
基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。
首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。
从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。
第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。
而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：教 AI 学会看图说话：Image Caption。
总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。
这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。
最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。
附录 视觉中国图片侵权追踪系统曝光：鹰眼系统
2018年度市科委第四季度项目(课题)验收公开清单
视觉（中国）文化发展股份有限公司 2016 年年度报告
《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋
《基于内容的图象和视频检索》</description>
    </item>
    
    <item>
      <title>机器学习项目的完整生命周期 Hands On Machine Learning in Industry </title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。
机器学习项目的生命周期  问题定义   定义问题，并关注大局   数据处理
 获取数据 探索性的数据分析 清洗数据，为接下来的模型做准备    模型方案
 探索不同的模型并挑选合适的模型 对模型进行微调，并集成为更好的模型 解决方案呈现    部署维护
 部署、监控并维护系统    定义问题，从大局出发  和业务团队一起定义问题目标 我们的解决方案将会如何发挥作用 现在的解决方案是什么样的（如果有） 你将如何定义这个问题（有监督、无监督，在线还是离线） 结果该如何衡量 衡量方法是否和商业目标一致 要达成这一目标，至少的表现该是什么样子的 类似的问题是什么？有无可复用的经验与工具 我们有专家知识吗 你将如何着手解决这个问题 列出你或者别人目前所作的努力 如果可能，对假说进行验证  获取数据 建议：尽量自动化以更容易地方式获取最新的数据
 列出你所需的数据以及体量 找寻并记录下获取数据的方式 检查数据将占据多少空间 检查是否有法律风险，如有必要请获得许可 获取许可 创建工作空间，确保存储足够大 获取数据 转换数据的格式以便能够方便操作（不需要改变数据本身） 确保敏感信息被删除或保护加密（匿名） 检查数据的大小和类型（时间序列、采样、地理信息等） 划分测试集，把他放一边，并且不再去动他（防止数据泄露）  探索数据 建议：在该阶段尽量获取领域专家的意见
 创建数据的副本以便做数据探索（如果数据量太大，做降采样处理） 创建 Jupyter notebook 以便保存探索记录 研究每个属性及其特征  名称 类型（类别，整型/浮点，有无上下界，文本，结构化等） 缺失值 噪声数据（随机数，异常值，四舍五入的误差） 对本任务可能有用的数据 分布类型（高斯分布，均匀分布，指数分布）   对于有监督问题：确定目标对象 可视化数据 研究变量间的相关性 研究你将如何着手解决此问题 确认比较有希望的解决方案 确认有用的外部数据 将以上信息存档记录下来  准备数据 建议：</description>
    </item>
    
    <item>
      <title>GPT2 模型生成假正经文稿 Slack gpt2 Bot </title>
      <link>https://kuhungio.me/2019/slack-gpt2-bot/</link>
      <pubDate>Mon, 25 Mar 2019 22:36:06 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/slack-gpt2-bot/</guid>
      <description>slack app：slack workspace
 记得在校的时候，冰岩作坊做过一个app，讲接龙故事的。类似于我写一段，另一个人写接下来的一段，最后凑成一个完整的故事。当时，可产生了不少有意思的段子。最近，GPT2 模型的发布，让人不禁想到，有没有可能让机器来完成这个任务呢？机器写十四行诗、机器写莎士比亚风格的文章，机器写对联，这些都已经成为了现实。人工智能虽然没有带来突飞猛进的质变，但着实催生了很多有意思的小玩意儿。对于GPT2，一个字概括来说就是：壕——数据量大，算力能够 cover 住。这套算法模型网罗了几乎现有的所有文本数据，成功“过拟合“地屠榜，刷新多个 NLP 任务榜单排行。作者为了预防滥用模型、同时让别的研究者能够有个初步地认识，开源了一个小一些地模型。该模型的能力之一，就是我们今天的主题：接着别人地话写故事。今天我们要通过算法来实现。
虽然作者有在尽力简化复现难度，但对于很多不是这行的人，让他去敲命令行来走完整个流程，还是困难重重。能够将深奥的原理讲给普通人听，并且简单易懂，是一项科学传播的必备能力。做为技术向的工程师，在产品处于雏形阶段时，能够通过一个 MVP 最小价值产品，实现核心功能，也是一项大大的加分项。对于今天的任务，我们选取容易上手，接口丰富的 slack 作为我们的前端交互窗口。
如何构建一个 MVP 产品；或者具体的来讲，在我们的这个任务中，如何将数据挖掘工程师的模型成果，转化为可落地、可感知的产品或服务呢。操起斧子直接开干，依葫芦画瓢撸个前后端出来吗？这，其实是很多技术人员的一个误区——认为什么都可以从技术层面解决，”少废话别bb，bb is cheap，show me the code“。但从一个商业产品或服务商的角度来看，客户与渠道是前台，我们的客户是谁、如何触达客户以及选用何种渠道维系客户，是一个一开始就要考虑的事情。
以这个 GPT2 bot 为例，我希望的客户是对 GPT感兴趣，但又没基础去折腾的学生或是其他领域的人士，抑或是没时间去跑 demo 的专业同行。如何触达客户：你看的这篇文章的平台，就是我的触达媒介。我最后选择用 slack 交付我的服务，而不是 qq 或 微信，是因为他成本更低，虽然阻挡了部分潜在客户，但权衡后是可以接受的。最后的工作才是依葫芦画瓢，照撸一个出来。本文参照了EdwardHuCS,并在其基础上做了部分改动。
虽然这波 AI 热潮，让很多像我这样的非科班得以上车。但在实际生产环境中，我们还是暴露了诸多问题。其中之一，便是工程能力薄弱。会写 SQL 、会手推算法、会调包，但是就是不会写能跑的整个小系统。在业务变化快的公司中，这可能不是一个好事情。你的模型也许还在细调参数，但突然整个业务就没了。如果你能拿出一个能跑的马儿，兴许能影响这个业务。这就是前面提到的加分项。
言归正传，我们回到在slack上面。我们的核心就以下代码：
核心代码解读 导入一些基础配置
import os import time import re from slackclient import SlackClient import sys from gpt2.src import generate_unconditional_samples # instantiate Slackk client slack_client = SlackClient(&amp;#39;&amp;#39;) # 认证口令 # starterbot&amp;#39;s user ID in Slack: value is ssigned after the bot starts up starterbot_id = None 延迟配置以及样例和匹配模式</description>
    </item>
    
    <item>
      <title>凭什么打败竞争对手？基于数据、基于分析的商业竞争 Competing on Analytics </title>
      <link>https://kuhungio.me/2019/competing-on-analytics/</link>
      <pubDate>Tue, 12 Mar 2019 10:48:59 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/competing-on-analytics/</guid>
      <description>数据科学家这个职位，随着12年的哈佛商业评论的一篇文章，成为了21世纪“最性感的职业”。这年头，越来越多的年轻人开始往这个方向奔，市场几近饱和。但是，很少有听见企业家说：“是的，我们很需要数据工程师，因为以下原因&amp;hellip;“对于看此文的老板们，你们是否不止一次听到媒体鼓吹大数据、鼓吹机器学习、鼓吹人工智能，却很少有听到说这些东西，对于企业来说，实实在在带来了什么。如果你的答案是“Yes”，那么这篇文章将解答你的疑惑。
本文论点主要取自 Thomas H. Davenport 文章 《Competing on Analytics》，试图从企业管理的角度，阐述为什么我们需要数据科学家（或者说广义的数据相关人员）；他们能给企业带来哪些切实的好处；以及作为企业家，我们该如何转型，如何拥有更强的竞争力。
同质化的市场危机 在当下，想依靠某个新奇的点子或者是产品服务，已经不大可能再和其他竞争者区分开来。作为一个人类组织，底子里仍保留有人类的天性。人类天生就爱模仿，从一出生模仿吃东西，到后面通过模仿习得语言，再到后面的学习。人类的本质可能就是个复读机。模仿可以说保证了我们人类种族的存在与延续。对于企业来说，也大抵相同。
尽管我们知道，从道德原则上讲，大企业模仿别的东西是不对的。但是，从商业利益角度，无数的事实告诉我们，模仿，对于企业来说真的是一个大概率稳赚不亏的事情。把市面稳定的产品拿来微创新，再加持自己的人力或渠道优势，很快就能回本。保不齐也能把竞争对手耗死。现实即是如此。
比你更有利的竞争对手 越来越多的产品、服务开始同质化。无论互联网、游戏、手机或是制造业、服装业，越成熟的领域这个现象越明显。与此同时，我们的竞争对手可能在东南亚，拥有更低的人工成本；可能在不规矩的私营企业，拥有更多免费加班的程序员；也可能是腾讯头条这样的大厂，控制着大部分渠道。那么，你的产品服务，凭什么脱颖而出？
答案就是成为分析型竞争者
数据分析竞争者在干什么 数据分析型竞争者会做以下几个事情。
用户 通过分析，去洞察客户的需求，以及他们所愿支付的价格，找到他们保持忠诚度的原因。在商业模式中，客户是我们的直接服务对象，也是收入来源。那么，势必需要搞清楚客户的数据情况。
在当下，比较流行的技术是通过用户画像技术，去刻画我们的用户群体。用户的分布地域、用户的性别以及年龄，用户的偏好。只有这些东西都搞清楚，我们才能清楚的知道我们的客户是谁，为什么他们需要我们的服务或产品。
渠道 与此同时，也要分析我们触达用户的渠道。不得不说，发明电视黄金档广告的人，一定是个商业奇才。曾几何时，电视广告和路标广告曾是众多老板的竞相争夺的资源，屡屡出现标王，一次次刷新记录。在那个时代，只要你砸钱，拿到黄金时间的广告，就是稳赚不赔。但现在不一样了，各种互联网渠道，在抢占着人们的注意力。楼宇电梯广告、站台路牌广告各种花样层出不穷。
但是，你就真的清楚该投哪一个了吗？还是听信对方销售人员一阵天花乱坠的吹嘘，就乖乖交了钱，却得不到想要的转化效果？通过适当的分析，我们可以知道用户在哪些渠道对我们的响应度最高，知道哪些渠道可以带来更高的转化，从而优化我们的渠道成本投入。
举个我自己的例子：我的文章隔几天就会发一篇，分布在不同渠道：微信、知乎、头条、掘金、简书。那我是单单为了占坑防洗稿就完事了吗？不是的，作为一个数据挖掘工程师，我会分析各个渠道带来的阅读、关注和互动，从而调整渠道策略。
目前我就发现，知乎和头条的信息流产品在分发策略上做的很不错，能保证充分的曝光。微信适合做核心粉丝的沉淀，和粉丝去探讨交流一些问题。而掘金、简书的曝光有限，那我就会在更新是把他们往后放。
那是不是我就应该放弃简书掘金了呢？也不是的。通过分析我发现，掘金在谷歌搜索的排名占比靠前，简书在百度搜索的排名靠前，他们俩实际是很好的 SEO 流量优化渠道。这就是渠道分析的效果。
人力 通过分析，去计算员工对公司利润做出的具体贡献，而不仅仅是关注薪酬成本。以前的自己觉得，买东西或是做事情，先去看成本是多少。工作后发现，领导的视角不是这样的。成本对于老板们来说，只是个数字。他们更关心做事的投入产出比。对于员工问题也是这样。
但现实不是这样的。很少有公司会关注这名员工对利润的贡献，反而更多的去关注他的成本是多少。他今天996了没，没有996对不起我给他开的价钱，而丝毫不关心员工对公司利润所做的贡献。而另一个极端就是，有些老板觉得这类人便宜，从而养了很多闲人。这两种情形虽然短时不会给企业带来多大负面影响，但你的竞争性选手，已经在利用数据，去发现员工的价值贡献，并对人事招聘进行调整了。
库存 在实业中，我们还要追踪现有的库存，预测并分析需求量，减少库存的积压，提高现金流转效率。这里主要是对重资产的企业老板，如果你能在这其中发现机会，一个点的提升，都会带来巨大收益。
数据分析竞争者的特质 那么，集体来讲，分析型数据竞争者具有怎么样的特质呢？如同招聘时给出的工作描述，我们也可以给分析型竞争者做画像。
  数据竞争型选手应广泛应用模型和算法以及对应的最优化技术。例如作者之前实习的某普惠金融银行，通过最广泛的数据建模，给中小微个人提供贷款，赚大型银行看不上的钱，同时自己也很滋润。
  组织内部全面应用数据分析等相关技术。对各个流程进行数据分析、对各个环节进行建模以优化体验，减少流失。
  同时，也应该有自上而下的支持。如果一个企业的领军人物都不相信，那一线员工又何来的信任和执行力呢。企业老板应具备一些基础知识，同时有能够值得信任、不编造数据的专家。
  为什么它有效 说了现状说了要求，那为什么套措施有效呢？如果大家都有，那不就是没有差异化了吗？难道我们要搞军备竞赛吗？这不就和贩卖焦虑的自媒体一样的了吗？
其实不是这样的。一个身材羸弱的人和一个经常分析自己身体状态并针对性强化的人，他们外在的表现就会不一样。大部分企业在竞争中，使用的技术很相近，产品差别也不大；唯一能有差异化的，可能就是商业流程了。数据的挖掘分析，帮助企业家从流程中挤出每一滴价值。
尽管很多公司都有数据分析团队，但只有娴熟运用的公司，才能在各行各业取得霸主地位。甚至，对于如头条、亚马逊这样的公司，数据挖掘、算法已经成为了企业的名片和核心竞争力。
核心4条解决方案   合适的焦点、分析不可过于分散，免得失去焦点。
  合适的文化、小范围检验，最小可行产品验证。
  合适的人才、有分析能力且能深入浅出说明问题；有商业才能能够在商业角度阐述价值；以及沟通的技巧。
  合适的技术、数据储备、硬件支持，最终才会立于不败之地。
  最后，数据竞争型选手，如何说明他确实有效。很简单，以始为终点，检视最初的目标。</description>
    </item>
    
    <item>
      <title>用先知模型预测股市 Prophet in 000300 </title>
      <link>https://kuhungio.me/2019/prophet-in-000300/</link>
      <pubDate>Fri, 08 Mar 2019 22:48:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/prophet-in-000300/</guid>
      <description>跑步进场 最近股市大涨，不少人忙着跑步进场。作为保守型“投资者”，主投指数基金：沪深300。在这波行情 中，短短2个月，也有13%的账面收益。虽然知道指数类适合长期持有，但也好奇，这个点是否是高位了。为了解决这个疑虑。我们今天用算法模型套一套，看能否发现些什么。
时序预测的价值 时序问题的预测在生活中很常见。例如：游戏在线人数预测、消费情况预测、 O2O 的到店人数预测、交通流量预测，这些场景的精确预测，为资源的调配起到了重大的参考作用。从个体角度来说，得到的服务和体验也大大提升。
为此，Facebook 开源了一套工具 Prophet，专门用于时间学列预测。在这里，我们将用它，来一探股市究竟。
时序预测的原理 对于时间序列问题，常用的手法是时间序列的分解：这里有些类似于傅里叶变换的意味。将一个函数分解为多个规律函数的和积。时间序列的常见组成成分包括：季节项、趋势项以及噪声。在 Prophet 中，结合实际情况，他们又加入了节假日项目。之前在一次 kaggle 的比赛中，我们也发现节假日的数据波动，其实是类似于周末效应的。即：节假日的前后数据，类似于周六的前后数据。对数据进行修正后，评价指标会好很多。
 废话不多说，咱们开干。
Prophet in 沪深300 工具包安装 pip install fbprophet
数据准备与清洗 import pandas as pd import numpy as np from fbprophet import Prophet 数据准备
 数据来源为网易财经，沪深三百指数。  data = pd.read_csv(&amp;#39;../data/000300.csv&amp;#39;,encoding=&amp;#39;GB2312&amp;#39;) data.head() 数据清洗
 选取需要的数据，并对数据做 log / box-cox 变换，使数据更符合线性、正态分布，减少方差差异。经济系统和生态系统类似，都存在指数级增长现象，也存在饱和现象。我们这里采用 log 变换。  df = data[[u&amp;#39;日期&amp;#39;,u&amp;#39;收盘价&amp;#39;]] df.columns = [&amp;#39;ds&amp;#39;,&amp;#39;y&amp;#39;] df[&amp;#39;y&amp;#39;] = df[&amp;#39;y&amp;#39;].apply(lambda x: np.log(int(x))) 模型拟合与预测 简单定义，然后拟合。
m = Prophet() m.</description>
    </item>
    
    <item>
      <title>机器学习落地需攻破的9个难题 The Next Step for Machine Learning</title>
      <link>https://kuhungio.me/2019/the-next-step-for-machine-learning/</link>
      <pubDate>Sun, 24 Feb 2019 23:31:58 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the-next-step-for-machine-learning/</guid>
      <description>机器学习在前两年的时间里，一下子就爆火了起来。很多公司也跟着这个趋势，招募了很多算法工程师、数据挖掘工程师。但是，在实践中，企业发现要落地，实际上还有很多问题需解决。以至于在大部分项目，还是规则主导。算法工程师的日常，也不过是清洗数据，调整规则。所以，机器学习技术，在真实的应用中到底缺少些什么呢？
在国立台湾大学《机器学习》2019春季班，李宏毅老师给出了他的观察。以下的内容，结合李老师的最新讲义、加上我本身工作的理解，给大家梳理机器学习落地急需解决的9个难题。
拒绝回答与可解释性（哲学层面） 1. Anomaly Detection 机器能不能知道“我不知道” 机器能不能知道自己的识别范围，还是说生硬地给出模型内的东西，或者说抛出无法识别。在猫狗分类里，现有的模型已经到达很高的精度，甚至能给出猫狗的品种。
但是正式上线后，用户真的会乖乖给到猫狗的图片吗？如果用户丢一张妹子图，机器能够知道自己不知道吗？目前这个领域的研究叫做 Anomaly Detection。知道自己不知道，对于一些异常的情况，十分重要。
2. Explainable AI 说出为什么“我知道” 神马汉斯的故事：
18世纪德国，一匹名叫汉斯的马成为当地网红。他能够计算简单的算术题，并用蹄子敲出正确回答。这在当时一度引起轰动。后来，有人做了个实验，把汉斯和周围的人完全隔绝，这匹马就完全蒙圈了。时事证明，这匹马的神奇能力不在于他的算数能力，而在于他的观察能力。当给到正确答案时，周围的人会有不一样的反应，汉斯也就随即停止敲马蹄。
机器学习的成果，是否同汉斯一样，通过一些意想不到的渠道，获得的答案。在 GCPR 2017 Tutorial 的研究中，研究者通过注意力机制，研究机器判断的依据。
实验者测试了两个模型，两个模型均为马匹识别。DNN 模型的焦点集中在马匹身上，是一个正常的模型。但 FV 的交点却集中在图片左下角。原来，图片的左下角有图片的出处，所有的包含马匹的图都有这个标记。所以，FV 模型学到的重点在于这些标记。同样的表现，却是不一样的判断依据。显然，FV 模型的判断依据是滑稽和不可靠的。
我们需要一些技术，让 AI 不仅给出结果，同时要给出判断的依据。即：模型的可解释性。
抵御恶意攻击 3. 防止 Adversarial Attack 人有错觉，机器是否也会有错觉。我们来做一个认知实验。以下两个圈圈，哪个的颜色更深？好，记住你的答案。结果将在稍后揭晓。
对于机器，有研究表明，通过改变图像中的个别像素，可以起到迷惑机器的作用。改变一个像素，就可以让模型的判断结果从熊猫到长臂猿。该技术名叫 Adversarial Attack。
这样的技术相当危险。举个例子，当自动驾驶的车辆行驶在路上时，可能路边的人挥舞下旗子，机器的判断就会被干扰，做出不当的举动。
回到开头的例子，正确答案是左边。这其实是一个计中计。你以为这是视觉认知实验，其实这也是某种形式的“心理攻击”。 学习模式 4. Life-long learning 终身学习 终身学习是一个人类行为的概念。活到老学到老，大家都知道只有不断更新自己的知识，才能跟上社会发展的步伐。同时呢，先前学到的东西，对后面的学习仍有帮助。举个例子：学完线性代数之后，对学习和理解机器学习就大有帮助。
但是，机器不一样。今天的我们，一般只让一个模型学习一个任务。但这样会存在一些问题。首先是随着建模的增多，模型数量将无限增长。其次，模型之前学到的技能，对之后的学习没有帮助。就像 Alphastar 它玩星际争霸很棒，但让他同时学下围棋，目前来说是不行的。它和 Alphazero 是两个不同的模型 。
那么，自然而然的，我们就会抛出这样一个疑问，机器能否终身学习呢？这里的相关研究，提个关键词 Catastrophic Forgetting 。
5. Meta-learning / Learn to learn 学习如何学习 现有的机器学习模型设计，都遵循着这样一个范式——在特定领域人工设计一套算法，让机器去学习。我们就想，能不能设计一套算法，让机器自己去设计自己的学习算法呢？
这样的范式，我们称之为 meta-learning 元学习，或者叫 learn to learn，学习如何学习。</description>
    </item>
    
    <item>
      <title>中文语料的 Bert 微调 Bert Chinese Finetune </title>
      <link>https://kuhungio.me/2019/bert-chinese-finetune/</link>
      <pubDate>Sun, 17 Feb 2019 11:30:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/bert-chinese-finetune/</guid>
      <description>Finetune Bert for Chinese NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。
Bert 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 Bert as service 代码的开源，使用 Bert 分类或阅读理解的副产物&amp;ndash;词空间，成为一个更具实用价值的方向。
因而，此文档着重以一个例子，梳理 finetune 垂直语料，获得微调后的模型 这一过程。Bert 原理或 Bert as service 还请移步官方文档。
依赖 python==3.6 tensorflow&amp;gt;=1.11.0 预训练模型  下载 BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  数据准备  train.tsv 训练集 dev.tsv 验证集  数据格式 第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。
fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!... houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客... game	赛季末用他们两天上一段，7.20最强LOL上分英雄推荐！ 各位小伙... 样例数据位置：data</description>
    </item>
    
    <item>
      <title>What is Data Mining 什么是数据挖掘</title>
      <link>https://kuhungio.me/2019/what-is-data-mining/</link>
      <pubDate>Sun, 17 Feb 2019 00:40:20 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/what-is-data-mining/</guid>
      <description>一、数据挖掘的定义 什么是数据挖掘？  数据挖掘是一个用数据发现问题、解决问题的学科。 通常通过对数据的探索、处理、分析或建模实现。  数据挖掘学习路线  大学里并没有数据挖掘这么一个专业，现有的数据挖掘工程师大都来自工科或统计学等专业。 目前的数据挖掘工程师大都来自不同背景，计算机科学、数学甚至是机械工程。要想成功胜任，其诀窍是热情、好奇心，不断学习新的工具的能力，以及对数据清洗和分析的耐心。  给新人的建议  最重要的三个品质：好奇心、是非观以及批判性思考。这三个品质，放在其他领域同样适用。 专业领域的三种能力：编程能力、统计基础、商业思维。编程和统计在大学较为容易学到，商业思维需要多实践总结。  二、数据挖掘在做什么 数据挖掘工程师的一天  检查日常报表数据是否异常，寻求数据波动的合理解释。 针对新业务，设计指标，搭建数据模型。 搭建商品推荐系统、价格预测系统、文本分类系统或是聊天机器人。  数据挖掘的算法  使用复杂的机器学习算法并不能保证效果。一般来讲，最好的解决办法，通常很简单。 生产环境使用简单的算法，并不意味着要放弃前沿算法。每一套新的方法，其目的都在解决前面的薄弱之处。  数据挖掘与服务器  本地 PC 由于硬件与系统限制，工程师常在服务器进行大规模数据的运算、脚本部署与接口部署。  三、商业中的数据挖掘 作为公司，该如何开展数据挖掘  评估可能的收益与需要的投入 开始收集数据 招募数据挖掘团队  招聘数据挖掘团队  好奇心应该是数据挖掘从业者的最重要品质。 招聘时，应确保候选人对工作内容感兴趣。 候选人应具备一定的成果意识。商业更重成果，而不是过程。  数据挖掘应用  广告位点击预估 信用卡风控评估 用户流失干预  四、数据挖掘工具 数据挖掘工具与大数据  掌握以下工具：Python、Linux、Pandas 及 Jupyter、关系型和非关系型数据库。 大数据通常指传统数据系统无法处理的数据。体量和增速都相当大。处理工具以 Hadoop 为代表。  五、数据挖掘进阶 神经网络和深度学习  神经网络出现已数十年，但由于条件限制，这一方向搁置了数十年。目前随着新的优化方法的出现和算力的提升，这一方向的工业化逐渐成为可能。  如何更上一层楼  掌握基本的编程知识，更多地去理解背后的原理。 流程化意识，及时复盘总结，规范流程（复用）。 成果导向，将知识转化为行动和成果，给他人带来价值，服务更多人。  </description>
    </item>
    
    <item>
      <title>Add SSL to Your Websites</title>
      <link>https://kuhungio.me/2019/add-ssl-to-your-websites/</link>
      <pubDate>Mon, 28 Jan 2019 00:32:18 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/add-ssl-to-your-websites/</guid>
      <description>https://poplite.xyz/post/2018/05/03/how-to-enable-https-for-custom-domain-on-github-pages.html
https://www.v2ex.com/t/451406</description>
    </item>
    
    <item>
      <title>12306Bypass Server 抢票神器&#43;微信提醒</title>
      <link>https://kuhungio.me/2019/12306bypass-server/</link>
      <pubDate>Sat, 26 Jan 2019 15:52:08 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/12306bypass-server/</guid>
      <description>前言 春节假期临近，车票一度紧张。某行、某团开了加速包后，仍然无法第一时间刷到目的地的票。稍微有点儿技术底子的我们岂能坐以待毙，自然是要自己动手，丰衣足食。
网上有各类开源的工具包，这里不做过多点评。之前在好友圈内传得比较靠谱的是 12306Bypass，又叫分流。分流是一个 Windows 应用，工作在 PC 端。其核心功能完全免费，更更重要的是，它的监控刷新在本地可以真实的感知。
以前在学校还好，可以守在电脑面前。但工作后，由于各种原因，无法第一时间获取分流的抢票信息，因而白白错过好几次下单付钱的机会。于是我们就有了这样一个愿望，希望能将分流的信息第一时间转发。
前几日逛某论坛，有人向分流开发者传达了增加 Server 酱的请求。开发者还是很给力，在最近的几次版本迭代中实现了该功能。简单的来说，Server 酱就是一个提醒服务。在这里，我们把它用在抢票软件中。当软件抢到票时，通过该服务，给到微信提醒。通知我们及时付款。
通过这样的形式，即可在微信端第一时间收到下订单的信息。那么如何配置这样的一个服务呢？我们只需要以下步骤。
​
准备工作  最新版本的分流软件 搜索关键词：12306Bypass  这里使用的版本号是1.13.30。 没用过？下载链接   Github 账号 这里用做 Server 酱的登陆认证  不知道？注册链接    实操阶段 Server 酱 用于获取认证的接口
 登入：用GitHub账号 登入网站，获取SCKEY（在「发送消息」页面） 绑定：点击「微信推送」，扫码关注同时即完成绑定  记住 SCKEY ，我们接下来会用着。
分流   启动分流，按正常流程配置票务信息。
  点选主界面左下角的推送
  填入以下信息
 通知地址 `https://sc.ftqq.com/[SCKEY].send 通知参数 text=#bypass#    点击测试发送，即可在微信端，收到本文一开始的推送测试提醒啦
  实际效果 就在配置完成不久后，分流帮我抢到了回家的车票。同时在微信端，Server 酱强制推送。</description>
    </item>
    
    <item>
      <title>速查表 | Linear Algebra and Calculus 线代与微积分</title>
      <link>https://kuhungio.me/2018/algebra-calculus/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/algebra-calculus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>速查表 | Probabilities Statistics 数理统计</title>
      <link>https://kuhungio.me/2018/probabilities-statistics/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/probabilities-statistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>为啥说数据这行不容易 Why is Data Hard </title>
      <link>https://kuhungio.me/2018/why-is-data-hard/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/why-is-data-hard/</guid>
      <description>原文链接 Slack 工程师 : why-is-data-hard?
做数据挖掘时，常常需要考虑很多方面。其中一个方面，常常会涉及到跨功能，复杂且琐碎的一些事项。数据准备以及评价指标的制定，就是这些事项之一。
等等，似乎干数据这一行，并不容易？
当大多数的组织谈到数据时，他们想的其实是指标——能反应近期业务、或是能够提供数据驱动的决策、抑或是能够监测企业经营状况的指标。
按上面的说法，我们应该能够招聘到聪明且能干的分析师，做出酷炫的可视化仪表盘，并马上投入使用。
 “Every second of every day, our senses bring in way [more] data than we can possibly process in our brains.”&amp;ndash; Peter Diamandis, Founder of the X-Prize
 拥有大量的数据并不会立马产生价值。当你是在数据增长快如 Slack 这样的公司处理数据时，不仅怎样驾驭数据和指标极其重要且困难的，更困难的是你像是在 “building the plane as it is flying”。
数据金字塔：评价指标（metrics）最为重要 数据金子塔大致可以分为4个级别。每一个级别都高度依赖下一级。
见解/洞察（Insights） 大部分的老板和公司董事关心的是这一层。见解（Insights）是我们所讲的关于数据的故事，即什么驱动了商业，或者是有什么新的机会能够推动大量的增长。
在理想的世界中，有一个共享的、不断演进的关于业务性能的数据叙述。这种数据叙述在整个组织中传播，以建立对业务的共同理解。
探索以及工具 为了获得见解，我们需要雇佣很多人定期去探索数据。只有当有人在盯着数据的时候，才能有策划和故事!
在快速增长的业务中，最优的数据探索涉及到一些关键事物：
  **数据探查的多样性。**要真正建立起，对正在发生的事情和重要的事情的理解和见解，我们需要每个人都拥有，对数据的关注和探索的主人翁意识。现实情况是，如果探索困难，只有管理员(分析师)能够完成这项工作。你要么雇佣更多的分析师来深入挖掘你的见解，或者，你可以找到简化数据访问的方法，让团队能够自行解决问题。Slack 的做法介于两者之间——我们不断寻找，在整个组织中增加自助数据服务的方法；同时也确保，我们有优秀的分析师参与到每一个核心功能来。
  **频繁使用。**像所有良好习惯的养成一样，查看数据和指标的一致性，是建立对所期望东西见解的唯一方法，什么样的结果是出乎意料的，什么样的问题是需要分析数据的。分析师可以帮助挖掘趋势，有些趋势值得挖掘，而许多趋势则不然。如果老板经常查看数据，那么你的分析师就更有可能对他们的精力，进行最优配置。
   **例子：**本周活跃用户增加了4%。这是好是坏？是预期的增长放缓?还是因为这周，我们推出了新产品，所以实际上我们希望的是，高于平时一周的增长?
分析师能够挖掘并做出各种比较，以帮助老板对数字进行说明。分析人士可以将该数字与往年做比较，深入了解这些新要素的组成，以及他们来自哪里。也许4%符合你的期望。但事实上，它比平时要低，我们没有推出任何新产品，且处于一个缓增长放缓期。这就是您希望董事会和分析人员构建的见解。你不会希望在某些事情上耗费精力，这些事情并不会带来业务的增长，或者改变我们的决策。
  **发现能力与数据探索。**数据探索不同于在仪表盘上点来点去，这是我想在这里指出的。仪表盘是用一组具体的需求创建的，通常在特定的粒度级别上报告指标或世界的某些视图。数据探索是一种能力，即通过各种不同的特征结合来调查指标，以确定在固定的仪表盘中不会立即出现的趋势或机会。可以将其考虑为，能够对数据进行转换和筛选，从而向监控之外的数据提出问题的能力。看到活跃用户的激增吗？太棒了！也许我们需要探究这在所有国家都这样，还是仅仅出现在英国。那周我们是否发起了一项针对英国的营销行动？销售团队是不是在那周完成了一个大单子?  企业主离数据越近，他们就越有能力着手进行自助服务的探索，就能发现更快捷、更有效的关键见解。这是因为，他们更有能力将我们在业务中所做的事情，与我们在数据中可能表现的特点结合起来。反之亦然！那些从商业伙伴那里拥有大量业务背景的分析人士，可以更快地找到正确的见解，而不是身陷各种假设之中。对于一个快速成长的组织来说，你可能希望两者都存在于你的组织中，这样每个人都能带着主人翁意识，理解我们最大的机遇和存在的差距。</description>
    </item>
    
    <item>
      <title>一场 kaggle 比赛总结出的时间序列处理技巧 time series problem summary </title>
      <link>https://kuhungio.me/2018/time-series-problem-summary/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/time-series-problem-summary/</guid>
      <description>Source https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion
总结一：保证数据同分布 验证集的选取，分布上应尽量靠近测试集。
 方式一:：对抗验证集的生成。 方式二： 就近选取相同天数。 方式三:：类比属性。如本赛题 &amp;ldquo;golden week&amp;rdquo; 与 &amp;ldquo;new year&amp;rdquo; 类比，选取 &amp;ldquo;new year&amp;rdquo; 段作为验证集。  tips: kfold 用在时间序列上不合适，会有数据泄露风险。正确的方法应是滑窗。
总结二：异常值特殊处理 一些特殊的时间节点（或者说是异常值），应该予以特殊考虑。比如本次比赛中的 &amp;ldquo;golden week&amp;rdquo;.。需要对其进行变换，而不是直接依靠模型的预测结果。
 方式一:：等同法   The rules:
Treat holiday as Saturday
If the day before holiday is weekday ,treat the day before holiday as Friday If the day after holiday is weekday ,treat the day after holiday as Monday it work not only golden week but also a lot other holidays.</description>
    </item>
    
    <item>
      <title>Single Shot MultiBox Detector Keras version</title>
      <link>https://kuhungio.me/2017/ssd/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2017/ssd/</guid>
      <description>SSD目标检测Keras版 SSD是一种Object Detection方法。本文是基于论文SSD: Single Shot MultiBox Detector，实现的keras版本。
 该文章在既保证速度，又要保证精度的情况下，提出了SSD物体检测模型，与现在流行的检测模型一样，将检测过程整个成一个single deep neural network。便于训练与优化，同时提高检测速度。 SSD将输出一系列离散化（discretization）的bounding boxes，这些bounding boxes是在不同层次（layers）上的feature maps上生成的，并且有着不同的aspect ratio。
 模型效果  模型对载具的检测   模型对动物的检测   模型的视频检测  如何使用 项目地址kuhung/SSD_keras
所需依赖 cv2==3.3.0 keras==1.2.2 matplotlib==2.1.0 tensorflow==1.3.0 numpy==1.13.3 如果想跑通视频模块，则需额外pip install scikit-video
具体操作 git clone git@github.com:kuhung/SSD_keras.git cd SSD_keras  Download model weight weights_SSD300.hdf5here  cp weights_SSD300.hdf5 into SSD_keras  对于图片的检测  参考SSD.ipynb
 若要剪切图片为下一步处理做准备  参考SSD_crop.py
 检测视频  cd video_utils python videotest_example.py hy.</description>
    </item>
    
    <item>
      <title>yysGAN 生成对抗网络，在游戏角色生成中的尝试</title>
      <link>https://kuhungio.me/2017/yysgan/</link>
      <pubDate>Tue, 21 Nov 2017 09:02:35 +0800</pubDate>
      
      <guid>https://kuhungio.me/2017/yysgan/</guid>
      <description>使用GAN生成新的游戏角色 摘要 Generative Adversarial Networks（简称GAN），中文名叫生成对抗网络。我们将使用它，来生成新的阴阳师角色。 依赖 （pip install） cv2 tensorflow( &amp;gt;=1.0) scipy numpy 使用方法 cd yysGAN python yysGAN.py 5000次迭代训练结果 了解更多GAN的知识 Generative Adversarial Networks.ipynb
 参考资料  Siraj Raval moxiegushi/pokeGAN  项目地址 https://github.com/kuhung/yysGAN
定制你的GAN图片生成器 # 拆包即用，修改input下文件，改为对应的jpg素材即可。 </description>
    </item>
    
    <item>
      <title>Cats VS. Dogs 图像分类之猫狗大战</title>
      <link>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</link>
      <pubDate>Wed, 06 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</guid>
      <description>我是参加DataCastle猫狗大战的选手，kuhung。在测评中，我提交的数据集最后评分0.98639。以下是我的备战过程及心得体会。（最后有完整代码及较全面的注释）
个人介绍 华中科技大学机械学院的大二（准大三）学生，接触数据挖掘快有一年了。早期在学生团队做过一些D3数据可视化方面的工作，今年上半年开始数据挖掘实践。想把这个爱好发展成事业。做过阿里的天池竞赛，也有在kaggle混迹。算个数据新手，但一直不承认：你是新人，所以成绩不好看没啥关系。
初识比赛 第一次接触数据集，就感觉有些难度。因为以前没做过图片分类的比赛，更没想过要用深度学习的神经网络进行识别。思索一番，还是觉得特征提取后，使用决策树靠谱。自己也下去找过资料，发现并不容易实现。期间，还曾一度想过肉眼识别。但打开文件，看到那1400+图片，就觉得这时间花在肉眼识别上不值。中间一度消停。
初见曙光——yinjh战队分享 后来上论坛逛过几次。一次偶然的机会，让我看到了yinjh团队分享的vgg16模型。乍一看，代码简单、效果不错。更为重要的是，这个模型自己以前从未见过。于是抱着验证学习的态度，我把代码扣了下来，打算自己照着做一遍。
过程艰难 一开始，我就把一屏的代码放进了我的jupyter notebook中，一步一步试水。很明显，我的很多依赖包都没安装，所以也是错误不断。早先是在Windows系统下，使用python2.7，需要什么包，就安装什么包。在安装keras过程中，我发现了Anaconda——很好用的一个科学计算环境，集成了各种数据挖掘包。即使是这样，仍然是满屏的错误，亟待排查。
步步优化 离比赛截止就还只有几天，一边准备期末考试，一边焦急地排查bug。Windows系统下仍有个别难以解决的错误，我索性切换到了做NAO机器人时装的Ubuntu系统下。结合keras给的官方文档，我对原代码进行了函数拆分解耦，又在循环体部分增加了异常检测。综合考虑性能，稍微修改了循环结构。下载好训练的vgg16_weights，在没有错误之后，焦急地等待25分钟后，屏幕开始打印结果。
欣喜万分 第一次提交，随便截取了前面一段，没成绩。折腾了几次，才发现是提交的格式出了问题。后面取p=0.99+部分，提交结果在0.58左右，数据集大概有90个。估计了下，狗狗总数应该在180左右。第二次提交，取了180左右，结果0.97多一点。第三次，也是最后一次提交，取了result前189个，结果0.98639，一举升到第一。
 比赛总结 这次比赛，首先还得感谢yinjh团队的yin前辈。如果没有您分享的代码，就不会有我今天的成绩。感谢您分享的代码，感想您在我写这篇分享时提供的代码指导。 我是新手，但我一直不觉得成绩低是理所当。立志从事这一行，就需要快速地学习、快速地成长。新人，也需要做到最好。当然，自己目前还存在很多问题。一些基本的概念只是模糊掌握，需要更多的实践，需要更多的理论积淀，而不是简单地做一个调包侠。
给新手的建议  善用搜索引擎，多读官方文档，不要一开始就依赖Google。 Google Groups、Stack Overflow、GitHub是好东西。 干！就是干！   完整代码  以下操作均在Ubuntu14.04+Anaconda中进行  导入python标准包 import os # 处理字符串路径 import glob # 用于查找文件 导入相关库   keras
  keras是基于Theano的深度学习(Deep Learning)框架
  详细信息请见keras官方文档
  安装过程  conda update conda
  conda update &amp;ndash;all
  conda install mingw libpython
  pip install git+git://github.</description>
    </item>
    
    <item>
      <title>高效能人士的7个习惯</title>
      <link>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</link>
      <pubDate>Sun, 10 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</guid>
      <description>第一部分：认识自我  一切探索的尽头，就是重回起点。——艾略特
 以原则为中心的思维  公平的原则 诚实与善良  以原则为中心，以品德为基础  由内而外强调，先追求个人的成功，才能有人际关系的成就;先信守对自己的承诺，才能信守对他人的承诺。  七个习惯&amp;ndash;大纲  习惯一：积极主动（BE PROACTIVE) 习惯二：以终为始(BEGIN WITH THE END IN MIND) 习惯三：要事第一(PUT FIRST THINGS FIRST) 习惯四：双赢思维(THINK WIN) 习惯五：知彼解己(SEEK FIRST TOUNDERSTAND,THEN TOBE UNDERSTOOD) 习惯六：统合综效(SYNERGIZE) 习惯七：不断更新(SHARPEN THE SAW)  习惯的定义
  习惯：知识，技巧，意愿    成熟模式图（成长三阶段）
   阶段：依赖、独立、互赖    有效性的定义
   效能：产出与产能必须平衡(P/PC balance)   第二部分：个人的成功：从依赖到独立 习惯一：积极主动  最令人鼓舞的事实，莫过于人类确实能主动努力以提升生命价值。&amp;mdash;-卢梭
 三种决定论  基因决定论 心理决定论 环境决定论  人类的四种天赋  选择的自由(freedom to choose) 想象力(imagination) 良知(conscience) 独立意志(independent conscience)  积极主动是人类的天性</description>
    </item>
    
    <item>
      <title>产品实践之应用沉淀</title>
      <link>https://kuhungio.me/1970/web_deploy/</link>
      <pubDate>Thu, 01 Jan 1970 23:44:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/1970/web_deploy/</guid>
      <description>   项目地址 简介 相关资料 参考     以图搜图 上传图片，检索图库内容，返回最相似图片 自制以图搜图引擎 matsui528/sisFlask补充系列–将应用部署在Heroku上   spam 文本检测 输入英文文本，检测是否为垃圾营销内容 机器学习建模与部署&amp;ndash;以垃圾消息识别为例 kuhung/flask_vue_MLsingle-page-apps-with-vue-js-and-flask-deployment   机器学习系统设计测试题 高级软件工程师需要掌握系统设计，高级机器学习从业者同样如此 机器学习系统设计原则 10个机器学习系统设计案例chiphuyen/machine-learning-systems-design    </description>
    </item>
    
  </channel>
</rss>