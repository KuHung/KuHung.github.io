<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/posts/</link>
    <description>Recent content in Posts on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 20 Apr 2019 14:31:26 +0800</lastBuildDate>
    
	<atom:link href="https://kuhungio.me/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>机器学习模型部署--打通前后端任督二脉</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>前言 学历与定位 近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个小本就工作的人，没有较为丰富的实战经验，有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。
模型算法的实用主义 机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。
 关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。
 这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 kuhung/flask_vue_ML
后端 flask 相关依赖的安装 pip install -r requirements.txt
核心函数  导入函数包  from flask import Flask, jsonify, request from flask_cors import CORS # 做跨域的准备 from flask import session # 追踪客户端会话 from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类 from flair.data import Sentence   准备工作  app = Flask(__name__) # 声明准备 app.</description>
    </item>
    
    <item>
      <title>如何设计一套类似视觉中国鹰眼的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”
 2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。
 “鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。
爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。
首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。
基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。
首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。
从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。
第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。
而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：教 AI 学会看图说话：Image Caption。
总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。
这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。
最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。
附录 视觉中国图片侵权追踪系统曝光：鹰眼系统
2018年度市科委第四季度项目(课题)验收公开清单
视觉（中国）文化发展股份有限公司 2016 年年度报告
《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋
《基于内容的图象和视频检索》</description>
    </item>
    
    <item>
      <title>Hands On Machine Learning in Industry 一文看懂机器学习项目的完整生命周期</title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。
机器学习项目的生命周期 问题定义
定义问题，并关注大局  数据处理
获取数据 探索性的数据分析 清洗数据，为接下来的模型做准备  模型方案
探索不同的模型并挑选合适的模型 对模型进行微调，并集成为更好的模型 解决方案呈现  部署维护
部署、监控并维护系统    定义问题，从大局出发  和业务团队一起定义问题目标 我们的解决方案将会如何发挥作用 现在的解决方案是什么样的（如果有） 你将如何定义这个问题（有监督、无监督，在线还是离线） 结果该如何衡量 衡量方法是否和商业目标一致 要达成这一目标，至少的表现该是什么样子的 类似的问题是什么？有无可复用的经验与工具 我们有专家知识吗 你将如何着手解决这个问题 列出你或者别人目前所作的努力 如果可能，对假说进行验证  获取数据 建议：尽量自动化以更容易地方式获取最新的数据
 列出你所需的数据以及体量 找寻并记录下获取数据的方式 检查数据将占据多少空间 检查是否有法律风险，如有必要请获得许可 获取许可 创建工作空间，确保存储足够大 获取数据 转换数据的格式以便能够方便操作（不需要改变数据本身） 确保敏感信息被删除或保护加密（匿名） 检查数据的大小和类型（时间序列、采样、地理信息等） 划分测试集，把他放一边，并且不再去动他（防止数据泄露）  探索数据 建议：在该阶段尽量获取领域专家的意见
 创建数据的副本以便做数据探索（如果数据量太大，做降采样处理） 创建 Jupyter notebook 以便保存探索记录 研究每个属性及其特征  名称 类型（类别，整型/浮点，有无上下界，文本，结构化等） 缺失值 噪声数据（随机数，异常值，四舍五入的误差） 对本任务可能有用的数据 分布类型（高斯分布，均匀分布，指数分布）  对于有监督问题：确定目标对象 可视化数据 研究变量间的相关性 研究你将如何着手解决此问题 确认比较有希望的解决方案 确认有用的外部数据 将以上信息存档记录下来  准备数据 建议：</description>
    </item>
    
    <item>
      <title>Slack gpt2 Bot 机器人写文已经到了如此地步？邀你一同测评史上最强 GPT2 模型</title>
      <link>https://kuhungio.me/2019/slack-gpt2-bot/</link>
      <pubDate>Mon, 25 Mar 2019 22:36:06 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/slack-gpt2-bot/</guid>
      <description>记得在校的时候，某岩做过一个app，讲接龙故事的。类似于我写一段，另一个人写接下来的一段，最后凑成一个完整的故事。当时，可产生了不少有意思的段子。最近，GPT2 模型的发布，让人不禁想到，有没有可能让机器来完成这个任务呢？机器写十四行诗、机器写莎士比亚风格的文章，机器写对联，这些都已经成为了现实。人工智能虽然没有带来突飞猛进的质变，但着实催生了很多有意思的小玩意儿。对于GPT2，一个字概括来说就是：壕——数据量大，算力能够 cover 住。这套算法模型网罗了几乎现有的所有文本数据，成功“过拟合“地屠榜，刷新多个 NLP 任务榜单排行。作者为了预防滥用模型、同时让别的研究者能够有个初步地认识，开源了一个小一些地模型。该模型的能力之一，就是我们今天的主题：接着别人地话写故事。今天我们要通过算法来实现。
虽然作者有在尽力简化复现难度，但对于很多不是这行的人，让他去敲命令行来走完整个流程，还是困难重重。能够将深奥的原理讲给普通人听，并且简单易懂，是一项科学传播的必备能力。做为技术向的工程师，在产品处于雏形阶段时，能够通过一个 MVP 最小价值产品，实现核心功能，也是一项大大的加分项。对于今天的任务，我们选取容易上手，接口丰富的 slack 作为我们的前端交互窗口。
如何构建一个 MVP 产品；或者具体的来讲，在我们的这个任务中，如何将数据挖掘工程师的模型成果，转化为可落地、可感知的产品或服务呢。操起斧子直接开干，依葫芦画瓢撸个前后端出来吗？这，其实是很多技术人员的一个误区——认为什么都可以从技术层面解决，”少废话别bb，bb is cheap，show me the code“。但从一个商业产品或服务商的角度来看，客户与渠道是前台，我们的客户是谁、如何触达客户以及选用何种渠道维系客户，是一个一开始就要考虑的事情。
以这个 GPT2 bot 为例，我希望的客户是对 GPT感兴趣，但又没基础去折腾的学生或是其他领域的人士，抑或是没时间去跑 demo 的专业同行。如何触达客户：你看的这篇文章的平台，就是我的触达媒介。我最后选择用 slack 交付我的服务，而不是 qq 或 微信，是因为他成本更低，虽然阻挡了部分潜在客户，但权衡后是可以接受的。最后的工作才是依葫芦画瓢，照撸一个出来。本文参照了EdwardHuCS,并在其基础上做了部分改动。
虽然这波 AI 热潮，让很多像我这样的非科班得以上车。但在实际生产环境中，我们还是暴露了诸多问题。其中之一，便是工程能力薄弱。会写 SQL 、会手推算法、会调包，但是就是不会写能跑的整个小系统。在业务变化快的公司中，这可能不是一个好事情。你的模型也许还在细调参数，但突然整个业务就没了。如果你能拿出一个能跑的马儿，兴许能影响这个业务。这就是前面提到的加分项。
言归正传，我们回到在slack上面。我们的核心就以下代码：
核心代码解读 导入一些基础配置
import os import time import re from slackclient import SlackClient import sys from gpt2.src import generate_unconditional_samples # instantiate Slackk client slack_client = SlackClient(&#39;&#39;) # 认证口令 # starterbot&#39;s user ID in Slack: value is ssigned after the bot starts up starterbot_id = None  延迟配置以及样例和匹配模式</description>
    </item>
    
    <item>
      <title>Competing on Analytics 凭什么打败竞争对手？基于数据、基于分析的商业竞争</title>
      <link>https://kuhungio.me/2019/competing-on-analytics/</link>
      <pubDate>Tue, 12 Mar 2019 10:48:59 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/competing-on-analytics/</guid>
      <description>数据科学家这个职位，随着12年的哈佛商业评论的一篇文章，成为了21世纪“最性感的职业”。这年头，越来越多的年轻人开始往这个方向奔，市场几近饱和。但是，很少有听见企业家说：“是的，我们很需要数据工程师，因为以下原因&amp;hellip;“对于看此文的老板们，你们是否不止一次听到媒体鼓吹大数据、鼓吹机器学习、鼓吹人工智能，却很少有听到说这些东西，对于企业来说，实实在在带来了什么。如果你的答案是“Yes”，那么这篇文章将解答你的疑惑。
本文论点主要取自 Thomas H. Davenport 文章 《Competing on Analytics》，试图从企业管理的角度，阐述为什么我们需要数据科学家（或者说广义的数据相关人员）；他们能给企业带来哪些切实的好处；以及作为企业家，我们该如何转型，如何拥有更强的竞争力。
同质化的市场危机 在当下，想依靠某个新奇的点子或者是产品服务，已经不大可能再和其他竞争者区分开来。作为一个人类组织，底子里仍保留有人类的天性。人类天生就爱模仿，从一出生模仿吃东西，到后面通过模仿习得语言，再到后面的学习。人类的本质可能就是个复读机。模仿可以说保证了我们人类种族的存在与延续。对于企业来说，也大抵相同。
尽管我们知道，从道德原则上讲，大企业模仿别的东西是不对的。但是，从商业利益角度，无数的事实告诉我们，模仿，对于企业来说真的是一个大概率稳赚不亏的事情。把市面稳定的产品拿来微创新，再加持自己的人力或渠道优势，很快就能回本。保不齐也能把竞争对手耗死。现实即是如此。
比你更有利的竞争对手 越来越多的产品、服务开始同质化。无论互联网、游戏、手机或是制造业、服装业，越成熟的领域这个现象越明显。与此同时，我们的竞争对手可能在东南亚，拥有更低的人工成本；可能在不规矩的私营企业，拥有更多免费加班的程序员；也可能是腾讯头条这样的大厂，控制着大部分渠道。那么，你的产品服务，凭什么脱颖而出？
答案就是成为分析型竞争者
数据分析竞争者在干什么 数据分析型竞争者会做以下几个事情。
用户 通过分析，去洞察客户的需求，以及他们所愿支付的价格，找到他们保持忠诚度的原因。在商业模式中，客户是我们的直接服务对象，也是收入来源。那么，势必需要搞清楚客户的数据情况。
在当下，比较流行的技术是通过用户画像技术，去刻画我们的用户群体。用户的分布地域、用户的性别以及年龄，用户的偏好。只有这些东西都搞清楚，我们才能清楚的知道我们的客户是谁，为什么他们需要我们的服务或产品。
渠道 与此同时，也要分析我们触达用户的渠道。不得不说，发明电视黄金档广告的人，一定是个商业奇才。曾几何时，电视广告和路标广告曾是众多老板的竞相争夺的资源，屡屡出现标王，一次次刷新记录。在那个时代，只要你砸钱，拿到黄金时间的广告，就是稳赚不赔。但现在不一样了，各种互联网渠道，在抢占着人们的注意力。楼宇电梯广告、站台路牌广告各种花样层出不穷。
但是，你就真的清楚该投哪一个了吗？还是听信对方销售人员一阵天花乱坠的吹嘘，就乖乖交了钱，却得不到想要的转化效果？通过适当的分析，我们可以知道用户在哪些渠道对我们的响应度最高，知道哪些渠道可以带来更高的转化，从而优化我们的渠道成本投入。
举个我自己的例子：我的文章隔几天就会发一篇，分布在不同渠道：微信、知乎、头条、掘金、简书。那我是单单为了占坑防洗稿就完事了吗？不是的，作为一个数据挖掘工程师，我会分析各个渠道带来的阅读、关注和互动，从而调整渠道策略。
目前我就发现，知乎和头条的信息流产品在分发策略上做的很不错，能保证充分的曝光。微信适合做核心粉丝的沉淀，和粉丝去探讨交流一些问题。而掘金、简书的曝光有限，那我就会在更新是把他们往后放。
那是不是我就应该放弃简书掘金了呢？也不是的。通过分析我发现，掘金在谷歌搜索的排名占比靠前，简书在百度搜索的排名靠前，他们俩实际是很好的 SEO 流量优化渠道。这就是渠道分析的效果。
人力 通过分析，去计算员工对公司利润做出的具体贡献，而不仅仅是关注薪酬成本。以前的自己觉得，买东西或是做事情，先去看成本是多少。工作后发现，领导的视角不是这样的。成本对于老板们来说，只是个数字。他们更关心做事的投入产出比。对于员工问题也是这样。
但现实不是这样的。很少有公司会关注这名员工对利润的贡献，反而更多的去关注他的成本是多少。他今天996了没，没有996对不起我给他开的价钱，而丝毫不关心员工对公司利润所做的贡献。而另一个极端就是，有些老板觉得这类人便宜，从而养了很多闲人。这两种情形虽然短时不会给企业带来多大负面影响，但你的竞争性选手，已经在利用数据，去发现员工的价值贡献，并对人事招聘进行调整了。
库存 在实业中，我们还要追踪现有的库存，预测并分析需求量，减少库存的积压，提高现金流转效率。这里主要是对重资产的企业老板，如果你能在这其中发现机会，一个点的提升，都会带来巨大收益。
数据分析竞争者的特质 那么，集体来讲，分析型数据竞争者具有怎么样的特质呢？如同招聘时给出的工作描述，我们也可以给分析型竞争者做画像。
 数据竞争型选手应广泛应用模型和算法以及对应的最优化技术。例如作者之前实习的某普惠金融银行，通过最广泛的数据建模，给中小微个人提供贷款，赚大型银行看不上的钱，同时自己也很滋润。
 组织内部全面应用数据分析等相关技术。对各个流程进行数据分析、对各个环节进行建模以优化体验，减少流失。
 同时，也应该有自上而下的支持。如果一个企业的领军人物都不相信，那一线员工又何来的信任和执行力呢。企业老板应具备一些基础知识，同时有能够值得信任、不编造数据的专家。
  为什么它有效 说了现状说了要求，那为什么套措施有效呢？如果大家都有，那不就是没有差异化了吗？难道我们要搞军备竞赛吗？这不就和贩卖焦虑的自媒体一样的了吗？
其实不是这样的。一个身材羸弱的人和一个经常分析自己身体状态并针对性强化的人，他们外在的表现就会不一样。大部分企业在竞争中，使用的技术很相近，产品差别也不大；唯一能有差异化的，可能就是商业流程了。数据的挖掘分析，帮助企业家从流程中挤出每一滴价值。
尽管很多公司都有数据分析团队，但只有娴熟运用的公司，才能在各行各业取得霸主地位。甚至，对于如头条、亚马逊这样的公司，数据挖掘、算法已经成为了企业的名片和核心竞争力。
核心4条解决方案  合适的焦点、分析不可过于分散，免得失去焦点。
 合适的文化、小范围检验，最小可行产品验证。
 合适的人才、有分析能力且能深入浅出说明问题；有商业才能能够在商业角度阐述价值；以及沟通的技巧。
 合适的技术、数据储备、硬件支持，最终才会立于不败之地。
  最后，数据竞争型选手，如何说明他确实有效。很简单，以始为终点，检视最初的目标。</description>
    </item>
    
    <item>
      <title>Prophet in 000300 我把算法模型套在了股市上，发现...</title>
      <link>https://kuhungio.me/2019/prophet-in-000300/</link>
      <pubDate>Fri, 08 Mar 2019 22:48:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/prophet-in-000300/</guid>
      <description>跑步进场 最近股市大涨，不少人忙着跑步进场。作为保守型“投资者”，主投指数基金：沪深300。在这波行情 中，短短2个月，也有13%的账面收益。虽然知道指数类适合长期持有，但也好奇，这个点是否是高位了。为了解决这个疑虑。我们今天用算法模型套一套，看能否发现些什么。
时序预测的价值 时序问题的预测在生活中很常见。例如：游戏在线人数预测、消费情况预测、 O2O 的到店人数预测、交通流量预测，这些场景的精确预测，为资源的调配起到了重大的参考作用。从个体角度来说，得到的服务和体验也大大提升。
为此，Facebook 开源了一套工具 Prophet，专门用于时间学列预测。在这里，我们将用它，来一探股市究竟。
时序预测的原理 对于时间序列问题，常用的手法是时间序列的分解：这里有些类似于傅里叶变换的意味。将一个函数分解为多个规律函数的和积。时间序列的常见组成成分包括：季节项、趋势项以及噪声。在 Prophet 中，结合实际情况，他们又加入了节假日项目。之前在一次 kaggle 的比赛中，我们也发现节假日的数据波动，其实是类似于周末效应的。即：节假日的前后数据，类似于周六的前后数据。对数据进行修正后，评价指标会好很多。
废话不多说，咱们开干。
Prophet in 沪深300 工具包安装 pip install fbprophet
数据准备与清洗 import pandas as pd import numpy as np from fbprophet import Prophet  数据准备
 数据来源为网易财经，沪深三百指数。  data = pd.read_csv(&#39;../data/000300.csv&#39;,encoding=&#39;GB2312&#39;) data.head()  数据清洗
 选取需要的数据，并对数据做 log / box-cox 变换，使数据更符合线性、正态分布，减少方差差异。经济系统和生态系统类似，都存在指数级增长现象，也存在饱和现象。我们这里采用 log 变换。  df = data[[u&#39;日期&#39;,u&#39;收盘价&#39;]] df.columns = [&#39;ds&#39;,&#39;y&#39;] df[&#39;y&#39;] = df[&#39;y&#39;].apply(lambda x: np.log(int(x)))  模型拟合与预测 简单定义，然后拟合。</description>
    </item>
    
    <item>
      <title>The Next Step for Machine Learning 机器学习落地需攻破的9个难题</title>
      <link>https://kuhungio.me/2019/the-next-step-for-machine-learning/</link>
      <pubDate>Sun, 24 Feb 2019 23:31:58 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the-next-step-for-machine-learning/</guid>
      <description>机器学习在前两年的时间里，一下子就爆火了起来。很多公司也跟着这个趋势，招募了很多算法工程师、数据挖掘工程师。但是，在实践中，企业发现要落地，实际上还有很多问题需解决。以至于在大部分项目，还是规则主导。算法工程师的日常，也不过是清洗数据，调整规则。所以，机器学习技术，在真实的应用中到底缺少些什么呢？
在国立台湾大学《机器学习》2019春季班，李宏毅老师给出了他的观察。以下的内容，结合李老师的最新讲义、加上我本身工作的理解，给大家梳理机器学习落地急需解决的9个难题。
拒绝回答与可解释性（哲学层面） 1. Anomaly Detection 机器能不能知道“我不知道” 机器能不能知道自己的识别范围，还是说生硬地给出模型内的东西，或者说抛出无法识别。在猫狗分类里，现有的模型已经到达很高的精度，甚至能给出猫狗的品种。
但是正式上线后，用户真的会乖乖给到猫狗的图片吗？如果用户丢一张妹子图，机器能够知道自己不知道吗？目前这个领域的研究叫做 Anomaly Detection。知道自己不知道，对于一些异常的情况，十分重要。
2. Explainable AI 说出为什么“我知道” 神马汉斯的故事：
18世纪德国，一匹名叫汉斯的马成为当地网红。他能够计算简单的算术题，并用蹄子敲出正确回答。这在当时一度引起轰动。后来，有人做了个实验，把汉斯和周围的人完全隔绝，这匹马就完全蒙圈了。时事证明，这匹马的神奇能力不在于他的算数能力，而在于他的观察能力。当给到正确答案时，周围的人会有不一样的反应，汉斯也就随即停止敲马蹄。
机器学习的成果，是否同汉斯一样，通过一些意想不到的渠道，获得的答案。在 GCPR 2017 Tutorial 的研究中，研究者通过注意力机制，研究机器判断的依据。
实验者测试了两个模型，两个模型均为马匹识别。DNN 模型的焦点集中在马匹身上，是一个正常的模型。但 FV 的交点却集中在图片左下角。原来，图片的左下角有图片的出处，所有的包含马匹的图都有这个标记。所以，FV 模型学到的重点在于这些标记。同样的表现，却是不一样的判断依据。显然，FV 模型的判断依据是滑稽和不可靠的。
我们需要一些技术，让 AI 不仅给出结果，同时要给出判断的依据。即：模型的可解释性。
抵御恶意攻击 3. 防止 Adversarial Attack 人有错觉，机器是否也会有错觉。我们来做一个认知实验。以下两个圈圈，哪个的颜色更深？好，记住你的答案。结果将在稍后揭晓。
对于机器，有研究表明，通过改变图像中的个别像素，可以起到迷惑机器的作用。改变一个像素，就可以让模型的判断结果从熊猫到长臂猿。该技术名叫 Adversarial Attack。
这样的技术相当危险。举个例子，当自动驾驶的车辆行驶在路上时，可能路边的人挥舞下旗子，机器的判断就会被干扰，做出不当的举动。
回到开头的例子，正确答案是左边。这其实是一个计中计。你以为这是视觉认知实验，其实这也是某种形式的“心理攻击”。 学习模式 4. Life-long learning 终身学习 终身学习是一个人类行为的概念。活到老学到老，大家都知道只有不断更新自己的知识，才能跟上社会发展的步伐。同时呢，先前学到的东西，对后面的学习仍有帮助。举个例子：学完线性代数之后，对学习和理解机器学习就大有帮助。
但是，机器不一样。今天的我们，一般只让一个模型学习一个任务。但这样会存在一些问题。首先是随着建模的增多，模型数量将无限增长。其次，模型之前学到的技能，对之后的学习没有帮助。就像 Alphastar 它玩星际争霸很棒，但让他同时学下围棋，目前来说是不行的。它和 Alphazero 是两个不同的模型 。
那么，自然而然的，我们就会抛出这样一个疑问，机器能否终身学习呢？这里的相关研究，提个关键词 Catastrophic Forgetting 。
5. Meta-learning / Learn to learn 学习如何学习 现有的机器学习模型设计，都遵循着这样一个范式——在特定领域人工设计一套算法，让机器去学习。我们就想，能不能设计一套算法，让机器自己去设计自己的学习算法呢？
这样的范式，我们称之为 meta-learning 元学习，或者叫 learn to learn，学习如何学习。</description>
    </item>
    
    <item>
      <title>Bert Chinese Finetune 中文语料的 Bert 微调</title>
      <link>https://kuhungio.me/2019/bert-chinese-finetune/</link>
      <pubDate>Sun, 17 Feb 2019 11:30:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/bert-chinese-finetune/</guid>
      <description>Finetune Bert for Chinese NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。
Bert 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 Bert as service 代码的开源，使用 Bert 分类或阅读理解的副产物&amp;ndash;词空间，成为一个更具实用价值的方向。
因而，此文档着重以一个例子，梳理 finetune 垂直语料，获得微调后的模型 这一过程。Bert 原理或 Bert as service 还请移步官方文档。
依赖 python==3.6 tensorflow&amp;gt;=1.11.0  预训练模型  下载 BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  数据准备  train.tsv 训练集 dev.tsv 验证集   数据格式 第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。
fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!... houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客... game	赛季末用他们两天上一段，7.</description>
    </item>
    
    <item>
      <title>What is Data Mining 什么是数据挖掘</title>
      <link>https://kuhungio.me/2019/what-is-data-mining/</link>
      <pubDate>Sun, 17 Feb 2019 00:40:20 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/what-is-data-mining/</guid>
      <description> 一、数据挖掘的定义 什么是数据挖掘？  数据挖掘是一个用数据发现问题、解决问题的学科。 通常通过对数据的探索、处理、分析或建模实现。  数据挖掘学习路线  大学里并没有数据挖掘这么一个专业，现有的数据挖掘工程师大都来自工科或统计学等专业。 目前的数据挖掘工程师大都来自不同背景，计算机科学、数学甚至是机械工程。要想成功胜任，其诀窍是热情、好奇心，不断学习新的工具的能力，以及对数据清洗和分析的耐心。  给新人的建议  最重要的三个品质：好奇心、是非观以及批判性思考。这三个品质，放在其他领域同样适用。 专业领域的三种能力：编程能力、统计基础、商业思维。编程和统计在大学较为容易学到，商业思维需要多实践总结。  二、数据挖掘在做什么 数据挖掘工程师的一天  检查日常报表数据是否异常，寻求数据波动的合理解释。 针对新业务，设计指标，搭建数据模型。 搭建商品推荐系统、价格预测系统、文本分类系统或是聊天机器人。  数据挖掘的算法  使用复杂的机器学习算法并不能保证效果。一般来讲，最好的解决办法，通常很简单。 生产环境使用简单的算法，并不意味着要放弃前沿算法。每一套新的方法，其目的都在解决前面的薄弱之处。  数据挖掘与服务器  本地 PC 由于硬件与系统限制，工程师常在服务器进行大规模数据的运算、脚本部署与接口部署。   三、商业中的数据挖掘 作为公司，该如何开展数据挖掘  评估可能的收益与需要的投入 开始收集数据 招募数据挖掘团队  招聘数据挖掘团队  好奇心应该是数据挖掘从业者的最重要品质。 招聘时，应确保候选人对工作内容感兴趣。 候选人应具备一定的成果意识。商业更重成果，而不是过程。  数据挖掘应用  广告位点击预估 信用卡风控评估 用户流失干预  四、数据挖掘工具 数据挖掘工具与大数据  掌握以下工具：Python、Linux、Pandas 及 Jupyter、关系型和非关系型数据库。 大数据通常指传统数据系统无法处理的数据。体量和增速都相当大。处理工具以 Hadoop 为代表。  五、数据挖掘进阶 神经网络和深度学习  神经网络出现已数十年，但由于条件限制，这一方向搁置了数十年。目前随着新的优化方法的出现和算力的提升，这一方向的工业化逐渐成为可能。  如何更上一层楼  掌握基本的编程知识，更多地去理解背后的原理。 流程化意识，及时复盘总结，规范流程（复用）。 成果导向，将知识转化为行动和成果，给他人带来价值，服务更多人。  </description>
    </item>
    
    <item>
      <title>12306Bypass Server 给抢票神器加上微信提醒</title>
      <link>https://kuhungio.me/2019/12306bypass-server/</link>
      <pubDate>Sat, 26 Jan 2019 15:52:08 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/12306bypass-server/</guid>
      <description>前言 春节假期临近，车票一度紧张。某行、某团开了加速包后，仍然无法第一时间刷到目的地的票。稍微有点儿技术底子的我们岂能坐以待毙，自然是要自己动手，丰衣足食。
网上有各类开源的工具包，这里不做过多点评。之前在好友圈内传得比较靠谱的是 12306Bypass，又叫分流。分流是一个 Windows 应用，工作在 PC 端。其核心功能完全免费，更更重要的是，它的监控刷新在本地可以真实的感知。
以前在学校还好，可以守在电脑面前。但工作后，由于各种原因，无法第一时间获取分流的抢票信息，因而白白错过好几次下单付钱的机会。于是我们就有了这样一个愿望，希望能将分流的信息第一时间转发。
前几日逛某论坛，有人向分流开发者传达了增加 Server 酱的请求。开发者还是很给力，在最近的几次版本迭代中实现了该功能。简单的来说，Server 酱就是一个提醒服务。在这里，我们把它用在抢票软件中。当软件抢到票时，通过该服务，给到微信提醒。通知我们及时付款。
通过这样的形式，即可在微信端第一时间收到下订单的信息。那么如何配置这样的一个服务呢？我们只需要以下步骤。
​
准备工作  最新版本的分流软件 搜索关键词：12306Bypass  这里使用的版本号是1.13.30。 没用过？下载链接  Github 账号 这里用做 Server 酱的登陆认证  不知道？注册链接   实操阶段 Server 酱 用于获取认证的接口
 登入：用GitHub账号 登入网站，获取SCKEY（在「发送消息」页面） 绑定：点击「微信推送」，扫码关注同时即完成绑定  记住 SCKEY ，我们接下来会用着。
分流  启动分流，按正常流程配置票务信息。
 点选主界面左下角的推送
   填入以下信息
 通知地址 `https://sc.ftqq.com/[SCKEY].send
 通知参数 text=#bypass#    点击测试发送，即可在微信端，收到本文一开始的推送测试提醒啦  实际效果 就在配置完成不久后，分流帮我抢到了回家的车票。同时在微信端，Server 酱强制推送。
总结 通过这样的一番配置，我们终于能够安稳的玩耍手机，而不用担心错过订单付款时间。事实上，分流本身的基础功能，也自带了一些提醒服务。但是他们大多较为繁琐。以 QQ 提醒为例，有被顶掉下线的风险。自带的微信提醒，模拟的微信桌面登陆，理论上需要2个微信号。按照上面的操作，我们只需要简单的配置，即可实现强制推送，错过的几率大大减小。</description>
    </item>
    
    <item>
      <title>速查表 | Linear Algebra and Calculus 线代与微积分</title>
      <link>https://kuhungio.me/2018/algebra-calculus/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/algebra-calculus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>速查表 | Probabilities Statistics 数理统计</title>
      <link>https://kuhungio.me/2018/probabilities-statistics/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/probabilities-statistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why is Data Hard 为啥说做数据这行不容易</title>
      <link>https://kuhungio.me/2018/why-is-data-hard/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/why-is-data-hard/</guid>
      <description>原文链接 Slack 工程师 : why-is-data-hard?
做数据挖掘时，常常需要考虑很多方面。其中一个方面，常常会涉及到跨功能，复杂且琐碎的一些事项。数据准备以及评价指标的制定，就是这些事项之一。
等等，似乎干数据这一行，并不容易？
当大多数的组织谈到数据时，他们想的其实是指标——能反应近期业务、或是能够提供数据驱动的决策、抑或是能够监测企业经营状况的指标。
按上面的说法，我们应该能够招聘到聪明且能干的分析师，做出酷炫的可视化仪表盘，并马上投入使用。
 “Every second of every day, our senses bring in way [more] data than we can possibly process in our brains.”&amp;ndash; Peter Diamandis, Founder of the X-Prize
 拥有大量的数据并不会立马产生价值。当你是在数据增长快如 Slack 这样的公司处理数据时，不仅怎样驾驭数据和指标极其重要且困难的，更困难的是你像是在 “building the plane as it is flying”。
数据金字塔：评价指标（metrics）最为重要 数据金子塔大致可以分为4个级别。每一个级别都高度依赖下一级。
见解/洞察（Insights） 大部分的老板和公司董事关心的是这一层。见解（Insights）是我们所讲的关于数据的故事，即什么驱动了商业，或者是有什么新的机会能够推动大量的增长。
在理想的世界中，有一个共享的、不断演进的关于业务性能的数据叙述。这种数据叙述在整个组织中传播，以建立对业务的共同理解。
探索以及工具 为了获得见解，我们需要雇佣很多人定期去探索数据。只有当有人在盯着数据的时候，才能有策划和故事!
在快速增长的业务中，最优的数据探索涉及到一些关键事物：
 数据探查的多样性。要真正建立起，对正在发生的事情和重要的事情的理解和见解，我们需要每个人都拥有，对数据的关注和探索的主人翁意识。现实情况是，如果探索困难，只有管理员(分析师)能够完成这项工作。你要么雇佣更多的分析师来深入挖掘你的见解，或者，你可以找到简化数据访问的方法，让团队能够自行解决问题。Slack 的做法介于两者之间——我们不断寻找，在整个组织中增加自助数据服务的方法；同时也确保，我们有优秀的分析师参与到每一个核心功能来。
 频繁使用。像所有良好习惯的养成一样，查看数据和指标的一致性，是建立对所期望东西见解的唯一方法，什么样的结果是出乎意料的，什么样的问题是需要分析数据的。分析师可以帮助挖掘趋势，有些趋势值得挖掘，而许多趋势则不然。如果老板经常查看数据，那么你的分析师就更有可能对他们的精力，进行最优配置。
   例子：本周活跃用户增加了4%。这是好是坏？是预期的增长放缓?还是因为这周，我们推出了新产品，所以实际上我们希望的是，高于平时一周的增长?
分析师能够挖掘并做出各种比较，以帮助老板对数字进行说明。分析人士可以将该数字与往年做比较，深入了解这些新要素的组成，以及他们来自哪里。也许4%符合你的期望。但事实上，它比平时要低，我们没有推出任何新产品，且处于一个缓增长放缓期。这就是您希望董事会和分析人员构建的见解。你不会希望在某些事情上耗费精力，这些事情并不会带来业务的增长，或者改变我们的决策。
  发现能力与数据探索。数据探索不同于在仪表盘上点来点去，这是我想在这里指出的。仪表盘是用一组具体的需求创建的，通常在特定的粒度级别上报告指标或世界的某些视图。数据探索是一种能力，即通过各种不同的特征结合来调查指标，以确定在固定的仪表盘中不会立即出现的趋势或机会。可以将其考虑为，能够对数据进行转换和筛选，从而向监控之外的数据提出问题的能力。看到活跃用户的激增吗？太棒了！也许我们需要探究这在所有国家都这样，还是仅仅出现在英国。那周我们是否发起了一项针对英国的营销行动？销售团队是不是在那周完成了一个大单子?  企业主离数据越近，他们就越有能力着手进行自助服务的探索，就能发现更快捷、更有效的关键见解。这是因为，他们更有能力将我们在业务中所做的事情，与我们在数据中可能表现的特点结合起来。反之亦然！那些从商业伙伴那里拥有大量业务背景的分析人士，可以更快地找到正确的见解，而不是身陷各种假设之中。对于一个快速成长的组织来说，你可能希望两者都存在于你的组织中，这样每个人都能带着主人翁意识，理解我们最大的机遇和存在的差距。</description>
    </item>
    
    <item>
      <title>时序小结 | time series problem summary 时间序列问题处理</title>
      <link>https://kuhungio.me/2018/time-series-problem-summary/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/time-series-problem-summary/</guid>
      <description>Source https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion
总结一：保证数据同分布 验证集的选取，分布上应尽量靠近测试集。
 方式一:：对抗验证集的生成。 方式二： 就近选取相同天数。 方式三:：类比属性。如本赛题 &amp;ldquo;golden week&amp;rdquo; 与 &amp;ldquo;new year&amp;rdquo; 类比，选取 &amp;ldquo;new year&amp;rdquo; 段作为验证集。  tips: kfold 用在时间序列上不合适，会有数据泄露风险。正确的方法应是滑窗。
总结二：异常值特殊处理 一些特殊的时间节点（或者说是异常值），应该予以特殊考虑。比如本次比赛中的 &amp;ldquo;golden week&amp;rdquo;.。需要对其进行变换，而不是直接依靠模型的预测结果。
 方式一:：等同法   The rules:
Treat holiday as Saturday
If the day before holiday is weekday ,treat the day before holiday as Friday If the day after holiday is weekday ,treat the day after holiday as Monday it work not only golden week but also a lot other holidays.</description>
    </item>
    
    <item>
      <title>Single Shot MultiBox Detector Keras version</title>
      <link>https://kuhungio.me/2017/ssd/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2017/ssd/</guid>
      <description>SSD目标检测Keras版 SSD是一种Object Detection方法。本文是基于论文SSD: Single Shot MultiBox Detector，实现的keras版本。
 该文章在既保证速度，又要保证精度的情况下，提出了SSD物体检测模型，与现在流行的检测模型一样，将检测过程整个成一个single deep neural network。便于训练与优化，同时提高检测速度。 SSD将输出一系列离散化（discretization）的bounding boxes，这些bounding boxes是在不同层次（layers）上的feature maps上生成的，并且有着不同的aspect ratio。
 模型效果  模型对载具的检测  模型对动物的检测  模型的视频检测   如何使用 项目地址kuhung/SSD_keras
所需依赖 cv2==3.3.0 keras==1.2.2 matplotlib==2.1.0 tensorflow==1.3.0 numpy==1.13.3  如果想跑通视频模块，则需额外pip install scikit-video
具体操作 git clone git@github.com:kuhung/SSD_keras.git cd SSD_keras   Download model weight weights_SSD300.hdf5here  cp weights_SSD300.hdf5 into SSD_keras   对于图片的检测  参考SSD.ipynb
 若要剪切图片为下一步处理做准备  参考SSD_crop.py
 检测视频 bash cd video_utils python videotest_example.</description>
    </item>
    
    <item>
      <title>yysGAN 生成对抗网络，在游戏角色生成中的尝试</title>
      <link>https://kuhungio.me/2017/yysgan/</link>
      <pubDate>Tue, 21 Nov 2017 09:02:35 +0800</pubDate>
      
      <guid>https://kuhungio.me/2017/yysgan/</guid>
      <description> 使用GAN生成新的游戏角色 摘要 Generative Adversarial Networks（简称GAN），中文名叫生成对抗网络。我们将使用它，来生成新的阴阳师角色。 依赖 （pip install） cv2 tensorflow( &amp;gt;=1.0) scipy numpy  使用方法 cd yysGAN python yysGAN.py  5000次迭代训练结果 了解更多GAN的知识 Generative Adversarial Networks.ipynb
 参考资料  Siraj Raval moxiegushi/pokeGAN  项目地址 https://github.com/kuhung/yysGAN
定制你的GAN图片生成器 # 拆包即用，修改input下文件，改为对应的jpg素材即可。  </description>
    </item>
    
    <item>
      <title>Cats VS. Dogs 图像分类之猫狗大战</title>
      <link>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</link>
      <pubDate>Wed, 06 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</guid>
      <description>我是参加DataCastle猫狗大战的选手，kuhung。在测评中，我提交的数据集最后评分0.98639。以下是我的备战过程及心得体会。（最后有完整代码及较全面的注释）
个人介绍 华中科技大学机械学院的大二（准大三）学生，接触数据挖掘快有一年了。早期在学生团队做过一些D3数据可视化方面的工作，今年上半年开始数据挖掘实践。想把这个爱好发展成事业。做过阿里的天池竞赛，也有在kaggle混迹。算个数据新手，但一直不承认：你是新人，所以成绩不好看没啥关系。
初识比赛 第一次接触数据集，就感觉有些难度。因为以前没做过图片分类的比赛，更没想过要用深度学习的神经网络进行识别。思索一番，还是觉得特征提取后，使用决策树靠谱。自己也下去找过资料，发现并不容易实现。期间，还曾一度想过肉眼识别。但打开文件，看到那1400+图片，就觉得这时间花在肉眼识别上不值。中间一度消停。
初见曙光——yinjh战队分享 后来上论坛逛过几次。一次偶然的机会，让我看到了yinjh团队分享的vgg16模型。乍一看，代码简单、效果不错。更为重要的是，这个模型自己以前从未见过。于是抱着验证学习的态度，我把代码扣了下来，打算自己照着做一遍。
过程艰难 一开始，我就把一屏的代码放进了我的jupyter notebook中，一步一步试水。很明显，我的很多依赖包都没安装，所以也是错误不断。早先是在Windows系统下，使用python2.7，需要什么包，就安装什么包。在安装keras过程中，我发现了Anaconda——很好用的一个科学计算环境，集成了各种数据挖掘包。即使是这样，仍然是满屏的错误，亟待排查。
步步优化 离比赛截止就还只有几天，一边准备期末考试，一边焦急地排查bug。Windows系统下仍有个别难以解决的错误，我索性切换到了做NAO机器人时装的Ubuntu系统下。结合keras给的官方文档，我对原代码进行了函数拆分解耦，又在循环体部分增加了异常检测。综合考虑性能，稍微修改了循环结构。下载好训练的vgg16_weights，在没有错误之后，焦急地等待25分钟后，屏幕开始打印结果。
欣喜万分 第一次提交，随便截取了前面一段，没成绩。折腾了几次，才发现是提交的格式出了问题。后面取p=0.99+部分，提交结果在0.58左右，数据集大概有90个。估计了下，狗狗总数应该在180左右。第二次提交，取了180左右，结果0.97多一点。第三次，也是最后一次提交，取了result前189个，结果0.98639，一举升到第一。
比赛总结 这次比赛，首先还得感谢yinjh团队的yin前辈。如果没有您分享的代码，就不会有我今天的成绩。感谢您分享的代码，感想您在我写这篇分享时提供的代码指导。 再者，感谢我的女票晶晶，谢谢你一直陪在我身边，谢谢你包容我写代码时不那么快的回复手速。我是新手，但我一直不觉得成绩低是理所当。立志从事这一行，就需要快速地学习、快速地成长。新人，也需要做到最好。当然，自己目前还存在很多问题。一些基本的概念只是模糊掌握，需要更多的实践，需要更多的理论积淀，而不是简单地做一个调包侠。
给新手的建议  善用搜索引擎，多读官方文档，不要一开始就依赖Google。 Google Groups、Stack Overflow、GitHub是好东西。 干！就是干！  完整代码  以下操作均在Ubuntu14.04+Anaconda中进行
导入python标准包  import os # 处理字符串路径 import glob # 用于查找文件  导入相关库  keras
 keras是基于Theano的深度学习(Deep Learning)框架
 详细信息请见keras官方文档
   安装过程  conda update conda
conda update &amp;ndash;all
conda install mingw libpython
pip install git+git://github.com/Theano/Theano.git
pip install git+git://github.com/fchollet/keras.git
  cv2</description>
    </item>
    
    <item>
      <title>高效能人士的7个习惯</title>
      <link>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</link>
      <pubDate>Sun, 10 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</guid>
      <description>第一部分：认识自我  一切探索的尽头，就是重回起点。——艾略特
 以原则为中心的思维  公平的原则 诚实与善良  以原则为中心，以品德为基础  由内而外强调，先追求个人的成功，才能有人际关系的成就;先信守对自己的承诺，才能信守对他人的承诺。  七个习惯&amp;ndash;大纲  习惯一：积极主动（BE PROACTIVE) 习惯二：以终为始(BEGIN WITH THE END IN MIND) 习惯三：要事第一(PUT FIRST THINGS FIRST) 习惯四：双赢思维(THINK WIN) 习惯五：知彼解己(SEEK FIRST TOUNDERSTAND,THEN TOBE UNDERSTOOD) 习惯六：统合综效(SYNERGIZE) 习惯七：不断更新(SHARPEN THE SAW)  习惯的定义
  习惯：知识，技巧，意愿  成熟模式图（成长三阶段）
 阶段：依赖、独立、互赖  有效性的定义
 效能：产出与产能必须平衡(P/PC balance)   第二部分：个人的成功：从依赖到独立 习惯一：积极主动  最令人鼓舞的事实，莫过于人类确实能主动努力以提升生命价值。&amp;mdash;-卢梭
 三种决定论  基因决定论 心理决定论 环境决定论  人类的四种天赋  选择的自由(freedom to choose) 想象力(imagination) 良知(conscience) 独立意志(independent conscience)  积极主动是人类的天性</description>
    </item>
    
  </channel>
</rss>