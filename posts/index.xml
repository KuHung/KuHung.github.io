<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/posts/</link>
    <description>Recent content in Posts on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 17 Jul 2019 17:02:56 +0800</lastBuildDate>
    
	<atom:link href="https://kuhungio.me/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>为什么95后这么难管，这些年轻人到底在想什么</title>
      <link>https://kuhungio.me/2019/manadement/</link>
      <pubDate>Wed, 17 Jul 2019 17:02:56 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/manadement/</guid>
      <description>一位朋友跟我讲，他们公司新来不到2个月的数据挖掘工程师离职了，表面理由是有上岸考公的打算，但实际原因却是和管理者气场不合。小伙是个95后，广州某985毕业，能力不错背景不错。他的上司是位新晋领导，勤勤恳恳，90后。
朋友和我感叹道：没想到95后与90后，在管理上就已产生分歧。其实我们95后，也很难理解00后的一些想法。但在职场上，后辈在走的路，前辈也走过，为什么他们似乎很难理解这些年轻人？
在老一辈的眼中，学而优则仕。学习好了就去当官从政，去服务别人。而在父母这一辈人的眼中，不论你干啥，当“老实人”被人管是不行的，他们的观点有一定的时代背景，但仍然在潜移默化影响着每个人。
而对于初入职场的新人来说，虽然暂时当不上管理者，但被管理时却也会思考：“如果是自己，将会怎样去做管理？” 对于这一批新的90后甚至00后来说，管理并不再是一场服从性测试，权威性的组织管理方法或不再有效。
什么是这些年轻人喜欢的管理风格呢？ 如果稍微读过一些管理学的书籍，就会发现，管理其实在近现代发生了较大的变化。厚黑学受人推崇，有它的一定意义，但是小年轻们对里面的技巧似乎并不买账。这点在酒桌或者聚餐时就可以看得出来。这批年轻人有自己的想法，有独立的意识，甚至有些“不懂”人情世故。
回顾历史，近现代企业管理做得比较好的，要当属日本。日本凭借其精益管理思路，在汽车制造业一举占领美国市场，打得美国的传统汽车巨头没有还手之力。在大学里，作为机械大类的学生，一定多少接触过精益生产。
这套理念，帮助日本一跃成为制造业强国。而反观国内，作为一个机械大类出身的同学，你一定知道国内的“中国制造”现状是什么。而作为一个跨行的 IT 向工程师，在实践中，也发现，以信息互联标榜自己的互联网，除了开源的代码复制粘贴得挺快，管理模式其实并没有跟上节奏。
今天，在当下环境中，还有很多管理者是靠着本能在管理，而不是一套系统科学的方法。一个程序员，或者是 IT 企业的中层管理，有时间去研究业务，却少有时间去研究管理。项目短平快上线、管理粗糙莽随意。像极了早期国内自然资源开采，先污染后治理的样子。
IT 工程师眼中的现代管理究竟应该是什么样的呢？ 我们接着从上面的日本制造业说起。在当时，他们推崇一种见 kanban 的工作法。即在看板上列出工作事项，工作流公开透明。而在当下，国内头条、国外谷歌都在推崇 OKR。这里两者的本质是相通的，即：公开透明公司的业务流，每个人都能参与到目标设定里面来。
低效的管理者 在执行这套的同学可能会说，这其实只是形式主义，到头来还是 KPI 导向，面向 PPT 晋升。这在企业中确实存在，而其中的缘由，有以下5点：
 管理者不能良好的安排自己的时间，自己的时间属于别人&amp;ndash;无尽的会议、向上汇报、向下沟通 眼光受限于岗位，注意力集中在流程、规范与控制上，而不是贡献 没能充分发挥人的长处，无论是自己、上司抑或是下属。总认为下属不能很好地完成工作。从职位出发去设定一个人能做什么、不能做什么。不能容忍人之短。 零碎容易完成的优先做，根据和需求方的亲疏远近安排优先级，而不是要事优先 无法有效决策，没有流程，不愿放权。决策没有边界，不设立反馈机制，任由自己的“偏见”主导决策  做好了上面的5点，企业就能蒸蒸日上了吗？其实也不是，如果没有一个学习型的组织，单靠个人也是难以推动的。千里马常有，而伯乐不常有。运气好，遇到一个放权给你的领导，做起来是运气，做不起来是常态。企业中的死海效应，“劣币驱逐良币”也同样常见。
螺旋沉默的组织团队 也就是说，还需要一个良好的组织氛围。而变成一个死海的组织氛围常有以下特征：
 安于现状，封闭思想。更愿以主观的视角观察现实，而不是客观。 心智模式不成熟。对已有的成功盲目崇拜模仿，而忽视掉其潜在的天时地利人和背景。 各自有各自的小算盘，没有共同的愿景。 团队内部给自为战，几乎不存在团队学习。 局部思考而不是系统思考。认为危机的主因是人或事，而不是系统机制的问题。从未留意过系统如何塑造自己的行为。不清楚系统的边界、增长极限、反馈回路以及压力是如何转移的 。  如果是想做一个失败的管理者，营造一种糟糕的团队氛围，按照上面做准没错。
短期利益驱动的变革  学校教育告诉我们：永远不能承认我们不知道的答案。而大多数公司还在强化这种训练，奖励善于推销自己观点的人，却忽视对复杂问题的探寻。（还记得上一次你的组织给对公司现行政策提出难题的人——而不是解决某个紧迫问题的人——颁发奖励是什么时候吗？）&amp;ndash; 《第五项修炼》
 别急，是不是准备收藏，并在组织中逆向推行以上措施呢？那你可能又陷入了组织变革中的另一个陷阱：在变革过程中，我们不仅难以看到整片森林；甚至，我们还会挑出一两棵我们认为最看好的树，然后就全神贯注在它们身上，为它们而倾注全部的变革努力。
为什么目前还有很多的 IT 企业管理者，在靠着本能管理呢？一个字：利。 无利不起早。 概念发明以后，还要在有实用价值的成本范围内，以一定的规模进行可靠的复制，它才能够真正落地。
为什么大家都觉得修正以上的问题是不符合利益的呢？因为很多时候，都是想短期梭哈一波，先用着后面再说，先这样管理出问题了再说。即忽视了系统性的东西，而仅专注于眼前的事物。
系统思考 如果想在组织中构建学习型组织，成为一个卓有成效的管理者，那肯定不是忽视系统思考的力量。
关注长期的行为和系统内部的结构，而不是表象和短期事件；世界非线性，不要用线性的思维思考；恰当的划分系统的边界；充分考虑多方的限制因素及相对强弱。
通过实际行为来推断系统目标，而不能只看表面的言辞或其标榜的目标。时间延迟无所不在，当下的干预很可能一段时间后才会产生影响。没有人能做到充分理性，每个人的理性都是有限的。
总结 在最近和实习生同事的合作过程中，深切的感受到信息差带来的权力膨胀感。实际上，管理也是一门实践课程。一开始可能会走偏，但只要有回顾、有反思，也终究会上正轨。系统思考、长远为重。不仅要问这些年轻人想要什么、也要问自己想要什么。</description>
    </item>
    
    <item>
      <title>A/B test 评价指标的选择</title>
      <link>https://kuhungio.me/2019/abtest-2/</link>
      <pubDate>Sat, 22 Jun 2019 15:28:01 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest-2/</guid>
      <description>如何定义一个评价指标 这是上一篇文章什么是 A/B test的续集，上一篇主要讲述 A/B 测试的历史，这里接着讲如何选择指标。
从本人的经验来看，一个指标怎么选择确实重要，但更重要的是需要自上而下理解且落实科学实验。而不是拍脑袋想指标，中途随意更换指标，汇报时仅罗列有利的指标。
如果要用一句话解释，如何定义一个评价指标，那一定是“以始为终”。在定义一个指标的时候，要想一想为什么要定义这个指标，这个指标的定义是为了说明什么情况，如果这个指标发生变化，将需要怎么去解释它。
指标定义的两种情况 在这里，定义指标的时候有两类：一是不变量，即变量组和对照组的都应该相同；另一个是变量，即需要观察改变的量。
对于不变量，需要注意两者的总量是否相同，数据的分布是否相同。以上保证实验的正常进行。对于变量，首先思考高层次的商业指标。诸如收益、市场份额、用户量等。接下来就是细节的指标，如用户体验，网页停留时长。
 例如，在游戏中，新手教程没完成的玩家，虽然不能直接知道原因，但根据经验，可能是引导时间太长、网络卡顿或者是别的原因。类似这样的情况，是用户体验上的问题。后面也会有一些方法提到如何去评估它。
 在实验中，可能得到的不是想要的信息、或者实验时间太短，得到的结果不准确。甚至有些东西无法衡量，这种情况又该如何去评估它呢。别急，下面的内容会给你回答。
自顶向下设计评价指标 如何确定指标来做健全性检验
 高层次的指标（如：活跃用户数、点击转化率 CTR） 指标细节（如：如何定义用户活跃） 使用一组指标，并将他们整合为一个单一指标（如：总体评价指标（OEC））  对于评估，可以选择一个指标或一套指标。如果是使用一套指标，可以把他们聚合成一个指标，比如构造一个目标函数，或者是简单的加权指标。
最后一点需要考虑的是：指标的普适性有多少。如果你在运用 A/B 测试，最好能有一个指标能够贯穿整个体系。
 举个例子：用户漏斗。
它表示用户通过站点执行的一系列步骤。 之所以被称为漏斗，是因为每个后续阶段的用户数都少于上面的阶段。 每个阶段都是一个指标——总数，比率和概率。
 数据不足怎么办 有些数据可能难以获得，主要原因如下：
 没有数据的权限 需要较长时间去收集数据  使用外部数据 其它数据收集的技巧：3种公司常用的方法
 数据中间商 调研公司 学术文章  以上能够帮助你依照整个行业设定指标。
额外的内部数据 额外的内部数据也可被使用，例如：
 回溯性分析：查看历史数据以找寻改变并进行评估 调研与用户研究：这个帮助你找到你想研究的点  以上办法的缺点是它只告诉了你相关性、没有告诉你因果性，而实验一定程度上可以解释因果。
最后，别忘了与你的同事交换意见，看看他们认为重要的指标有哪些。
附：其它获得额外数据的方法：
 用户体验研究（UER）——高深度少用户。这也适用于头脑风暴，在 UER 中也可以使用诸如眼动相机的设备，同时回溯历史进行分析。 焦点小组——中等深度中等规模用户。能够在一些假设上获得反馈，但也容易陷入集体思想的情况（即真正的个人意见难以获得表达） 调研报告——深度较低但用户规模大。对于一些难以直接衡量的指标很有用。不能用于直接和其它指标比较，因为调研的对象和指标很可能与大盘不同。  指标的实际例子 高层次指标：点击率
 定义一：Cookie 的总点击次数除以 Cookie 去重后的总数 定义二：被点击的页面数除以总页面数 定义三：总的页面点击次数除以总页面数  可能还需要过滤爬虫、牟利等行为以消除数据偏差。通过切片来判断数据是需要偏置还是过分偏置。在过滤掉数据后，计算每个切片的评价指标表现。如果数据表现有偏差，那说明数据里可能还需要调整。</description>
    </item>
    
    <item>
      <title>HIVE 技巧积累之合并重叠日期</title>
      <link>https://kuhungio.me/2019/merge_overlapping_date/</link>
      <pubDate>Sun, 09 Jun 2019 00:17:05 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/merge_overlapping_date/</guid>
      <description>目前网上流传着一个段子，说算法工程师实际上就是 SQL boy，数据分析师是 PPT boy。艺术来源于现实，实际上的我们真的有很多时间在写 SQL 出数据，或者是针对 bad case 做数据的进一步分析。
这不，近期这边接到的一个需求就是对玩家的某项行为进行统计。一般来讲，掌握基本 SQL 的技巧，这些需求的难度都不大。但是这个需求需要将玩家用户的多个重叠日期进行拉伸去重。这一下可难到大伙儿。在自个儿思考无果，团队讨论之后也没啥直接的办法。
在网上搜索一番后，很多都不是很对应。不过好在几轮筛选，找到了一个类似的需求。原文链接在这里：🔗。为了方便后来的人，在这里做个分析记录，以及后面举一反三该怎么做。毕竟这些东西很少出现在教程和课本里，但是当业务方有这个需求的时候，常常又很紧急，容不得细思慢想。
问题定义： 在解决一个问题之前，我们需要先明确定义问题。这里的问题是对多个重叠日期，用 SQL 将其进行去重，并在 HIVE 环境中使用。
对于日期情况的定义 这里采用穷举法，可以得出以下13类情况：
问题简化 解决问题的核心是简化问题。这个问题看起来情况众多，实际上，对于我们的任务，只有两种情况：一个是两个日期有重叠；一个是两个日期没有重叠。
对于不同的情况，要做不同的处理。重叠日期取最大最小日期即可，非重叠的分段取。剩下的即是通过工具去实现逻辑。
数据准备 这里采用原作的方式定义数据，创建出上面的13中情况。实际上，如果你的格式和下面的类似，做出对应的调整即可。
drop table t purge; create table t ( test_case varchar2(32) not null, start_date date not null, end_date date not null ); Insert into t values (&#39;01:precedes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;01:precedes&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;02:meets&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;02:meets&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;04:finished by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;04:finished by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;05:contains&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;05:contains&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;09:during&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;09:during&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;10:finishes&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;10:finishes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;12:met by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;)); Insert into t values (&#39;12:met by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;)); Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;)); commit;  定义出来的数据如下</description>
    </item>
    
    <item>
      <title>A/B test 揭秘之什么是 A/B test</title>
      <link>https://kuhungio.me/2019/abtest/</link>
      <pubDate>Fri, 24 May 2019 09:02:00 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest/</guid>
      <description>此文总结自 Udacity 的课程：A/B test，详细而系统地讲述了 Google，Amazon 以及 Netflix 等公司是如何在商业问题中设计 A/B test 并评估效果的，对于国内的业务也有很强的参考意义。这里是总结的的一部分：什么是 A/B test，讲述 A/B Test 的定义、适用范围以及和传统方法的异同。指标选择、实验设计与评估将在后面陆续放出。
A/B 概览 Q：什么是 A/B test？ A：A/B test 是一种用来测试新产品或新功能的在线测试常规方法。一般分为两组用户，一组对照组，一组实验组。对照组采用已有的产品或功能，实验组采用新功能。要做的是找到他们的不同反应，并以此确定哪个版本更好。
Q：A/B test 是否有适用范围，还是说所有情况都适用？ A：A/B test 能帮助你爬上前面的山峰，但如果想弄清楚是爬这座还是另一座，A/B test 可能不太有效。A/B test 能对很大范围的事情进行测试。
 例如：  亚马逊个性化推荐的 A/B test，发现个推能显著提升收益。 领英对首页流排序的测试，谷歌的搜索广告排名。 此外还可以对用户难以察觉的东西进行测试，如网站响应速度。亚马逊在07年发现：页面每增加100ms延迟，收入将会下降1个百分点。   Q：A/B test 不能做什么事情？ A：上线新的版本，带来完全不同的交互体验；或是低频长周期的产品；以及 A/B test 并不能发现被遗漏了什么。
测试新的交互体验时，A/B test 可能不太奏效。原因有两个：一、厌恶改变，不是每个人都喜欢改变，这可能导致用户的厌恶和抵触情绪。二、新奇效应，对于新鲜事物，用户可能会挨个尝试所有东西。
于此同时，这里会有两个问题，一个是你的比较基准是什么？另一个是需要花多少时间得出结论？举个例子：像低频的房屋租赁，在测试推荐流的时候，很难确定用户是为啥回来的。因为这要花的时间太长了，也许是半年，甚至是更久。
A/B test 无法告诉你是否有遗漏。当我们在某个产品测试信息推荐流时，仅凭 A/B test，无法知道是否该给这个用户推荐地理信息的资讯。于此同时，也无法确定别的产品是否需要推荐流。
Q：对于 A/B test 难以胜任的事情，该如何解决？ A：通过其它数据源来补充，对日志进行分析假设验证。或是通过其它技术，如用户研究来定性分析。
Q：A/B test 的历史是什么样的？ A：最先使用 A/B test 的，可能是农业领域。人们将土地分为不同部分，测试哪块地适合哪种作物作物或是作物如何生长。在科研领域。假设检验是确定创新的关键方法。医学上的 A/B test 被称为临床试验，通过此种方法来确定新的治疗方法是否有效。</description>
    </item>
    
    <item>
      <title>数据从业者必读的7本书 Booklist for DE</title>
      <link>https://kuhungio.me/2019/book-list-for-ds/</link>
      <pubDate>Tue, 07 May 2019 23:34:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/book-list-for-ds/</guid>
      <description>之前逛论坛，或者学习网站，看到很多人喜欢推荐书。自己早些时候也是这样，但是只 mark，却很少去看。如今作为一名社会人，虽说工作之余时间少了很多，但业余仍在坚持阅读。其中，支撑学习动力的一本书便是：《穷查理宝典》。书中查理·芒格提到的多学科思维，以及复利思维，一直在影响我的交友、做事和看问题的方式。
有关注某校友的公众号，他是做爬虫和可视乎的。某天在推荐 Python 学习资料。封面看着挺美，点开一看，书单质量实属一般。倒像是接的推广，很多估计他自己都没有看过，不太负责任。于是乎，便萌生了出一期书单的想法。而定位，便是数据科学家、数据挖掘工程师、算法工程师的书单。
首先声明，这份书单不是单纯的技术向书籍，不会有什么西瓜书或是算法导论之类的。他们也是好书，但不会出现在这里。因为在工作中大家就会发现，技术只是工具，好的工匠 != 熟练使用工具的熟练工。看见大局，同时有跨学科的思维，能够从事物的本质去出发，理解和思考它，也很重要。
作为一个数据挖掘工程师，以下是推荐的核心7本书单。为什么是7本呢？因为人一下子能记住的东西是有限的，记不住就忍不住收藏。收藏了就几乎等于很少看了。收藏一时爽，一直收藏一直爽。所以，书单从原来的二十几本变为了现在的7本。
这7本书的逻辑是从底层到高层。底层是构成我们一部分的东西，是我们的认知。中间则是我们的技能。而高层，则是我们的自我实现。最终又回到我们的认知。简单来说，就是从软技能到硬实力，再到软实力。
通识与概念  Top 7  通识趣味读本&amp;ndash;《赤裸裸的统计学》
该书讲了很多身边的例子，让人对统计学的应用有一个初步认识。且是一个检验兴趣点的很好方式。如果你对这些东西都不是很感冒，那么可能这行除了薪水，没有别的能吸引你。后面的内容也就没有读的必要了。
除了例子以外，本书也有很多反常识反直觉的东西。诸如统计数字会撒谎、因果关系与相关关系的混淆。黑天鹅、三门问题等地很考验一个人的智商。看完之后有醍醐灌顶的感觉。
与之类似的书还有《大教堂与旧集市》、《编码》等。
 Top 6  大而全&amp;ndash;《信息论、推理与学习算法》
如果你对第一本书的内容感兴趣，想要深入了解背后的原理，那么这本书不容错过。这本书更像是一本大百科全书，涵盖了传统信息论到最新算法的大部分内容。从熵、到编码、再到概率与推理，最后到常见的模型和神经网络。是一本适合高年级学生或者专人人员的查阅宝典。
这本书说实话有些厚重，限于版面，如果只推荐一本，会推荐它。当然如果想看更多元的内容，附加的书籍📚可不容错过。由于本身的专业偏传统工科，编码、信息压缩也有接触，因而过渡起来不会很困难。
与之互补的书还有《推荐系统实战》、《信息检索导论》、《集异壁》等。
工具与思想  top 5  吃饭工具&amp;ndash;《SQL 必知必会》
作为一个工程师，常自嘲自己是 sql boy。那是因为，在实际生产环境中，数据处理花了很大事件。大部分时间都是和sql 打交道。做过比赛的同学可能知道，数据处理、特征提取是很关键的一步。
在企业中，这一情况越发突出。有时候原始数据分散在各个地方，连规整的数据都没有。因而需要掌握一定的 sql 技能。虽然有些专业会学习数据库这一门课程，但这本书可以起到一个梳理作用，同时也有一些小的注意点。
掌握了这本书的同学，推荐《 SQL 反模式》，讲 sql 范式更进一步。虽说是给数据库开发人员看的，但是知其然并知其所以然，也是很好的。
如果想看到更大的图景，那么 ddia 一定不容错过。ddia 在一年前就很火，网上也有他的公开中文翻译。讲解整个数据系统很透彻。适合各类程序开发人员阅读。
 top 4  《利用 python 进行数据分析》
这本书也算是启蒙书。涉及的内容基本面很广，该有的都有了。介绍了 python 在数据科学领域的基础知识，同时也有案例解析。
读完这本书，参加小型的数据挖掘、机器学习类的比赛不会存在门槛了。与此类似的书还有《集体智慧编程》，以及近期比较火的 hands on ml。
思考与呈现 前面都是技术向、原理向的内容。是不是掌握了以上内容，就可以美滋滋的享受生活了呢？其实这是很多软件从业人员、甚至是工科同学的一个共同误区。觉得把我的技术学好了，就万事大吉，酒香不怕巷子深了。在这里千万不要忽略掉你的软实力。
在某些头部公司、ppt 文化盛行。虽然有些走极端，这其实也是一种现状。从原则上来讲，只讲 PPT 画大饼而不做事是不对的，所以他们被放在最后讲。与此同时要记住，硬币的反面也是不对的，只埋头苦干，而不去扩大影响力，事情的价值就很可能被低估。</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>深度强化学习技巧 hacks for training deep RL 这是一篇旧文，John Schulman 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。 测试新算法的技巧  简化问题，使用低维变量。  使用类似只有角度和速度两个变量的 Pendulum problem 问题。 这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。 当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。   构造一个 demo 来测试你的算法
 比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。 这样能够轻易地发现那里出了问题。 注意：不要在这样的小问题上过分的尝试。   在熟悉的场景中测试
 随着时间的推移，你将能预估训练所需的时间。 明白你的奖赏是如何变化的。 能够设定一个基线，以便让你知道相对过去改进了多少。 作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。   快速上手新任务的技巧  简化问题  从简单的开始，直到回到问题。 途径1： 简化特征空间  举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。 一旦起步，逐步还原问题直到解决问题。
  途径2：简化奖赏函数  简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。 比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。    将一个问题转化为强化学习的技巧 可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。
 第一步：将这个问题使用随机策略可视化出来。
 看看那些部分吸引了你。 如果这个随机策略在某些情况下做了正确的事，那么很大概率，强化学习也可以做到。</description>
    </item>
    
    <item>
      <title>机器学习模型部署--打通前后端任督二脉</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>前言 学历与定位 近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个小本就工作的人，没有较为丰富的实战经验，有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。
模型算法的实用主义 机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。
 关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。
 这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 kuhung/flask_vue_ML
后端 flask 相关依赖的安装 pip install -r requirements.txt
核心函数  导入函数包  from flask import Flask, jsonify, request from flask_cors import CORS # 做跨域的准备 from flask import session # 追踪客户端会话 from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类 from flair.data import Sentence   准备工作  app = Flask(__name__) # 声明准备 app.</description>
    </item>
    
    <item>
      <title>如何设计一套类似视觉中国鹰眼的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”
 2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。
 “鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。
爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。
首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。
基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。
首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。
从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。
第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。
而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：教 AI 学会看图说话：Image Caption。
总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。
这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。
最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。
附录 视觉中国图片侵权追踪系统曝光：鹰眼系统
2018年度市科委第四季度项目(课题)验收公开清单
视觉（中国）文化发展股份有限公司 2016 年年度报告
《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋
《基于内容的图象和视频检索》</description>
    </item>
    
    <item>
      <title>Hands On Machine Learning in Industry 一文看懂机器学习项目的完整生命周期</title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。
机器学习项目的生命周期 问题定义
定义问题，并关注大局  数据处理
获取数据 探索性的数据分析 清洗数据，为接下来的模型做准备  模型方案
探索不同的模型并挑选合适的模型 对模型进行微调，并集成为更好的模型 解决方案呈现  部署维护
部署、监控并维护系统    定义问题，从大局出发  和业务团队一起定义问题目标 我们的解决方案将会如何发挥作用 现在的解决方案是什么样的（如果有） 你将如何定义这个问题（有监督、无监督，在线还是离线） 结果该如何衡量 衡量方法是否和商业目标一致 要达成这一目标，至少的表现该是什么样子的 类似的问题是什么？有无可复用的经验与工具 我们有专家知识吗 你将如何着手解决这个问题 列出你或者别人目前所作的努力 如果可能，对假说进行验证  获取数据 建议：尽量自动化以更容易地方式获取最新的数据
 列出你所需的数据以及体量 找寻并记录下获取数据的方式 检查数据将占据多少空间 检查是否有法律风险，如有必要请获得许可 获取许可 创建工作空间，确保存储足够大 获取数据 转换数据的格式以便能够方便操作（不需要改变数据本身） 确保敏感信息被删除或保护加密（匿名） 检查数据的大小和类型（时间序列、采样、地理信息等） 划分测试集，把他放一边，并且不再去动他（防止数据泄露）  探索数据 建议：在该阶段尽量获取领域专家的意见
 创建数据的副本以便做数据探索（如果数据量太大，做降采样处理） 创建 Jupyter notebook 以便保存探索记录 研究每个属性及其特征  名称 类型（类别，整型/浮点，有无上下界，文本，结构化等） 缺失值 噪声数据（随机数，异常值，四舍五入的误差） 对本任务可能有用的数据 分布类型（高斯分布，均匀分布，指数分布）  对于有监督问题：确定目标对象 可视化数据 研究变量间的相关性 研究你将如何着手解决此问题 确认比较有希望的解决方案 确认有用的外部数据 将以上信息存档记录下来  准备数据 建议：</description>
    </item>
    
    <item>
      <title>Slack gpt2 Bot 机器人写文已经到了如此地步？邀你一同测评史上最强 GPT2 模型</title>
      <link>https://kuhungio.me/2019/slack-gpt2-bot/</link>
      <pubDate>Mon, 25 Mar 2019 22:36:06 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/slack-gpt2-bot/</guid>
      <description>记得在校的时候，某岩做过一个app，讲接龙故事的。类似于我写一段，另一个人写接下来的一段，最后凑成一个完整的故事。当时，可产生了不少有意思的段子。最近，GPT2 模型的发布，让人不禁想到，有没有可能让机器来完成这个任务呢？机器写十四行诗、机器写莎士比亚风格的文章，机器写对联，这些都已经成为了现实。人工智能虽然没有带来突飞猛进的质变，但着实催生了很多有意思的小玩意儿。对于GPT2，一个字概括来说就是：壕——数据量大，算力能够 cover 住。这套算法模型网罗了几乎现有的所有文本数据，成功“过拟合“地屠榜，刷新多个 NLP 任务榜单排行。作者为了预防滥用模型、同时让别的研究者能够有个初步地认识，开源了一个小一些地模型。该模型的能力之一，就是我们今天的主题：接着别人地话写故事。今天我们要通过算法来实现。
虽然作者有在尽力简化复现难度，但对于很多不是这行的人，让他去敲命令行来走完整个流程，还是困难重重。能够将深奥的原理讲给普通人听，并且简单易懂，是一项科学传播的必备能力。做为技术向的工程师，在产品处于雏形阶段时，能够通过一个 MVP 最小价值产品，实现核心功能，也是一项大大的加分项。对于今天的任务，我们选取容易上手，接口丰富的 slack 作为我们的前端交互窗口。
如何构建一个 MVP 产品；或者具体的来讲，在我们的这个任务中，如何将数据挖掘工程师的模型成果，转化为可落地、可感知的产品或服务呢。操起斧子直接开干，依葫芦画瓢撸个前后端出来吗？这，其实是很多技术人员的一个误区——认为什么都可以从技术层面解决，”少废话别bb，bb is cheap，show me the code“。但从一个商业产品或服务商的角度来看，客户与渠道是前台，我们的客户是谁、如何触达客户以及选用何种渠道维系客户，是一个一开始就要考虑的事情。
以这个 GPT2 bot 为例，我希望的客户是对 GPT感兴趣，但又没基础去折腾的学生或是其他领域的人士，抑或是没时间去跑 demo 的专业同行。如何触达客户：你看的这篇文章的平台，就是我的触达媒介。我最后选择用 slack 交付我的服务，而不是 qq 或 微信，是因为他成本更低，虽然阻挡了部分潜在客户，但权衡后是可以接受的。最后的工作才是依葫芦画瓢，照撸一个出来。本文参照了EdwardHuCS,并在其基础上做了部分改动。
虽然这波 AI 热潮，让很多像我这样的非科班得以上车。但在实际生产环境中，我们还是暴露了诸多问题。其中之一，便是工程能力薄弱。会写 SQL 、会手推算法、会调包，但是就是不会写能跑的整个小系统。在业务变化快的公司中，这可能不是一个好事情。你的模型也许还在细调参数，但突然整个业务就没了。如果你能拿出一个能跑的马儿，兴许能影响这个业务。这就是前面提到的加分项。
言归正传，我们回到在slack上面。我们的核心就以下代码：
核心代码解读 导入一些基础配置
import os import time import re from slackclient import SlackClient import sys from gpt2.src import generate_unconditional_samples # instantiate Slackk client slack_client = SlackClient(&#39;&#39;) # 认证口令 # starterbot&#39;s user ID in Slack: value is ssigned after the bot starts up starterbot_id = None  延迟配置以及样例和匹配模式</description>
    </item>
    
    <item>
      <title>Competing on Analytics 凭什么打败竞争对手？基于数据、基于分析的商业竞争</title>
      <link>https://kuhungio.me/2019/competing-on-analytics/</link>
      <pubDate>Tue, 12 Mar 2019 10:48:59 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/competing-on-analytics/</guid>
      <description>数据科学家这个职位，随着12年的哈佛商业评论的一篇文章，成为了21世纪“最性感的职业”。这年头，越来越多的年轻人开始往这个方向奔，市场几近饱和。但是，很少有听见企业家说：“是的，我们很需要数据工程师，因为以下原因&amp;hellip;“对于看此文的老板们，你们是否不止一次听到媒体鼓吹大数据、鼓吹机器学习、鼓吹人工智能，却很少有听到说这些东西，对于企业来说，实实在在带来了什么。如果你的答案是“Yes”，那么这篇文章将解答你的疑惑。
本文论点主要取自 Thomas H. Davenport 文章 《Competing on Analytics》，试图从企业管理的角度，阐述为什么我们需要数据科学家（或者说广义的数据相关人员）；他们能给企业带来哪些切实的好处；以及作为企业家，我们该如何转型，如何拥有更强的竞争力。
同质化的市场危机 在当下，想依靠某个新奇的点子或者是产品服务，已经不大可能再和其他竞争者区分开来。作为一个人类组织，底子里仍保留有人类的天性。人类天生就爱模仿，从一出生模仿吃东西，到后面通过模仿习得语言，再到后面的学习。人类的本质可能就是个复读机。模仿可以说保证了我们人类种族的存在与延续。对于企业来说，也大抵相同。
尽管我们知道，从道德原则上讲，大企业模仿别的东西是不对的。但是，从商业利益角度，无数的事实告诉我们，模仿，对于企业来说真的是一个大概率稳赚不亏的事情。把市面稳定的产品拿来微创新，再加持自己的人力或渠道优势，很快就能回本。保不齐也能把竞争对手耗死。现实即是如此。
比你更有利的竞争对手 越来越多的产品、服务开始同质化。无论互联网、游戏、手机或是制造业、服装业，越成熟的领域这个现象越明显。与此同时，我们的竞争对手可能在东南亚，拥有更低的人工成本；可能在不规矩的私营企业，拥有更多免费加班的程序员；也可能是腾讯头条这样的大厂，控制着大部分渠道。那么，你的产品服务，凭什么脱颖而出？
答案就是成为分析型竞争者
数据分析竞争者在干什么 数据分析型竞争者会做以下几个事情。
用户 通过分析，去洞察客户的需求，以及他们所愿支付的价格，找到他们保持忠诚度的原因。在商业模式中，客户是我们的直接服务对象，也是收入来源。那么，势必需要搞清楚客户的数据情况。
在当下，比较流行的技术是通过用户画像技术，去刻画我们的用户群体。用户的分布地域、用户的性别以及年龄，用户的偏好。只有这些东西都搞清楚，我们才能清楚的知道我们的客户是谁，为什么他们需要我们的服务或产品。
渠道 与此同时，也要分析我们触达用户的渠道。不得不说，发明电视黄金档广告的人，一定是个商业奇才。曾几何时，电视广告和路标广告曾是众多老板的竞相争夺的资源，屡屡出现标王，一次次刷新记录。在那个时代，只要你砸钱，拿到黄金时间的广告，就是稳赚不赔。但现在不一样了，各种互联网渠道，在抢占着人们的注意力。楼宇电梯广告、站台路牌广告各种花样层出不穷。
但是，你就真的清楚该投哪一个了吗？还是听信对方销售人员一阵天花乱坠的吹嘘，就乖乖交了钱，却得不到想要的转化效果？通过适当的分析，我们可以知道用户在哪些渠道对我们的响应度最高，知道哪些渠道可以带来更高的转化，从而优化我们的渠道成本投入。
举个我自己的例子：我的文章隔几天就会发一篇，分布在不同渠道：微信、知乎、头条、掘金、简书。那我是单单为了占坑防洗稿就完事了吗？不是的，作为一个数据挖掘工程师，我会分析各个渠道带来的阅读、关注和互动，从而调整渠道策略。
目前我就发现，知乎和头条的信息流产品在分发策略上做的很不错，能保证充分的曝光。微信适合做核心粉丝的沉淀，和粉丝去探讨交流一些问题。而掘金、简书的曝光有限，那我就会在更新是把他们往后放。
那是不是我就应该放弃简书掘金了呢？也不是的。通过分析我发现，掘金在谷歌搜索的排名占比靠前，简书在百度搜索的排名靠前，他们俩实际是很好的 SEO 流量优化渠道。这就是渠道分析的效果。
人力 通过分析，去计算员工对公司利润做出的具体贡献，而不仅仅是关注薪酬成本。以前的自己觉得，买东西或是做事情，先去看成本是多少。工作后发现，领导的视角不是这样的。成本对于老板们来说，只是个数字。他们更关心做事的投入产出比。对于员工问题也是这样。
但现实不是这样的。很少有公司会关注这名员工对利润的贡献，反而更多的去关注他的成本是多少。他今天996了没，没有996对不起我给他开的价钱，而丝毫不关心员工对公司利润所做的贡献。而另一个极端就是，有些老板觉得这类人便宜，从而养了很多闲人。这两种情形虽然短时不会给企业带来多大负面影响，但你的竞争性选手，已经在利用数据，去发现员工的价值贡献，并对人事招聘进行调整了。
库存 在实业中，我们还要追踪现有的库存，预测并分析需求量，减少库存的积压，提高现金流转效率。这里主要是对重资产的企业老板，如果你能在这其中发现机会，一个点的提升，都会带来巨大收益。
数据分析竞争者的特质 那么，集体来讲，分析型数据竞争者具有怎么样的特质呢？如同招聘时给出的工作描述，我们也可以给分析型竞争者做画像。
 数据竞争型选手应广泛应用模型和算法以及对应的最优化技术。例如作者之前实习的某普惠金融银行，通过最广泛的数据建模，给中小微个人提供贷款，赚大型银行看不上的钱，同时自己也很滋润。
 组织内部全面应用数据分析等相关技术。对各个流程进行数据分析、对各个环节进行建模以优化体验，减少流失。
 同时，也应该有自上而下的支持。如果一个企业的领军人物都不相信，那一线员工又何来的信任和执行力呢。企业老板应具备一些基础知识，同时有能够值得信任、不编造数据的专家。
  为什么它有效 说了现状说了要求，那为什么套措施有效呢？如果大家都有，那不就是没有差异化了吗？难道我们要搞军备竞赛吗？这不就和贩卖焦虑的自媒体一样的了吗？
其实不是这样的。一个身材羸弱的人和一个经常分析自己身体状态并针对性强化的人，他们外在的表现就会不一样。大部分企业在竞争中，使用的技术很相近，产品差别也不大；唯一能有差异化的，可能就是商业流程了。数据的挖掘分析，帮助企业家从流程中挤出每一滴价值。
尽管很多公司都有数据分析团队，但只有娴熟运用的公司，才能在各行各业取得霸主地位。甚至，对于如头条、亚马逊这样的公司，数据挖掘、算法已经成为了企业的名片和核心竞争力。
核心4条解决方案  合适的焦点、分析不可过于分散，免得失去焦点。
 合适的文化、小范围检验，最小可行产品验证。
 合适的人才、有分析能力且能深入浅出说明问题；有商业才能能够在商业角度阐述价值；以及沟通的技巧。
 合适的技术、数据储备、硬件支持，最终才会立于不败之地。
  最后，数据竞争型选手，如何说明他确实有效。很简单，以始为终点，检视最初的目标。</description>
    </item>
    
    <item>
      <title>Prophet in 000300 我把算法模型套在了股市上，发现...</title>
      <link>https://kuhungio.me/2019/prophet-in-000300/</link>
      <pubDate>Fri, 08 Mar 2019 22:48:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/prophet-in-000300/</guid>
      <description>跑步进场 最近股市大涨，不少人忙着跑步进场。作为保守型“投资者”，主投指数基金：沪深300。在这波行情 中，短短2个月，也有13%的账面收益。虽然知道指数类适合长期持有，但也好奇，这个点是否是高位了。为了解决这个疑虑。我们今天用算法模型套一套，看能否发现些什么。
时序预测的价值 时序问题的预测在生活中很常见。例如：游戏在线人数预测、消费情况预测、 O2O 的到店人数预测、交通流量预测，这些场景的精确预测，为资源的调配起到了重大的参考作用。从个体角度来说，得到的服务和体验也大大提升。
为此，Facebook 开源了一套工具 Prophet，专门用于时间学列预测。在这里，我们将用它，来一探股市究竟。
时序预测的原理 对于时间序列问题，常用的手法是时间序列的分解：这里有些类似于傅里叶变换的意味。将一个函数分解为多个规律函数的和积。时间序列的常见组成成分包括：季节项、趋势项以及噪声。在 Prophet 中，结合实际情况，他们又加入了节假日项目。之前在一次 kaggle 的比赛中，我们也发现节假日的数据波动，其实是类似于周末效应的。即：节假日的前后数据，类似于周六的前后数据。对数据进行修正后，评价指标会好很多。
废话不多说，咱们开干。
Prophet in 沪深300 工具包安装 pip install fbprophet
数据准备与清洗 import pandas as pd import numpy as np from fbprophet import Prophet  数据准备
 数据来源为网易财经，沪深三百指数。  data = pd.read_csv(&#39;../data/000300.csv&#39;,encoding=&#39;GB2312&#39;) data.head()  数据清洗
 选取需要的数据，并对数据做 log / box-cox 变换，使数据更符合线性、正态分布，减少方差差异。经济系统和生态系统类似，都存在指数级增长现象，也存在饱和现象。我们这里采用 log 变换。  df = data[[u&#39;日期&#39;,u&#39;收盘价&#39;]] df.columns = [&#39;ds&#39;,&#39;y&#39;] df[&#39;y&#39;] = df[&#39;y&#39;].apply(lambda x: np.log(int(x)))  模型拟合与预测 简单定义，然后拟合。</description>
    </item>
    
    <item>
      <title>The Next Step for Machine Learning 机器学习落地需攻破的9个难题</title>
      <link>https://kuhungio.me/2019/the-next-step-for-machine-learning/</link>
      <pubDate>Sun, 24 Feb 2019 23:31:58 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the-next-step-for-machine-learning/</guid>
      <description>机器学习在前两年的时间里，一下子就爆火了起来。很多公司也跟着这个趋势，招募了很多算法工程师、数据挖掘工程师。但是，在实践中，企业发现要落地，实际上还有很多问题需解决。以至于在大部分项目，还是规则主导。算法工程师的日常，也不过是清洗数据，调整规则。所以，机器学习技术，在真实的应用中到底缺少些什么呢？
在国立台湾大学《机器学习》2019春季班，李宏毅老师给出了他的观察。以下的内容，结合李老师的最新讲义、加上我本身工作的理解，给大家梳理机器学习落地急需解决的9个难题。
拒绝回答与可解释性（哲学层面） 1. Anomaly Detection 机器能不能知道“我不知道” 机器能不能知道自己的识别范围，还是说生硬地给出模型内的东西，或者说抛出无法识别。在猫狗分类里，现有的模型已经到达很高的精度，甚至能给出猫狗的品种。
但是正式上线后，用户真的会乖乖给到猫狗的图片吗？如果用户丢一张妹子图，机器能够知道自己不知道吗？目前这个领域的研究叫做 Anomaly Detection。知道自己不知道，对于一些异常的情况，十分重要。
2. Explainable AI 说出为什么“我知道” 神马汉斯的故事：
18世纪德国，一匹名叫汉斯的马成为当地网红。他能够计算简单的算术题，并用蹄子敲出正确回答。这在当时一度引起轰动。后来，有人做了个实验，把汉斯和周围的人完全隔绝，这匹马就完全蒙圈了。时事证明，这匹马的神奇能力不在于他的算数能力，而在于他的观察能力。当给到正确答案时，周围的人会有不一样的反应，汉斯也就随即停止敲马蹄。
机器学习的成果，是否同汉斯一样，通过一些意想不到的渠道，获得的答案。在 GCPR 2017 Tutorial 的研究中，研究者通过注意力机制，研究机器判断的依据。
实验者测试了两个模型，两个模型均为马匹识别。DNN 模型的焦点集中在马匹身上，是一个正常的模型。但 FV 的交点却集中在图片左下角。原来，图片的左下角有图片的出处，所有的包含马匹的图都有这个标记。所以，FV 模型学到的重点在于这些标记。同样的表现，却是不一样的判断依据。显然，FV 模型的判断依据是滑稽和不可靠的。
我们需要一些技术，让 AI 不仅给出结果，同时要给出判断的依据。即：模型的可解释性。
抵御恶意攻击 3. 防止 Adversarial Attack 人有错觉，机器是否也会有错觉。我们来做一个认知实验。以下两个圈圈，哪个的颜色更深？好，记住你的答案。结果将在稍后揭晓。
对于机器，有研究表明，通过改变图像中的个别像素，可以起到迷惑机器的作用。改变一个像素，就可以让模型的判断结果从熊猫到长臂猿。该技术名叫 Adversarial Attack。
这样的技术相当危险。举个例子，当自动驾驶的车辆行驶在路上时，可能路边的人挥舞下旗子，机器的判断就会被干扰，做出不当的举动。
回到开头的例子，正确答案是左边。这其实是一个计中计。你以为这是视觉认知实验，其实这也是某种形式的“心理攻击”。 学习模式 4. Life-long learning 终身学习 终身学习是一个人类行为的概念。活到老学到老，大家都知道只有不断更新自己的知识，才能跟上社会发展的步伐。同时呢，先前学到的东西，对后面的学习仍有帮助。举个例子：学完线性代数之后，对学习和理解机器学习就大有帮助。
但是，机器不一样。今天的我们，一般只让一个模型学习一个任务。但这样会存在一些问题。首先是随着建模的增多，模型数量将无限增长。其次，模型之前学到的技能，对之后的学习没有帮助。就像 Alphastar 它玩星际争霸很棒，但让他同时学下围棋，目前来说是不行的。它和 Alphazero 是两个不同的模型 。
那么，自然而然的，我们就会抛出这样一个疑问，机器能否终身学习呢？这里的相关研究，提个关键词 Catastrophic Forgetting 。
5. Meta-learning / Learn to learn 学习如何学习 现有的机器学习模型设计，都遵循着这样一个范式——在特定领域人工设计一套算法，让机器去学习。我们就想，能不能设计一套算法，让机器自己去设计自己的学习算法呢？
这样的范式，我们称之为 meta-learning 元学习，或者叫 learn to learn，学习如何学习。</description>
    </item>
    
    <item>
      <title>Bert Chinese Finetune 中文语料的 Bert 微调</title>
      <link>https://kuhungio.me/2019/bert-chinese-finetune/</link>
      <pubDate>Sun, 17 Feb 2019 11:30:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/bert-chinese-finetune/</guid>
      <description>Finetune Bert for Chinese NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。
Bert 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 Bert as service 代码的开源，使用 Bert 分类或阅读理解的副产物&amp;ndash;词空间，成为一个更具实用价值的方向。
因而，此文档着重以一个例子，梳理 finetune 垂直语料，获得微调后的模型 这一过程。Bert 原理或 Bert as service 还请移步官方文档。
依赖 python==3.6 tensorflow&amp;gt;=1.11.0  预训练模型  下载 BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  数据准备  train.tsv 训练集 dev.tsv 验证集   数据格式 第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。
fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!... houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客... game	赛季末用他们两天上一段，7.</description>
    </item>
    
    <item>
      <title>What is Data Mining 什么是数据挖掘</title>
      <link>https://kuhungio.me/2019/what-is-data-mining/</link>
      <pubDate>Sun, 17 Feb 2019 00:40:20 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/what-is-data-mining/</guid>
      <description> 一、数据挖掘的定义 什么是数据挖掘？  数据挖掘是一个用数据发现问题、解决问题的学科。 通常通过对数据的探索、处理、分析或建模实现。  数据挖掘学习路线  大学里并没有数据挖掘这么一个专业，现有的数据挖掘工程师大都来自工科或统计学等专业。 目前的数据挖掘工程师大都来自不同背景，计算机科学、数学甚至是机械工程。要想成功胜任，其诀窍是热情、好奇心，不断学习新的工具的能力，以及对数据清洗和分析的耐心。  给新人的建议  最重要的三个品质：好奇心、是非观以及批判性思考。这三个品质，放在其他领域同样适用。 专业领域的三种能力：编程能力、统计基础、商业思维。编程和统计在大学较为容易学到，商业思维需要多实践总结。  二、数据挖掘在做什么 数据挖掘工程师的一天  检查日常报表数据是否异常，寻求数据波动的合理解释。 针对新业务，设计指标，搭建数据模型。 搭建商品推荐系统、价格预测系统、文本分类系统或是聊天机器人。  数据挖掘的算法  使用复杂的机器学习算法并不能保证效果。一般来讲，最好的解决办法，通常很简单。 生产环境使用简单的算法，并不意味着要放弃前沿算法。每一套新的方法，其目的都在解决前面的薄弱之处。  数据挖掘与服务器  本地 PC 由于硬件与系统限制，工程师常在服务器进行大规模数据的运算、脚本部署与接口部署。   三、商业中的数据挖掘 作为公司，该如何开展数据挖掘  评估可能的收益与需要的投入 开始收集数据 招募数据挖掘团队  招聘数据挖掘团队  好奇心应该是数据挖掘从业者的最重要品质。 招聘时，应确保候选人对工作内容感兴趣。 候选人应具备一定的成果意识。商业更重成果，而不是过程。  数据挖掘应用  广告位点击预估 信用卡风控评估 用户流失干预  四、数据挖掘工具 数据挖掘工具与大数据  掌握以下工具：Python、Linux、Pandas 及 Jupyter、关系型和非关系型数据库。 大数据通常指传统数据系统无法处理的数据。体量和增速都相当大。处理工具以 Hadoop 为代表。  五、数据挖掘进阶 神经网络和深度学习  神经网络出现已数十年，但由于条件限制，这一方向搁置了数十年。目前随着新的优化方法的出现和算力的提升，这一方向的工业化逐渐成为可能。  如何更上一层楼  掌握基本的编程知识，更多地去理解背后的原理。 流程化意识，及时复盘总结，规范流程（复用）。 成果导向，将知识转化为行动和成果，给他人带来价值，服务更多人。  </description>
    </item>
    
    <item>
      <title>12306Bypass Server 给抢票神器加上微信提醒</title>
      <link>https://kuhungio.me/2019/12306bypass-server/</link>
      <pubDate>Sat, 26 Jan 2019 15:52:08 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/12306bypass-server/</guid>
      <description>前言 春节假期临近，车票一度紧张。某行、某团开了加速包后，仍然无法第一时间刷到目的地的票。稍微有点儿技术底子的我们岂能坐以待毙，自然是要自己动手，丰衣足食。
网上有各类开源的工具包，这里不做过多点评。之前在好友圈内传得比较靠谱的是 12306Bypass，又叫分流。分流是一个 Windows 应用，工作在 PC 端。其核心功能完全免费，更更重要的是，它的监控刷新在本地可以真实的感知。
以前在学校还好，可以守在电脑面前。但工作后，由于各种原因，无法第一时间获取分流的抢票信息，因而白白错过好几次下单付钱的机会。于是我们就有了这样一个愿望，希望能将分流的信息第一时间转发。
前几日逛某论坛，有人向分流开发者传达了增加 Server 酱的请求。开发者还是很给力，在最近的几次版本迭代中实现了该功能。简单的来说，Server 酱就是一个提醒服务。在这里，我们把它用在抢票软件中。当软件抢到票时，通过该服务，给到微信提醒。通知我们及时付款。
通过这样的形式，即可在微信端第一时间收到下订单的信息。那么如何配置这样的一个服务呢？我们只需要以下步骤。
​
准备工作  最新版本的分流软件 搜索关键词：12306Bypass  这里使用的版本号是1.13.30。 没用过？下载链接  Github 账号 这里用做 Server 酱的登陆认证  不知道？注册链接   实操阶段 Server 酱 用于获取认证的接口
 登入：用GitHub账号 登入网站，获取SCKEY（在「发送消息」页面） 绑定：点击「微信推送」，扫码关注同时即完成绑定  记住 SCKEY ，我们接下来会用着。
分流  启动分流，按正常流程配置票务信息。
 点选主界面左下角的推送
   填入以下信息
 通知地址 `https://sc.ftqq.com/[SCKEY].send
 通知参数 text=#bypass#    点击测试发送，即可在微信端，收到本文一开始的推送测试提醒啦  实际效果 就在配置完成不久后，分流帮我抢到了回家的车票。同时在微信端，Server 酱强制推送。
总结 通过这样的一番配置，我们终于能够安稳的玩耍手机，而不用担心错过订单付款时间。事实上，分流本身的基础功能，也自带了一些提醒服务。但是他们大多较为繁琐。以 QQ 提醒为例，有被顶掉下线的风险。自带的微信提醒，模拟的微信桌面登陆，理论上需要2个微信号。按照上面的操作，我们只需要简单的配置，即可实现强制推送，错过的几率大大减小。</description>
    </item>
    
    <item>
      <title>速查表 | Linear Algebra and Calculus 线代与微积分</title>
      <link>https://kuhungio.me/2018/algebra-calculus/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/algebra-calculus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>速查表 | Probabilities Statistics 数理统计</title>
      <link>https://kuhungio.me/2018/probabilities-statistics/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/probabilities-statistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why is Data Hard 为啥说做数据这行不容易</title>
      <link>https://kuhungio.me/2018/why-is-data-hard/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/why-is-data-hard/</guid>
      <description>原文链接 Slack 工程师 : why-is-data-hard?
做数据挖掘时，常常需要考虑很多方面。其中一个方面，常常会涉及到跨功能，复杂且琐碎的一些事项。数据准备以及评价指标的制定，就是这些事项之一。
等等，似乎干数据这一行，并不容易？
当大多数的组织谈到数据时，他们想的其实是指标——能反应近期业务、或是能够提供数据驱动的决策、抑或是能够监测企业经营状况的指标。
按上面的说法，我们应该能够招聘到聪明且能干的分析师，做出酷炫的可视化仪表盘，并马上投入使用。
 “Every second of every day, our senses bring in way [more] data than we can possibly process in our brains.”&amp;ndash; Peter Diamandis, Founder of the X-Prize
 拥有大量的数据并不会立马产生价值。当你是在数据增长快如 Slack 这样的公司处理数据时，不仅怎样驾驭数据和指标极其重要且困难的，更困难的是你像是在 “building the plane as it is flying”。
数据金字塔：评价指标（metrics）最为重要 数据金子塔大致可以分为4个级别。每一个级别都高度依赖下一级。
见解/洞察（Insights） 大部分的老板和公司董事关心的是这一层。见解（Insights）是我们所讲的关于数据的故事，即什么驱动了商业，或者是有什么新的机会能够推动大量的增长。
在理想的世界中，有一个共享的、不断演进的关于业务性能的数据叙述。这种数据叙述在整个组织中传播，以建立对业务的共同理解。
探索以及工具 为了获得见解，我们需要雇佣很多人定期去探索数据。只有当有人在盯着数据的时候，才能有策划和故事!
在快速增长的业务中，最优的数据探索涉及到一些关键事物：
 数据探查的多样性。要真正建立起，对正在发生的事情和重要的事情的理解和见解，我们需要每个人都拥有，对数据的关注和探索的主人翁意识。现实情况是，如果探索困难，只有管理员(分析师)能够完成这项工作。你要么雇佣更多的分析师来深入挖掘你的见解，或者，你可以找到简化数据访问的方法，让团队能够自行解决问题。Slack 的做法介于两者之间——我们不断寻找，在整个组织中增加自助数据服务的方法；同时也确保，我们有优秀的分析师参与到每一个核心功能来。
 频繁使用。像所有良好习惯的养成一样，查看数据和指标的一致性，是建立对所期望东西见解的唯一方法，什么样的结果是出乎意料的，什么样的问题是需要分析数据的。分析师可以帮助挖掘趋势，有些趋势值得挖掘，而许多趋势则不然。如果老板经常查看数据，那么你的分析师就更有可能对他们的精力，进行最优配置。
   例子：本周活跃用户增加了4%。这是好是坏？是预期的增长放缓?还是因为这周，我们推出了新产品，所以实际上我们希望的是，高于平时一周的增长?
分析师能够挖掘并做出各种比较，以帮助老板对数字进行说明。分析人士可以将该数字与往年做比较，深入了解这些新要素的组成，以及他们来自哪里。也许4%符合你的期望。但事实上，它比平时要低，我们没有推出任何新产品，且处于一个缓增长放缓期。这就是您希望董事会和分析人员构建的见解。你不会希望在某些事情上耗费精力，这些事情并不会带来业务的增长，或者改变我们的决策。
  发现能力与数据探索。数据探索不同于在仪表盘上点来点去，这是我想在这里指出的。仪表盘是用一组具体的需求创建的，通常在特定的粒度级别上报告指标或世界的某些视图。数据探索是一种能力，即通过各种不同的特征结合来调查指标，以确定在固定的仪表盘中不会立即出现的趋势或机会。可以将其考虑为，能够对数据进行转换和筛选，从而向监控之外的数据提出问题的能力。看到活跃用户的激增吗？太棒了！也许我们需要探究这在所有国家都这样，还是仅仅出现在英国。那周我们是否发起了一项针对英国的营销行动？销售团队是不是在那周完成了一个大单子?  企业主离数据越近，他们就越有能力着手进行自助服务的探索，就能发现更快捷、更有效的关键见解。这是因为，他们更有能力将我们在业务中所做的事情，与我们在数据中可能表现的特点结合起来。反之亦然！那些从商业伙伴那里拥有大量业务背景的分析人士，可以更快地找到正确的见解，而不是身陷各种假设之中。对于一个快速成长的组织来说，你可能希望两者都存在于你的组织中，这样每个人都能带着主人翁意识，理解我们最大的机遇和存在的差距。</description>
    </item>
    
    <item>
      <title>时序小结 | time series problem summary 时间序列问题处理</title>
      <link>https://kuhungio.me/2018/time-series-problem-summary/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/time-series-problem-summary/</guid>
      <description>Source https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion
总结一：保证数据同分布 验证集的选取，分布上应尽量靠近测试集。
 方式一:：对抗验证集的生成。 方式二： 就近选取相同天数。 方式三:：类比属性。如本赛题 &amp;ldquo;golden week&amp;rdquo; 与 &amp;ldquo;new year&amp;rdquo; 类比，选取 &amp;ldquo;new year&amp;rdquo; 段作为验证集。  tips: kfold 用在时间序列上不合适，会有数据泄露风险。正确的方法应是滑窗。
总结二：异常值特殊处理 一些特殊的时间节点（或者说是异常值），应该予以特殊考虑。比如本次比赛中的 &amp;ldquo;golden week&amp;rdquo;.。需要对其进行变换，而不是直接依靠模型的预测结果。
 方式一:：等同法   The rules:
Treat holiday as Saturday
If the day before holiday is weekday ,treat the day before holiday as Friday If the day after holiday is weekday ,treat the day after holiday as Monday it work not only golden week but also a lot other holidays.</description>
    </item>
    
    <item>
      <title>Single Shot MultiBox Detector Keras version</title>
      <link>https://kuhungio.me/2017/ssd/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2017/ssd/</guid>
      <description>SSD目标检测Keras版 SSD是一种Object Detection方法。本文是基于论文SSD: Single Shot MultiBox Detector，实现的keras版本。
 该文章在既保证速度，又要保证精度的情况下，提出了SSD物体检测模型，与现在流行的检测模型一样，将检测过程整个成一个single deep neural network。便于训练与优化，同时提高检测速度。 SSD将输出一系列离散化（discretization）的bounding boxes，这些bounding boxes是在不同层次（layers）上的feature maps上生成的，并且有着不同的aspect ratio。
 模型效果  模型对载具的检测  模型对动物的检测  模型的视频检测   如何使用 项目地址kuhung/SSD_keras
所需依赖 cv2==3.3.0 keras==1.2.2 matplotlib==2.1.0 tensorflow==1.3.0 numpy==1.13.3  如果想跑通视频模块，则需额外pip install scikit-video
具体操作 git clone git@github.com:kuhung/SSD_keras.git cd SSD_keras   Download model weight weights_SSD300.hdf5here  cp weights_SSD300.hdf5 into SSD_keras   对于图片的检测  参考SSD.ipynb
 若要剪切图片为下一步处理做准备  参考SSD_crop.py
 检测视频 bash cd video_utils python videotest_example.</description>
    </item>
    
    <item>
      <title>yysGAN 生成对抗网络，在游戏角色生成中的尝试</title>
      <link>https://kuhungio.me/2017/yysgan/</link>
      <pubDate>Tue, 21 Nov 2017 09:02:35 +0800</pubDate>
      
      <guid>https://kuhungio.me/2017/yysgan/</guid>
      <description> 使用GAN生成新的游戏角色 摘要 Generative Adversarial Networks（简称GAN），中文名叫生成对抗网络。我们将使用它，来生成新的阴阳师角色。 依赖 （pip install） cv2 tensorflow( &amp;gt;=1.0) scipy numpy  使用方法 cd yysGAN python yysGAN.py  5000次迭代训练结果 了解更多GAN的知识 Generative Adversarial Networks.ipynb
 参考资料  Siraj Raval moxiegushi/pokeGAN  项目地址 https://github.com/kuhung/yysGAN
定制你的GAN图片生成器 # 拆包即用，修改input下文件，改为对应的jpg素材即可。  </description>
    </item>
    
    <item>
      <title>Cats VS. Dogs 图像分类之猫狗大战</title>
      <link>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</link>
      <pubDate>Wed, 06 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</guid>
      <description>我是参加DataCastle猫狗大战的选手，kuhung。在测评中，我提交的数据集最后评分0.98639。以下是我的备战过程及心得体会。（最后有完整代码及较全面的注释）
个人介绍 华中科技大学机械学院的大二（准大三）学生，接触数据挖掘快有一年了。早期在学生团队做过一些D3数据可视化方面的工作，今年上半年开始数据挖掘实践。想把这个爱好发展成事业。做过阿里的天池竞赛，也有在kaggle混迹。算个数据新手，但一直不承认：你是新人，所以成绩不好看没啥关系。
初识比赛 第一次接触数据集，就感觉有些难度。因为以前没做过图片分类的比赛，更没想过要用深度学习的神经网络进行识别。思索一番，还是觉得特征提取后，使用决策树靠谱。自己也下去找过资料，发现并不容易实现。期间，还曾一度想过肉眼识别。但打开文件，看到那1400+图片，就觉得这时间花在肉眼识别上不值。中间一度消停。
初见曙光——yinjh战队分享 后来上论坛逛过几次。一次偶然的机会，让我看到了yinjh团队分享的vgg16模型。乍一看，代码简单、效果不错。更为重要的是，这个模型自己以前从未见过。于是抱着验证学习的态度，我把代码扣了下来，打算自己照着做一遍。
过程艰难 一开始，我就把一屏的代码放进了我的jupyter notebook中，一步一步试水。很明显，我的很多依赖包都没安装，所以也是错误不断。早先是在Windows系统下，使用python2.7，需要什么包，就安装什么包。在安装keras过程中，我发现了Anaconda——很好用的一个科学计算环境，集成了各种数据挖掘包。即使是这样，仍然是满屏的错误，亟待排查。
步步优化 离比赛截止就还只有几天，一边准备期末考试，一边焦急地排查bug。Windows系统下仍有个别难以解决的错误，我索性切换到了做NAO机器人时装的Ubuntu系统下。结合keras给的官方文档，我对原代码进行了函数拆分解耦，又在循环体部分增加了异常检测。综合考虑性能，稍微修改了循环结构。下载好训练的vgg16_weights，在没有错误之后，焦急地等待25分钟后，屏幕开始打印结果。
欣喜万分 第一次提交，随便截取了前面一段，没成绩。折腾了几次，才发现是提交的格式出了问题。后面取p=0.99+部分，提交结果在0.58左右，数据集大概有90个。估计了下，狗狗总数应该在180左右。第二次提交，取了180左右，结果0.97多一点。第三次，也是最后一次提交，取了result前189个，结果0.98639，一举升到第一。
比赛总结 这次比赛，首先还得感谢yinjh团队的yin前辈。如果没有您分享的代码，就不会有我今天的成绩。感谢您分享的代码，感想您在我写这篇分享时提供的代码指导。 再者，感谢我的女票晶晶，谢谢你一直陪在我身边，谢谢你包容我写代码时不那么快的回复手速。我是新手，但我一直不觉得成绩低是理所当。立志从事这一行，就需要快速地学习、快速地成长。新人，也需要做到最好。当然，自己目前还存在很多问题。一些基本的概念只是模糊掌握，需要更多的实践，需要更多的理论积淀，而不是简单地做一个调包侠。
给新手的建议  善用搜索引擎，多读官方文档，不要一开始就依赖Google。 Google Groups、Stack Overflow、GitHub是好东西。 干！就是干！  完整代码  以下操作均在Ubuntu14.04+Anaconda中进行
导入python标准包  import os # 处理字符串路径 import glob # 用于查找文件  导入相关库  keras
 keras是基于Theano的深度学习(Deep Learning)框架
 详细信息请见keras官方文档
   安装过程  conda update conda
conda update &amp;ndash;all
conda install mingw libpython
pip install git+git://github.com/Theano/Theano.git
pip install git+git://github.com/fchollet/keras.git
  cv2</description>
    </item>
    
    <item>
      <title>高效能人士的7个习惯</title>
      <link>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</link>
      <pubDate>Sun, 10 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2016/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/</guid>
      <description>第一部分：认识自我  一切探索的尽头，就是重回起点。——艾略特
 以原则为中心的思维  公平的原则 诚实与善良  以原则为中心，以品德为基础  由内而外强调，先追求个人的成功，才能有人际关系的成就;先信守对自己的承诺，才能信守对他人的承诺。  七个习惯&amp;ndash;大纲  习惯一：积极主动（BE PROACTIVE) 习惯二：以终为始(BEGIN WITH THE END IN MIND) 习惯三：要事第一(PUT FIRST THINGS FIRST) 习惯四：双赢思维(THINK WIN) 习惯五：知彼解己(SEEK FIRST TOUNDERSTAND,THEN TOBE UNDERSTOOD) 习惯六：统合综效(SYNERGIZE) 习惯七：不断更新(SHARPEN THE SAW)  习惯的定义
  习惯：知识，技巧，意愿  成熟模式图（成长三阶段）
 阶段：依赖、独立、互赖  有效性的定义
 效能：产出与产能必须平衡(P/PC balance)   第二部分：个人的成功：从依赖到独立 习惯一：积极主动  最令人鼓舞的事实，莫过于人类确实能主动努力以提升生命价值。&amp;mdash;-卢梭
 三种决定论  基因决定论 心理决定论 环境决定论  人类的四种天赋  选择的自由(freedom to choose) 想象力(imagination) 良知(conscience) 独立意志(independent conscience)  积极主动是人类的天性</description>
    </item>
    
  </channel>
</rss>