<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技巧 on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/categories/%E6%8A%80%E5%B7%A7/</link>
    <description>Recent content in 技巧 on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 12 Jan 2020 23:52:45 +0800</lastBuildDate>
    
	<atom:link href="https://kuhungio.me/categories/%E6%8A%80%E5%B7%A7/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>音频处理之人声提取：分离音频背景声，过滤空白</title>
      <link>https://kuhungio.me/2020/audio_progress/</link>
      <pubDate>Sun, 12 Jan 2020 23:52:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/audio_progress/</guid>
      <description>背景需求 在处理音频中，我们可能会有这样的场景：随着语音设备的能力越来越强，音频数据越来越大。但实际上，音频中的有效部分却很少，抑或是音频的背景声过大，非目标声音。在这样的场景下，我们希望得到人声，去掉噪声，提高信噪比。
问题界定 这里将问题进行界定，进行子任务拆分：
 将音频的背景声音去除， 去除“无声”阶段。  解决方案 要提高信噪比，这需求在很多场景中有见：比如课堂录音的提取，或者是录音笔的数据存储。
在使用本领域“高深”的技术前，一定要思考，切莫手上有锤子，就看啥都像钉子。想想该领域的专家会怎么做，如何从专业角度看待该问题；其次想想普通人会怎么做，防止落入经验主义陷阱。
背景声音的剥离，最简单的其实是音轨分离。其前提是两种声音存为了不同的音轨，在一些场景很合适。比如电话录音。
背景声分离 但是若只有一个音轨呢？别担心，机器学习来帮助你。spleeter 基于 tensorflow，训练了一套音乐检索系统，能够有效的分离人声和背景音乐声。
该工具已经进行封装，对于简单的人声分离，采用直接调取的方式即可。代码如下
# Use audio loader explicitly for loading audio waveform : from spleeter.audio.adapter import get_default_audio_adapter audio_loader = get_default_audio_adapter() sample_rate = 44100 waveform, _ = audio_loader.load(&#39;/path/to/audio/file&#39;, sample_rate=sample_rate) # Perform the separation : prediction = separator.separate(waveform)  空白切割 在分离之后，得到人声和背景声。人声分离后，仔细听，就会发现里面有很多空白。对于空白部分，进行切割分离。
这里参考 stackoverflow 的代码
from pydub import AudioSegment from pydub.utils import db_to_float # Let&#39;s load up the audio we need.</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>深度强化学习技巧 hacks for training deep RL 这是一篇旧文，John Schulman 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。 测试新算法的技巧  简化问题，使用低维变量。  使用类似只有角度和速度两个变量的 Pendulum problem 问题。 这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。 当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。   构造一个 demo 来测试你的算法
 比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。 这样能够轻易地发现那里出了问题。 注意：不要在这样的小问题上过分的尝试。   在熟悉的场景中测试
 随着时间的推移，你将能预估训练所需的时间。 明白你的奖赏是如何变化的。 能够设定一个基线，以便让你知道相对过去改进了多少。 作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。   快速上手新任务的技巧  简化问题  从简单的开始，直到回到问题。 途径1： 简化特征空间  举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。 一旦起步，逐步还原问题直到解决问题。
  途径2：简化奖赏函数  简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。 比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。    将一个问题转化为强化学习的技巧 可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。
 第一步：将这个问题使用随机策略可视化出来。
 看看那些部分吸引了你。 如果这个随机策略在某些情况下做了正确的事，那么很大概率，强化学习也可以做到。</description>
    </item>
    
  </channel>
</rss>