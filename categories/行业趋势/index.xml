<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>行业趋势 on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/categories/%E8%A1%8C%E4%B8%9A%E8%B6%8B%E5%8A%BF/</link>
    <description>Recent content in 行业趋势 on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 18 Jun 2020 23:18:26 +0800</lastBuildDate>
    
	<atom:link href="https://kuhungio.me/categories/%E8%A1%8C%E4%B8%9A%E8%B6%8B%E5%8A%BF/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>数据挖掘与风险控制，游戏反作弊的银弹在何方？</title>
      <link>https://kuhungio.me/2020/game_anti-cheat/</link>
      <pubDate>Thu, 18 Jun 2020 23:18:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/game_anti-cheat/</guid>
      <description>游戏反作弊，一直是各大游戏厂商头疼的问题。究其根本，游戏，本身是一种软件产品。交付到用户侧时，你永远无法穷举，玩家会怎么使用它。只要有利可图，就会有人去钻空子。
为了反作弊，各大厂商，也是用尽各种手段。除了内部的反作弊团队，还有法务团队的律师函警告，甚至直接招安外挂开发者。说到底，游戏反作弊，有没有一个终极方案呢？
数据挖掘，说是近5年的火热技术，没得跑的，甚至连电视剧里，都开始出现这个职业的主配角。
这个职业，被寄希望于做炫酷的事：在庞杂的用户数据中，找到其特有的规律，找到导致现状的原因、预测未来的发展。数据挖掘，在游戏反作弊，可以做些什么吗？
数据挖掘 整体行业概况 数据挖掘行业，如今有如下两个趋势：一个是计算广告，及其相关的推荐系统。这套东西，是信息流产品的核心。扩展开来，包括用户画像、用户生命周期等内容。
另一个，集中在敏感内容、反欺诈的识别上。这个方向，只要用户生产内容，就不可避免。换而言之，是 UGC 内容平台、活动平台的刚需。同时他又是一个劳动密集型工作，很适合用机器节省人力。
游戏中的数据挖掘 在游戏领域，数据挖掘又分为两个大方向。各个公司的AI lab，会去研究一些前沿技术。诸如强化学习、或者是迁移学习的事。满足玩家个性化的需求。其特点是：前瞻性强，复用性高，但落地困难。
而在业务侧，围绕玩家生命周期展开：渠道转化预估，异常渠道的识别、高潜玩家发现、流失的预测等。其特点：复杂多样、垂直性强，常需要单独建模。
游戏内，对于一个用户的刻画，十分具体。从基本的在线、消费；到玩法偏好、好友关系，都会有专门的标签画像。这些画像，帮助企业更好理解玩家，提供更细致的服务，达到 win-win 的目的。
对于多产品的公司（如：网易），数据互通，是其最迫切的需求。各产品数据独立，制约了它的社交属性，虽然在“洗用户”上表现克制，但数据资源白白浪费。如果是一家正在扩张业务线的公司，需提早防范：数据壁垒的出现。
如果把游戏反作弊抽象，实际也是风险控制的一个环节。风险控制有哪些注意事项？它的核心是什么，又该如何去应对挑战呢？理解风控的这些知识，有助于我们做好反作弊。
近现代风控，起源于二战后。而后迅速发展，形成以：金融业风控为代表的垂直学科。而随着80年代互联网的发展壮大，各类风险，也随之而至。
如今，互联网上的羊毛党，垃圾信息、黑产随处可见。和正常内容，争夺着用户的注意力。同时也影响着业务安全。在业务侧，安全业务可分为两类：一类是静态的账号、内容安全；另一类则是动态的行为安全，诸如活动安全等。
风控领域浅析 风控的核心 谈起金融的核心，大家的第一个念头，一定是风控。而风控的核心，则是成本控制。而成本，则不是简单的金钱成本。除了财力、物力、人力，这样的企业端成本，还应该注意，用户侧的成本。比如：用户体验的成本。
如今，互联网上，打开app前10s流失的用户，其数量之大，很可能超乎你的想象。如果为了风险控制，而过分牺牲用户体验，其实是得不偿失的。如12306的验证码，它的本意是防范刷票风险，若图库的区分度小到极端，则是过分牺牲了用户体验。
除了资源成本和用户体验成本，还有一个容易忽视的，是企业的信用成本。虽然互联网的记忆，只有短短7天；玩弄话术，运用公关手段，能够消除一时的风险。但对企业长期的公信力，其实是一种消磨。
产品出问题了，还可以修补。信用丢了，那就找不回了。
风控的挑战与应对 风控，显著性地，不同于其他业务。其他业务，存在的业务逻辑失效，是来自场景、数据、时间的漂移。即，随着时间、事态的发展，运用场景、数据表现产生了分布上的改变。而风控，则来自于强烈的对抗。道高一尺，魔高一丈。
传统意义上，为了应对风险，衍生出4种模式：
 回避风险 控制风险 转移风险 承受风险  一般来说，企业主要精力，花在控制风险上。不是所有风险，都可以回避。在控制风险的同时，也可转移部分风险，最后准备承受风险。这部分，在之前的文章《浅谈互联网风控——从策略到技术》有详细介绍。
策略上，分为前中后。前：打标签，标记风险用户、风险内容。中：拦截风险，对高危操作进行干预。后：回顾每个环节，堵住漏洞。同时辅以核心指标的监控，在所有措施失效时，留一手兜底措施。
技术上，给用户准备丰富的画像，从自然人、设备、账号等角度，刻画用户。用以支持风险的识别，策略的实施。
最后，别忘了它的对抗特性。这要求我们，持续不断的演进技术、策略和手段。
游戏作弊，其实就是游戏内的风险。它不仅会影响游戏产品的体验，使产品走向，偏离策划的初衷。更会影响玩家间的平衡，进而影响产品的营收。更进一步的，让游戏失去吸引力，导致产品失败。
游戏反作弊 作弊的形式及手法 谈到作弊的形式，不妨从一个玩家的角度出发。为了获得碾压感，满足感，玩家会从以下方面入手：
 为了获得满足感，玩家会修改道具获取逻辑，不付费、或者修改货币值，获得道具和服饰。
 为了获得数值上的优势，调高伤害、减轻承伤。诸如“无敌”或者“锁血”，可属于这一类。
 而对于时间换物资的“肝”玩法，则通过修改产出逻辑、或改变游戏内的时间节奏获取。
 而在信息不对称玩法中，则通过读取数据，以此获得优势。例如：吃鸡游戏中的透视。
  上述的种种作弊，其核心在于数值，其次在于程序逻辑。因此，在客户端，玩家可通过注入代码、读取内存实现。在客户端与服务端通信过程中，还可伪造中间人，截取、修改数据。更甚至，反编译游戏包体，生成一个看似一样的安装包。修改内在逻辑，重新打包。
游戏反作弊的业务逻辑 反作弊业务逻辑中，最重要的一环，是误判的处理。在作弊识别上，我们可以达到99.99%的准确率。但那万分之一，也是一个鲜活的玩家。如果误判了玩家，怎么办？除了提高准确率外，还应健全机制，预留申诉、回旋的空间。不至于，因为莫须有的判罚，让忠实玩家流失。
在技术层面，游戏开发时，会有两个地方进行校验——客户端与服务端。客户端，通过基本的签名校验，保证不被篡改。服务端，则对发回的数据，再次校验，综合其它数据，进行判断。数据挖掘起的作用，则是发现、总结作弊模式。在进行业务处罚的同时，反馈到开发过程中。
效果检查方面，游戏反作弊，又有其特殊性——不可证伪。不同于广告的点击，有明确的反馈。如果一个玩家，模型说他作弊，但他声称自己没作弊。那到底，是谁有问题？
在其它业务，会用客户投诉率，作为服务质量的考核。但客诉率在这里，不是一个好指标。因为，对作弊的处罚，势必引起玩家的不瞒，投诉中真假参合。
真正应当关心的，是核心指标的变化。比如，作弊让游戏内某项资源，产出大幅加倍，我们的效果指标，则应该是该资源的产出率。
而对于实锤作弊玩家，作弊的处罚，也不仅仅局限于封禁。在强社交游戏中，封禁他的社交行为，也是一种惩罚——即能警示其它玩家，又不至于影响正常游戏行为。除此之外，对于对抗类游戏，play with cheater，也是可行的思路。
最终目的与终极方案 游戏反作弊，更像是电子世界里的警察——打击罪犯，惩恶扬善。反作弊系统，能发现并打击作弊，但想彻底根除，只有一条路：关闭服务器。所以，反作弊的终极目的，不应当是：根除所有作弊；而是，赢得玩家信任。用各种手段，减弱不平衡，保障正常玩家权益，建立玩家对系统的信心。
前段时间，云游戏出现在大家视线。除了不受终端限制的便利外，媒体更是惊呼：“这是作弊者的末日！”。因为，客户端和服务端都不在玩家侧。但仔细想想，云游戏，真的是反作弊的终极方案吗？替考是作弊，AI 替打游戏呢？物理外挂，算不算作弊呢？
所以说，反作弊就是个开放世界游戏，当你以为快通关时，又会有新的冒险，等着你出发。</description>
    </item>
    
    <item>
      <title>我为何离开网易游戏——从个人商业模式角度，谈谈离开中国第二游戏公司的原因</title>
      <link>https://kuhungio.me/2020/why-i-left-netease-games/</link>
      <pubDate>Wed, 13 May 2020 00:41:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/why-i-left-netease-games/</guid>
      <description>前言 网易游戏是我毕业后的第一家公司，说没有感情，那是不可能的。当然，这感情主要针对那里的同事和朋友。
网易又叫猪场，猪场曾一度有最好吃的免费食堂，一度给名校毕业生开最高的工资。
在数年前，大话西游2帮助公司起死回生。
而后开发的梦幻西游，成了公司最强的现金流来源。
2016年阴阳师爆款，几乎成了全民游戏。
2018年，加入网易游戏，带着自豪感。因为它说：用心做游戏。
2020年，离开网易游戏，矛盾夹杂着解脱。
当知道我离开网易游戏时，许久没联系的朋友，都感到十分吃惊：这可是头部互联网公司，好多学校的人根本没资格进入；但熟悉我的朋友都知道，这件事已经“蓄谋已久”。
这其实源于一些观念的冲突。
我本人关于工作的信念是：个人以一定价钱出售其劳动产出。个体与组织的关系，是合作而不是卖身。
正如《软技能》一书所言，改变打工心态，把自己当公司经营，现在的公司是个大客户，仅此而已。
下面，从商业模式，特别是个人角度，来谈谈离开网易游戏的原因。个中原因，很多亲近的人，都未必知道。
商业模式个人篇 核心资源 商业模式中，很重要的一点便是：核心资源。即我是谁，我拥有什么。这个问题颇有——我是谁，我从哪里来，我要到哪里去的意味。
一般年轻人认为，我拥有用不完的精力，因而相较于更年长的员工，我的核心竞争力在于可以加班。
这样的想法大错特错。年轻是试错的机会，而不是让人无故内卷。没错，这样的“一般年轻人”便是两年前的我。
什么是核心资源呢？稀缺的是核心资源。人无我有、人有我精的，才是核心资源。
从这个角度想下去，所具备的技术技能、行业积累，以及对新事物的热情，才是真正的核心资源。
关键业务 关键业务，简单来说，就是每天所从事的事情。
但这里，根据28定律，20%的工作，产生80%的绩效；所以这里的关键业务并非指剩下80%的工作。
什么是80%的工作呢？在数据挖掘这个领域，80%的时间是在产出数据，保证数据的及时响应。
每天的取数工作，这个岗位的从业者有了新的绰号——取数男孩（茶树菇）。
剩下20%的工作，在提供数据的洞察。关于数据的过去与未来，溯因与预测，提供基于数据模型的决策方向，才是岗位的关键业务。
而80%的非关键业务，应当想方法标准化、自动化，以提高效率。而不是每天用 excel 做各种变换，洋洋洒洒写一份无人执行的分析报告。
客户群体 客户群体，是商业模式中的概念。正如一开始所言：公司，其实就是我们的大客户。
公司内的直接上级、boss、或者其它部门的人，都可以是我们的客户群体。
在这些客户群中，有人认为，向上管理是第一位的。即：做好上级和上上级的需求，服务好他们，才是升职加薪的正确之道。
这点上，我只同意一半。哪一半，后一半。即服务好我们的客户，才能赢得信任，才能得到更高的回报。
向上管理没问题，但向上管理很多时候成了唯上。我们的客户，是上级、是团队、更是整个公司。服务好每个部分，同等重要。
价值服务 这个概念是商业模式中，最重要的，因为它决定了你的定价区间。
简单来讲，我给客户提供的服务，帮助客户完成事情，其背后的价值，才是真正的价值服务。
价值服务和关键业务容易混淆。关键业务是干的活，而价值服务则是干的活所产生的价值意义。
同样的，有人认为，公司招聘我，就是买断了我的时间。而不去进行更深层次的思考。
实际上，买断一天8小时的时间，只是表象。客户期望的是能产出有价值的东西。如果这样想，就会明白，时间不是关键，给公司带来的价值才是。
渠道通路 渠道通路，简单来讲就是，如何宣传自己、以及如何交付服务。让别人知道自己能做的事情，且能够交付服务。
这里关键的问题在于，潜在客户如何知道你能帮助他们、是如何下定决心的、是如何购买的；以及如何交付及售后。
酒香不怕巷子深，这是很多技术型同事的想法。会觉得有了自己的东西，才能更好让客户接纳自己。
这个观点没错，是一种踏实务实的想法。但仔细想想，宣传服务和打造服务之间互斥吗，并不互斥。
只有找准自己的价值服务，并进行宣传，才会有买家认账。不管这个买家是领导或是别的团队。只有卖出去了，才会有实际的回报。
客户关系 客户关系讲的是如何和客户打交道。
是直接沟通，还是远程服务。
是一锤子买卖，还是长期性的维护。
是拓展新客户，还是维系老客户。
一般来说，公司招聘员工，希望的是能做持续性的项目。
但某些考核标准下，如按项目分成模式，持续性项目就少有生存空间。
自上而下，希望立足够多的项目，借此来分得一杯羹，因而出现了炒冷饭的情况。
最后面向晋升编程，晋升过后无人维护、一地鸡毛。n年过后，该项目又被下一个人立项。
项目失败不可怕，因为可以从失败中总结教训。可怕的是不断的立项，在公司内做一锤子买卖，造成无端的资源浪费。
重要合作 合作一般基于交换，这里的合作，指的是谁可以帮我。
他们可以是家人、同事、是导师、也可以是同一职业的其他人。他们提供帮助、建议和成长机会；提供必要的资源。
作为互联网新生代，信息不像之前闭塞。虽然信息茧房确实存在，但互联网确实是重要的合作对象。
而在公司中，提供资源和方向的一般是直接上级。
收入来源 简单来讲，大伙儿的收入来源是工资；其次，少部分收入可能来自于股票、基金或者房屋出租。
打工的主要收入来源便是工资。这里存在两个问题：
一是，工资奖金上涨带来的愉悦，存在边际递减效应。即同样的涨幅，越到后面越没感觉。更别说大部分人薪水几乎无变化。
其次，单一的收入来源伴随着风险。不管和领导关系多么密切，公司现金流多么充沛。小概率事件必然发生。
破解这两个问题的方法在于：
工资到了一定水平后，需要关注精神的满足。工作的成就感和社会贡献，就显得尤为重要。</description>
    </item>
    
    <item>
      <title>浅谈互联网风控--从策略到技术</title>
      <link>https://kuhungio.me/2020/risk_management/</link>
      <pubDate>Sun, 22 Mar 2020 14:34:33 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/risk_management/</guid>
      <description> 风控，全称风险控制，英文名 risk management。风控的研究起于二战结束后，主要集中在个人或企业的商业保险领域，用于减少突发事物带来的损失。金融行业的核心，乃是风险控制。
但今天，我们这里不谈金融的风控。金融风控已经演化了多年，众多顶尖学者已对其进行了研究，各种模型层出不穷，自有人去分析。我们这里说一说，互联网的风控。
风控的核心 如果你在网上检索，一定会发现很多人，谈到风控，必加智能，似乎不智能就不风控了一般。有人说，风控的核心是智能；也有人说，风控的核心是数据。这些老生常谈，将数据智能看成了银弹，看成了哆啦A梦的百宝袋，能解决一切问题，但其实这种说法忽略了现实。
那现实是什么呢？如果你问，风控的核心是什么。很多人可能回答不上。但你问，为什么你要买保险，很多人的回答会是，不怕一万、就怕万一，保险能够兜底未来可能的大额支出。用小额保费对冲小概率但大支出的以外，换而言之，就是一场成本核算。
成本控制的两个方面 风控对于成本的控制，在互联网主要体现在两个方面。一个是资金成本。搞活动，不能被薅羊毛的搞破产了。或者搞个特牛的模型，能识别所有的风险，有且只有一个缺点，要用上全球一半的计算机（费钱）。另一方面，是体验成本。互联网风控，免不了嵌入业务，但如果过于突兀，很可能影响用户体验。这方面的典型，极端就是恶搞的12306验证码识别。
风控与信息安全的异同 风控这个业务，和信息安全中的加密很像。当破译的难度大于潜在的收益时，加密方式其实就安全了。没有不计成本的密码破译，也没有不计成本的风险控制。风控要做的，也是某种程度的平衡。
但同时，风控和信息安全也有不同之处。
在互联网业务中，风控的对象一般会有两种形式存在。一类是静态的账号，比如恶意的初始号，或者是盗用、冒用的他人账号。另一类，是其动态的活动。具体表现为账号主题生产的内容，或是其参与的活动。而信息安全，主要是软硬件的漏洞，再加上社会工程中人性的漏洞。
风控的挑战与应对 最明显的挑战在于，敌在明我在暗，同时由于对抗手段的加码，对方会找到规避的手段，或是找到风控的系统漏洞。
风控策略与技术 在传统风控中，应对风险有4种基本思路。
 回避风险。即如果我知道你有风险，我就回避掉你。这会带来一定的损失，俗话说，风险伴随着收益，回避风险，在互联网业务中，有些能回避，有些则不能。对于政策风险，法律风险，该回避的则回避。对于不能回避的风险，我们采取下面的措施。 控制风险。这是互联网风控的主要内容。如果控制风险，从风险的酝酿、到风险的暴露，再到风险的控制，每一个环节都有可为。 转移风险。这个措施更靠近业务。通过将风险转嫁，或是共摊，来实现风险的控制。举个例子：平台将风险分散到平台与商家之间，或是将风险在声明中转移到UGC内容的用户上。 风险承受。最后这个措施，是风险的兜底措施。即承担风险带来的损失。这一般要求有资金的预留或是退路的预留。  策略 互联网的风控策略，可分为两部分。一部分是业务侧，通过一系列手段，去削弱风险。另一方面，则是宏观侧，通过数据监控整体的业务情况，进行风险的宏观判断。
在嵌入业务的一侧，可按风险行为分为前、中、后三个阶段进行。
 风险发生前：通过技术手段或用户引导，完善用户资料。同时对用户的基本信息进行分析，将明显特征的账号进行标记。该部分，成本和复杂度都较低，适合作为风控策略的主要部分。同时，可通过关联分析，将问题范围缩小，从账号、自然人、到工作室，集中处理。 风险进行中：这部分一般和用户的行为有关，也常常嵌入业务中。常见的如 UGC 的违规内容，色情、暴恐信息等。这部分，像豆瓣，在检测到关键词后，会进行先审在放行。另一个例子则是，12306的验证码，通过人机验证，规避机器人。 风险已发生：尽管手段丰富，但仍有“漏网之鱼”。一旦风险成为既定事实，则需要采取措施应对。一方面，是做好风险的应对，另一方面，则是及时复盘，对现有体系进行审视，避免机制上再出问题。  最后的，无论无论风控做得多好，总会有黑天鹅发生。做好应急预案，有兜底的策略，都十分重要。小概率事件必然发生。风险的发生是常态，无风险其实才是少有的异常状态。要做的就是，在风险发生后，减少风险造成的损失，让系统及时重上线。
技术 策略看起来很简单，但实际操作起来，困难重重。很重要的一个原因是，信息不对等。举个例子，知道该对问题账号处理，但是不知道哪些是问题账号。这里就需要技术来消除信息不对等。
这里就要请出用户画像。一般的，用户画像被用来理解用户，做更好（更上瘾）的视频推荐，做更精准的广告投放。而在风控领域，用户画像的作用，同样显著。
用户画像背后的技术，除了实打实的工程技术外，产品引导也十分重要。对于冷启动策略，通过引导，完善用户信息。更一般的，则是通过标签规则，通过一系列 if else 判断，生成用户标签。同时，对于社交产品，还会有好友关系链，通过社交图网络的挖掘，也可得到有用的信息。
在风险进行中，采用嵌入业务的干预手段，需要实时流计算，这方面有很多好的开源软件，或者是采用像 Prometheus 一类的开源监控软件。如果资源允许，还可做一些时序上的预测。对未来一段时间的数据，给出预测的上下区间，一旦超过，即调起报警。
在风险发生后，对样本的复盘，实际是异常检测。异常检测一般分为两类，孤立状态的点或块异常，或者是上下文相关的时序异常。其核心，是不平衡样本下的分类。这里的检测可以是对用户行为数据的检测，也可以是用户产出内容的检测，如图片检测、文本检测，这方面的技术已经很成熟，数据量足够，质量够高，即可保证高的准确率和召回率。
最后，在泛化能力外，技术还应注意其可解释性，以及可更新的能力。即模型越简单越好，如奥卡姆剃刀所言：“如无必要，勿增实体”。同时，减少数据中的噪声。在上模型或规则前，探索数据、剔除常变量、剔除离群点，通过xgboost等获得特征有效性、对关键有效特征进行筛选。
总结 互联网风控，是风控的一处延申。除风控的基本特点外，也带有其自身的特点。策略上，需要嵌入整个业务流程，同时准备兜底策略。技术上，有数据挖掘的手段，增加风控的效力。
以上总结来自于工作实践和阅读思考，难免受自身局限，如有疏漏，还请读者批判指正。
互联网风控思维导图
关于作者
参考资料：
 QCon 阿里毫秒级实时风控引擎
 Risk Management: History, Definition, and Critique &amp;ndash; Georges Dionne
 风控算法大赛解决方案&amp;ndash;不得仰视本王
  </description>
    </item>
    
    <item>
      <title>更高效的远程工作之道--REMOTE 手册精要</title>
      <link>https://kuhungio.me/2020/remote/</link>
      <pubDate>Sat, 07 Mar 2020 17:43:44 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/remote/</guid>
      <description>大规模远程工作实践 远程工作，一个之前都没怎么考虑的事情，在2020年的春节过后，中国大陆进行了一次大规模实验。WFH（work from home），一个在外企很常见的操作，在国内却鲜有生存环境。
虽然朋友圈已经有人发帖，渴望在办公室中办公，但是，也不能因此，就放弃思考远程工作的这么个事物。一成不变往往很简单，但变化之中，才有契机。
远程工作契机 什么阻挡了远程工作的推行，我们无从说起。但何不把这次当作一种契机，去学习其中的脉络。
关于远程工作，找到了一本小册子《Remote》，专门介绍远程工作的。作者也写过另一本书《Rework》，中文名重来 。写书虽说门槛不高，但是写出有说服力的书，具备条件的人往往很少。作者以其自己的公司 Basecamp 为例，说明了远程工作的优点，也向我们介绍了远程工作的注意事项。读懂它，你的远程工作事半功倍。
远程工作迷思 在书中，你可能看到自己的影子，也可以看到老板的影子。无论你是老板，还是打工者，其中的内容都值得细细理解。
拒绝远程工作的理由 只有在办公室，办公时间才是有限的 远程工作，不是一个新鲜事物。至少在作者这个书出版之时，到2020年，已经过去了7年。远程工作改变了集中式办公的缺点，时间被切割，无穷无尽的会议。但其自身也有适用范围，比如写作、编程、设计和客户支持等工作。像制造业，可能就不太现实。很多人对远程工作嗤之以鼻，常抱着努力干活，等我退休了，再来享受生活的态度。老板们顾及远程工作，很可能是担心没了约束，员工的拖延症很可能无限放大，毕竟谁都有拖延的时候。做好工作，而不是死守工作时间。
如果我能看见他，我才能控制他 远程工作，在2020春节之前，一定是有很多反对声音的。比如，缺乏讨论的氛围，公司没有源源不断的点子，这怎么行。没准下一个点子就能颠覆乔布斯。但实际上，我们知道，很多人还在执行几个月甚至几年前的一个点子。有员工认为，家里的干扰太多，琐事不断打扰。但实际上一份有成就感的工作，不会让你轻易被打断。而管理者，会觉得，没有盯着他们，怎么知道他们是在干活，还是躺在床上玩手机。但实际上，就在眼皮子底下，员工也有无数种方法摸鱼。如果不信任他，一开始就不该雇佣他。
别的公司都没这样做，我为什么要做 在团队内部，一个组这样做了，另一个组会嫉妒。但跳出这个逻辑，整个组织目标一致，效率最高才是最终的赢家。再一个，业务部门或者上级会觉得，我现在就要答案，现场能有更高的压迫感。但实际上，并不是所有事情同等重要。再一个，中小型企业会认为，BAT 大公司都没远程工作，肯定有他的不好，马某人都是聪明人，不可能没调研过。但实际上，你跟着大公司的脚步，永远成不了第二个马某人。远程工作能不受地域限制，网罗到世界各地的人才；有些时候，性价比更高。
远程工作精要 远程工作，在2020春节之后，大伙儿已经有了足够多体会。作者的公司长期远程且稳定盈利，他总结了以下内容。
及时同步进度 重要资料公开，而不是让人到处询问，让被询问人工作量加倍。展现工作进度，以成果导向。及时向团队内部公开。承诺往往有更高的约束力，而且，同行肯定比非技术领导更懂所需的工作时长。于此同时，做防灾的准备，诸如数据备份等工作。如果工作需要同客户合作，还需注意，及时将进度同步给客户。
打造良好团队氛围 对于团队内部，保持正向的氛围，阻止消极负面的情绪在团队内部蔓延。聪明且及完成任务，才是合适的好员工。用当地最好的薪水留住他们，而不是因地施策。关心员工的身心健康，担心过度劳累，而不是懒惰，因为可持续才能走更远。最后，保持一个强劲的动力，鼓励员工从事自己喜欢的事物。
员工如何出众 而对于员工，如果你想在团队内出众，往往有两种方法。一个是在保持活跃，另一个就是高质量的交付任务。
关于作者</description>
    </item>
    
    <item>
      <title>Dataops 数据化运维实践</title>
      <link>https://kuhungio.me/2019/dataops/</link>
      <pubDate>Sat, 19 Oct 2019 11:33:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/dataops/</guid>
      <description>翻译自：《What is DataOps? Everything You Need to Know》 From Oracle Data Science Blog
图片自：《DataOps is Not Just DevOps for Data》By DataKitchen in Medium
 DataOps, 看到它的第一眼，大多数人会觉得陌生。但是提到另一个词——DevOps，做开发的同学可能会有些熟悉。DataOps 的理念与 DevOps 类似：将开发或者说是数据，与运维、测试相结合，自动化业务的交付以及架构的变更，使得构建、测试和发布能够更加快捷、频繁且可靠。
DataOps，全称 Data Operations，是一种敏捷运维方法，无感知地将IT基础设施和大数据分析技术结合起来。它的目的是通过结合数据管理的目标与过程，加快分析的速度与准确度。而这一过程，通常会涉及数据的多个流程：数据获取、数据质量检查、自动化、集成，以及最终的模型部署与管理。
最核心的，DataOps 是为了方便管理数据、特别是当你有了一个特定的数据目标的时候。举个例子：为了降低客户的流失率，可以通过利用客户数据构建一个推荐引擎，推荐客户相关的东西，以此来减少浏览到下单的时间，减少客户流失。
这是一个很自然的想法，但是却并不是一件容易的事情。上面的设想需要以下条件：
 你的数据科学团队能够获取到他们需要的数据，同时能够有工具去部署模型。 除此之外，还需要能够将模型集成到你的网站中去，在新数据上训练以持续的改进。 最后，需要一套报表系统来监控其表现。  现在比较流行的做法，做好上面的事情，需要多个部门的合作，包括工程师、IT运维人员以及业务团队。
谁能从 DataOps 中获利？ 总的来说，几乎所有人都会从 DataOps 中获利。
 更好的数据管理将会带来更多可利用的数据； 越好的数据质量会有更准确的分析，与之相伴的就是更好的 insights、商业策略以及更高的利润。  DataOps 起一个润滑剂的作用，使数据团队、工程师团队和技术专家之间的工作更加紧密、更加自动化，以此来充分发掘数据价值、减少时间。
Ashish Thusoo，Qubole 的联合创始人曾在书籍《Creating a Data-Driven Enterprise with DataOps》写道：我在2007年的夏天加入 FaceBook 的数据团队。像平常一样，公司里的任何人想获取无论多小的数据，都不得不找到数据团队，并发起流程。我们的数据团队很优秀，但是他们的精力也有上限。很明显，这是一个瓶颈。
DataOps 这一概念从何而来？ DataOps 起源于 DevOps 这一概念。据了解，财富1000强的公司里，80%的公司已经采用了 DevOps 这一方法。DevOps 的成功主要仰仗于：它把之前独立的两个部门联合在了一起——开发和运维。在 DevOps 的世界里，软件的发布是迅速且持续的，因为整个团队都被整合在了一起，用来检查并处理当下的问题。</description>
    </item>
    
    <item>
      <title>机器学习实践--测试驱动开发</title>
      <link>https://kuhungio.me/2019/tdd_drive_ml/</link>
      <pubDate>Sun, 25 Aug 2019 00:22:07 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_drive_ml/</guid>
      <description>机器学习现状与问题 2012年，数据科学击败生命科学，成为”21世界最性感的职业“。2016年，AlphaGo 战胜人类顶尖围棋手，深度学习、人工智能一度占领新闻头版头条，并引起一股机器学习新热潮。
这一效应，一直持续到今年：在2019这一年，高考志愿填报金融遇冷，计算机一跃成为抢手专业，在各大工科院校中，有取代传统电气、机械之势；各学院的研究生院，纷纷开始往人工智能、深度学习上贴近。
这从一个侧面，反应了民众对于计算机、人工智能、机器学习的就业预期。但是，随着原来越多的从业者涌入，项目落地越来越多，机器学习这一领域的问题也开始暴露，亟需解决。
机器学习中的常见问题 机器学习的问题，由其特性所致。众所周知，机器学习的发展，离不开大数据技术。海量数据的收集、存储，让算法有了更强大的生命力。通过对大量数据的挖掘、学习，机器学习能够猜你所想，提升购物网站的转化率；能够识别障碍，让自动驾驶成为可能；能够识别风险，扩大业务同时减轻坏账。
由此，针对模型和数据的关系，大致可以分为三类问题。第一种：数据量不足，模型过拟合。算法学习的过程就犹如考前刷题，过拟合相当于只刷一套题，这样的后果就是上一套不同的卷子，算法就懵逼了。第二种：数据量充足，模型欠拟合。欠拟合的算法就像是心思不在学习上的孩子，报再多的补习班，结果也不会太好。最后一种：数据不稳定。算法前期可能很好的学到精髓，但是随着数据的变化，时间的流逝，模型很可能将变得不可预测。
测试驱动开发的解决之道 机器学习的实现方式还是通过软件工程、代码实现，既然是代码，那就存在应对范式。这里，就不得不提 Test Driven Development（测试驱动开发），简称 TDD。TDD 是一种很朴实的想法，在编码开始前，评估需要交付的功能点并写测试用例，一开始的时候测试会失败，接着编写代码修复测试，最后测试通过，修复代码。这里的方式，通俗来讲就是：目标导向，先成事，再迭代。
测试驱动有一个明显的好处就是，能够加快产品发布速度。以往的项目，需求讨论会占据很大时间，讨论完之后，开发方案一旦定下来，后续变更就很难。而现实却是需求常常变更，这往往会导致产品发布的延期。而在机器学习上，测试驱动好处更多体现在保证模型质量上。具体来讲，常通过以下办法：
 交叉验证 通过交叉验证来验证拟合效果 运行速度测试 根据奥卡姆剃刀原则：”如无必要，勿增实体“；简单模型胜过复杂模型 衔接测试 对数据的输入输入进行检测，以防止数据异常波动对模型影响 指标追踪 监控关键指标，不断追踪模型的性能，防止失效模型继续运行  机器学习的债务危机 测试驱动开发一定程度上能减轻机器学习中的问题，但是它只是一种表象。测试通过了，不代表算法模型就没有问题了。魔鬼藏在细节中。机器学习目前仍存在一些技术债务，仍需按特定原则对代码修复，迭代演进。
什么是技术债务 技术债务是一个比方，类比的金融领域的债务。一般指为了加快软件开发速度，折中妥协，选择易于实现的方式，结果是短期加速了软件开发，但长期来讲，开发负担累计，发布逐渐停滞。债务不都是有害的。在业务扩张，市场抢占时期，适当的债务有助于公司扩张。但是若一直不管不顾，最后只能花更大的成本去维护它，直至无法维护。
机器学习中的技术债务 机器学习项目中同样存在债务危机，Google 还就此写了篇文章 《Machine Learning: The High interest Credit Card of Technical Debt》。总结起来有三种：一、边界模糊，数据之间彼此依赖关联。二、没有系统级别代码分离，胶水代码处理一切。三、机器学习系统随着外部世界的改变而彻底改变。
偿还债务 代码重构，就犹如对你的资产进行一次清点盘算：清除不良资产、偿还债务、进行资产上的重新配置。重构能够有效减缓技术债务带来的负面影响。
面向对象的 SOLID 原则 SOLID 原则由罗伯特·C·马丁提出，是五项原则&amp;ndash;单一职责、开闭原则、替换原则、接口隔离、依赖倒置的缩写，是面向对象设计与开发的五个基本原则。通过这五项原则，写出来的程序可读性、可扩展性都大大提高，软件维护和系统扩展变得更加容易。
 SRP 单一职责原则：一片代码只做一件事，及一块代码只实现某一特定功能，尽量减少逻辑的交叉堆叠。 OCP 开闭原则：对象对于扩展开放，对于修改关闭。即保持最小单元，写完后不去修改它，而是通过扩展或者配置的方式补充功能。 LSP 替换原则：任何的子类应该轻松由同一对象树的其它对象替代。 ISP 接口隔离原则：不同的接口做不同的事，软件开发没有银弹，接口也是。解耦能解决掉开发过程中“牵一发而动全身”的情况。 DIP 依赖倒置原则：抽象来自于细节、来自于底层，开发依赖抽象。  机器学习与 SOLID 原则 将 SOLID 原则应用于机器学习，会发现：机器学习与 SOLID 原则相互交织。诸如机器学习中的降维，是在减少耦合；胶水代码、数据依赖又与 SOLID 原则相抵触。</description>
    </item>
    
    <item>
      <title>凭什么打败竞争对手？基于数据、基于分析的商业竞争 Competing on Analytics </title>
      <link>https://kuhungio.me/2019/competing-on-analytics/</link>
      <pubDate>Tue, 12 Mar 2019 10:48:59 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/competing-on-analytics/</guid>
      <description>数据科学家这个职位，随着12年的哈佛商业评论的一篇文章，成为了21世纪“最性感的职业”。这年头，越来越多的年轻人开始往这个方向奔，市场几近饱和。但是，很少有听见企业家说：“是的，我们很需要数据工程师，因为以下原因&amp;hellip;“对于看此文的老板们，你们是否不止一次听到媒体鼓吹大数据、鼓吹机器学习、鼓吹人工智能，却很少有听到说这些东西，对于企业来说，实实在在带来了什么。如果你的答案是“Yes”，那么这篇文章将解答你的疑惑。
本文论点主要取自 Thomas H. Davenport 文章 《Competing on Analytics》，试图从企业管理的角度，阐述为什么我们需要数据科学家（或者说广义的数据相关人员）；他们能给企业带来哪些切实的好处；以及作为企业家，我们该如何转型，如何拥有更强的竞争力。
同质化的市场危机 在当下，想依靠某个新奇的点子或者是产品服务，已经不大可能再和其他竞争者区分开来。作为一个人类组织，底子里仍保留有人类的天性。人类天生就爱模仿，从一出生模仿吃东西，到后面通过模仿习得语言，再到后面的学习。人类的本质可能就是个复读机。模仿可以说保证了我们人类种族的存在与延续。对于企业来说，也大抵相同。
尽管我们知道，从道德原则上讲，大企业模仿别的东西是不对的。但是，从商业利益角度，无数的事实告诉我们，模仿，对于企业来说真的是一个大概率稳赚不亏的事情。把市面稳定的产品拿来微创新，再加持自己的人力或渠道优势，很快就能回本。保不齐也能把竞争对手耗死。现实即是如此。
比你更有利的竞争对手 越来越多的产品、服务开始同质化。无论互联网、游戏、手机或是制造业、服装业，越成熟的领域这个现象越明显。与此同时，我们的竞争对手可能在东南亚，拥有更低的人工成本；可能在不规矩的私营企业，拥有更多免费加班的程序员；也可能是腾讯头条这样的大厂，控制着大部分渠道。那么，你的产品服务，凭什么脱颖而出？
答案就是成为分析型竞争者
数据分析竞争者在干什么 数据分析型竞争者会做以下几个事情。
用户 通过分析，去洞察客户的需求，以及他们所愿支付的价格，找到他们保持忠诚度的原因。在商业模式中，客户是我们的直接服务对象，也是收入来源。那么，势必需要搞清楚客户的数据情况。
在当下，比较流行的技术是通过用户画像技术，去刻画我们的用户群体。用户的分布地域、用户的性别以及年龄，用户的偏好。只有这些东西都搞清楚，我们才能清楚的知道我们的客户是谁，为什么他们需要我们的服务或产品。
渠道 与此同时，也要分析我们触达用户的渠道。不得不说，发明电视黄金档广告的人，一定是个商业奇才。曾几何时，电视广告和路标广告曾是众多老板的竞相争夺的资源，屡屡出现标王，一次次刷新记录。在那个时代，只要你砸钱，拿到黄金时间的广告，就是稳赚不赔。但现在不一样了，各种互联网渠道，在抢占着人们的注意力。楼宇电梯广告、站台路牌广告各种花样层出不穷。
但是，你就真的清楚该投哪一个了吗？还是听信对方销售人员一阵天花乱坠的吹嘘，就乖乖交了钱，却得不到想要的转化效果？通过适当的分析，我们可以知道用户在哪些渠道对我们的响应度最高，知道哪些渠道可以带来更高的转化，从而优化我们的渠道成本投入。
举个我自己的例子：我的文章隔几天就会发一篇，分布在不同渠道：微信、知乎、头条、掘金、简书。那我是单单为了占坑防洗稿就完事了吗？不是的，作为一个数据挖掘工程师，我会分析各个渠道带来的阅读、关注和互动，从而调整渠道策略。
目前我就发现，知乎和头条的信息流产品在分发策略上做的很不错，能保证充分的曝光。微信适合做核心粉丝的沉淀，和粉丝去探讨交流一些问题。而掘金、简书的曝光有限，那我就会在更新是把他们往后放。
那是不是我就应该放弃简书掘金了呢？也不是的。通过分析我发现，掘金在谷歌搜索的排名占比靠前，简书在百度搜索的排名靠前，他们俩实际是很好的 SEO 流量优化渠道。这就是渠道分析的效果。
人力 通过分析，去计算员工对公司利润做出的具体贡献，而不仅仅是关注薪酬成本。以前的自己觉得，买东西或是做事情，先去看成本是多少。工作后发现，领导的视角不是这样的。成本对于老板们来说，只是个数字。他们更关心做事的投入产出比。对于员工问题也是这样。
但现实不是这样的。很少有公司会关注这名员工对利润的贡献，反而更多的去关注他的成本是多少。他今天996了没，没有996对不起我给他开的价钱，而丝毫不关心员工对公司利润所做的贡献。而另一个极端就是，有些老板觉得这类人便宜，从而养了很多闲人。这两种情形虽然短时不会给企业带来多大负面影响，但你的竞争性选手，已经在利用数据，去发现员工的价值贡献，并对人事招聘进行调整了。
库存 在实业中，我们还要追踪现有的库存，预测并分析需求量，减少库存的积压，提高现金流转效率。这里主要是对重资产的企业老板，如果你能在这其中发现机会，一个点的提升，都会带来巨大收益。
数据分析竞争者的特质 那么，集体来讲，分析型数据竞争者具有怎么样的特质呢？如同招聘时给出的工作描述，我们也可以给分析型竞争者做画像。
 数据竞争型选手应广泛应用模型和算法以及对应的最优化技术。例如作者之前实习的某普惠金融银行，通过最广泛的数据建模，给中小微个人提供贷款，赚大型银行看不上的钱，同时自己也很滋润。
 组织内部全面应用数据分析等相关技术。对各个流程进行数据分析、对各个环节进行建模以优化体验，减少流失。
 同时，也应该有自上而下的支持。如果一个企业的领军人物都不相信，那一线员工又何来的信任和执行力呢。企业老板应具备一些基础知识，同时有能够值得信任、不编造数据的专家。
  为什么它有效 说了现状说了要求，那为什么套措施有效呢？如果大家都有，那不就是没有差异化了吗？难道我们要搞军备竞赛吗？这不就和贩卖焦虑的自媒体一样的了吗？
其实不是这样的。一个身材羸弱的人和一个经常分析自己身体状态并针对性强化的人，他们外在的表现就会不一样。大部分企业在竞争中，使用的技术很相近，产品差别也不大；唯一能有差异化的，可能就是商业流程了。数据的挖掘分析，帮助企业家从流程中挤出每一滴价值。
尽管很多公司都有数据分析团队，但只有娴熟运用的公司，才能在各行各业取得霸主地位。甚至，对于如头条、亚马逊这样的公司，数据挖掘、算法已经成为了企业的名片和核心竞争力。
核心4条解决方案  合适的焦点、分析不可过于分散，免得失去焦点。
 合适的文化、小范围检验，最小可行产品验证。
 合适的人才、有分析能力且能深入浅出说明问题；有商业才能能够在商业角度阐述价值；以及沟通的技巧。
 合适的技术、数据储备、硬件支持，最终才会立于不败之地。
  最后，数据竞争型选手，如何说明他确实有效。很简单，以始为终点，检视最初的目标。</description>
    </item>
    
    <item>
      <title>机器学习落地需攻破的9个难题 The Next Step for Machine Learning</title>
      <link>https://kuhungio.me/2019/the-next-step-for-machine-learning/</link>
      <pubDate>Sun, 24 Feb 2019 23:31:58 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the-next-step-for-machine-learning/</guid>
      <description>机器学习在前两年的时间里，一下子就爆火了起来。很多公司也跟着这个趋势，招募了很多算法工程师、数据挖掘工程师。但是，在实践中，企业发现要落地，实际上还有很多问题需解决。以至于在大部分项目，还是规则主导。算法工程师的日常，也不过是清洗数据，调整规则。所以，机器学习技术，在真实的应用中到底缺少些什么呢？
在国立台湾大学《机器学习》2019春季班，李宏毅老师给出了他的观察。以下的内容，结合李老师的最新讲义、加上我本身工作的理解，给大家梳理机器学习落地急需解决的9个难题。
拒绝回答与可解释性（哲学层面） 1. Anomaly Detection 机器能不能知道“我不知道” 机器能不能知道自己的识别范围，还是说生硬地给出模型内的东西，或者说抛出无法识别。在猫狗分类里，现有的模型已经到达很高的精度，甚至能给出猫狗的品种。
但是正式上线后，用户真的会乖乖给到猫狗的图片吗？如果用户丢一张妹子图，机器能够知道自己不知道吗？目前这个领域的研究叫做 Anomaly Detection。知道自己不知道，对于一些异常的情况，十分重要。
2. Explainable AI 说出为什么“我知道” 神马汉斯的故事：
18世纪德国，一匹名叫汉斯的马成为当地网红。他能够计算简单的算术题，并用蹄子敲出正确回答。这在当时一度引起轰动。后来，有人做了个实验，把汉斯和周围的人完全隔绝，这匹马就完全蒙圈了。时事证明，这匹马的神奇能力不在于他的算数能力，而在于他的观察能力。当给到正确答案时，周围的人会有不一样的反应，汉斯也就随即停止敲马蹄。
机器学习的成果，是否同汉斯一样，通过一些意想不到的渠道，获得的答案。在 GCPR 2017 Tutorial 的研究中，研究者通过注意力机制，研究机器判断的依据。
实验者测试了两个模型，两个模型均为马匹识别。DNN 模型的焦点集中在马匹身上，是一个正常的模型。但 FV 的交点却集中在图片左下角。原来，图片的左下角有图片的出处，所有的包含马匹的图都有这个标记。所以，FV 模型学到的重点在于这些标记。同样的表现，却是不一样的判断依据。显然，FV 模型的判断依据是滑稽和不可靠的。
我们需要一些技术，让 AI 不仅给出结果，同时要给出判断的依据。即：模型的可解释性。
抵御恶意攻击 3. 防止 Adversarial Attack 人有错觉，机器是否也会有错觉。我们来做一个认知实验。以下两个圈圈，哪个的颜色更深？好，记住你的答案。结果将在稍后揭晓。
对于机器，有研究表明，通过改变图像中的个别像素，可以起到迷惑机器的作用。改变一个像素，就可以让模型的判断结果从熊猫到长臂猿。该技术名叫 Adversarial Attack。
这样的技术相当危险。举个例子，当自动驾驶的车辆行驶在路上时，可能路边的人挥舞下旗子，机器的判断就会被干扰，做出不当的举动。
回到开头的例子，正确答案是左边。这其实是一个计中计。你以为这是视觉认知实验，其实这也是某种形式的“心理攻击”。 学习模式 4. Life-long learning 终身学习 终身学习是一个人类行为的概念。活到老学到老，大家都知道只有不断更新自己的知识，才能跟上社会发展的步伐。同时呢，先前学到的东西，对后面的学习仍有帮助。举个例子：学完线性代数之后，对学习和理解机器学习就大有帮助。
但是，机器不一样。今天的我们，一般只让一个模型学习一个任务。但这样会存在一些问题。首先是随着建模的增多，模型数量将无限增长。其次，模型之前学到的技能，对之后的学习没有帮助。就像 Alphastar 它玩星际争霸很棒，但让他同时学下围棋，目前来说是不行的。它和 Alphazero 是两个不同的模型 。
那么，自然而然的，我们就会抛出这样一个疑问，机器能否终身学习呢？这里的相关研究，提个关键词 Catastrophic Forgetting 。
5. Meta-learning / Learn to learn 学习如何学习 现有的机器学习模型设计，都遵循着这样一个范式——在特定领域人工设计一套算法，让机器去学习。我们就想，能不能设计一套算法，让机器自己去设计自己的学习算法呢？
这样的范式，我们称之为 meta-learning 元学习，或者叫 learn to learn，学习如何学习。</description>
    </item>
    
    <item>
      <title>为啥说数据这行不容易 Why is Data Hard </title>
      <link>https://kuhungio.me/2018/why-is-data-hard/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/why-is-data-hard/</guid>
      <description>原文链接 Slack 工程师 : why-is-data-hard?
做数据挖掘时，常常需要考虑很多方面。其中一个方面，常常会涉及到跨功能，复杂且琐碎的一些事项。数据准备以及评价指标的制定，就是这些事项之一。
等等，似乎干数据这一行，并不容易？
当大多数的组织谈到数据时，他们想的其实是指标——能反应近期业务、或是能够提供数据驱动的决策、抑或是能够监测企业经营状况的指标。
按上面的说法，我们应该能够招聘到聪明且能干的分析师，做出酷炫的可视化仪表盘，并马上投入使用。
 “Every second of every day, our senses bring in way [more] data than we can possibly process in our brains.”&amp;ndash; Peter Diamandis, Founder of the X-Prize
 拥有大量的数据并不会立马产生价值。当你是在数据增长快如 Slack 这样的公司处理数据时，不仅怎样驾驭数据和指标极其重要且困难的，更困难的是你像是在 “building the plane as it is flying”。
数据金字塔：评价指标（metrics）最为重要 数据金子塔大致可以分为4个级别。每一个级别都高度依赖下一级。
见解/洞察（Insights） 大部分的老板和公司董事关心的是这一层。见解（Insights）是我们所讲的关于数据的故事，即什么驱动了商业，或者是有什么新的机会能够推动大量的增长。
在理想的世界中，有一个共享的、不断演进的关于业务性能的数据叙述。这种数据叙述在整个组织中传播，以建立对业务的共同理解。
探索以及工具 为了获得见解，我们需要雇佣很多人定期去探索数据。只有当有人在盯着数据的时候，才能有策划和故事!
在快速增长的业务中，最优的数据探索涉及到一些关键事物：
 数据探查的多样性。要真正建立起，对正在发生的事情和重要的事情的理解和见解，我们需要每个人都拥有，对数据的关注和探索的主人翁意识。现实情况是，如果探索困难，只有管理员(分析师)能够完成这项工作。你要么雇佣更多的分析师来深入挖掘你的见解，或者，你可以找到简化数据访问的方法，让团队能够自行解决问题。Slack 的做法介于两者之间——我们不断寻找，在整个组织中增加自助数据服务的方法；同时也确保，我们有优秀的分析师参与到每一个核心功能来。
 频繁使用。像所有良好习惯的养成一样，查看数据和指标的一致性，是建立对所期望东西见解的唯一方法，什么样的结果是出乎意料的，什么样的问题是需要分析数据的。分析师可以帮助挖掘趋势，有些趋势值得挖掘，而许多趋势则不然。如果老板经常查看数据，那么你的分析师就更有可能对他们的精力，进行最优配置。
   例子：本周活跃用户增加了4%。这是好是坏？是预期的增长放缓?还是因为这周，我们推出了新产品，所以实际上我们希望的是，高于平时一周的增长?
分析师能够挖掘并做出各种比较，以帮助老板对数字进行说明。分析人士可以将该数字与往年做比较，深入了解这些新要素的组成，以及他们来自哪里。也许4%符合你的期望。但事实上，它比平时要低，我们没有推出任何新产品，且处于一个缓增长放缓期。这就是您希望董事会和分析人员构建的见解。你不会希望在某些事情上耗费精力，这些事情并不会带来业务的增长，或者改变我们的决策。
  发现能力与数据探索。数据探索不同于在仪表盘上点来点去，这是我想在这里指出的。仪表盘是用一组具体的需求创建的，通常在特定的粒度级别上报告指标或世界的某些视图。数据探索是一种能力，即通过各种不同的特征结合来调查指标，以确定在固定的仪表盘中不会立即出现的趋势或机会。可以将其考虑为，能够对数据进行转换和筛选，从而向监控之外的数据提出问题的能力。看到活跃用户的激增吗？太棒了！也许我们需要探究这在所有国家都这样，还是仅仅出现在英国。那周我们是否发起了一项针对英国的营销行动？销售团队是不是在那周完成了一个大单子?  企业主离数据越近，他们就越有能力着手进行自助服务的探索，就能发现更快捷、更有效的关键见解。这是因为，他们更有能力将我们在业务中所做的事情，与我们在数据中可能表现的特点结合起来。反之亦然！那些从商业伙伴那里拥有大量业务背景的分析人士，可以更快地找到正确的见解，而不是身陷各种假设之中。对于一个快速成长的组织来说，你可能希望两者都存在于你的组织中，这样每个人都能带着主人翁意识，理解我们最大的机遇和存在的差距。</description>
    </item>
    
  </channel>
</rss>