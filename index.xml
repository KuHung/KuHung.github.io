<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kuhung&#39;s Blog on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/</link>
    <description>Recent content in Kuhung&#39;s Blog on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 07 Mar 2020 17:43:44 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>更高效的远程工作之道--给老板看的 REMOTE 手册</title>
      <link>https://kuhungio.me/2020/remote/</link>
      <pubDate>Sat, 07 Mar 2020 17:43:44 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/remote/</guid>
      <description>

&lt;h1 id=&#34;大规模远程工作实践&#34;&gt;大规模远程工作实践&lt;/h1&gt;

&lt;p&gt;远程工作，一个之前都没怎么考虑的事情，在2020年的春节过后，中国大陆进行了一次大规模实验。WFH（work from home），一个在外企很常见的操作，在国内却鲜有生存环境。&lt;/p&gt;

&lt;p&gt;虽然朋友圈已经有人发帖，渴望在办公室中办公，但是，也不能因此，就放弃思考远程工作的这么个事物。一成不变往往很简单，但变化之中，才有契机。&lt;/p&gt;

&lt;h1 id=&#34;远程工作契机&#34;&gt;远程工作契机&lt;/h1&gt;

&lt;p&gt;什么阻挡了远程工作的推行，我们无从说起。但何不把这次当作一种契机，去学习其中的脉络。&lt;/p&gt;

&lt;p&gt;关于远程工作，找到了一本小册子《Remote》，专门介绍远程工作的。作者也写过另一本书《Rework》，中文名重来 。写书虽说门槛不高，但是写出有说服力的书，具备条件的人往往很少。作者以其自己的公司 Basecamp 为例，说明了远程工作的优点，也向我们介绍了远程工作的注意事项。读懂它，你的远程工作事半功倍。&lt;/p&gt;

&lt;h1 id=&#34;远程工作迷思&#34;&gt;远程工作迷思&lt;/h1&gt;

&lt;p&gt;在书中，你可能看到自己的影子，也可以看到老板的影子。无论你是老板，还是打工者，其中的内容都值得细细理解。&lt;/p&gt;

&lt;h2 id=&#34;我拒绝远程工作&#34;&gt;我拒绝远程工作&lt;/h2&gt;

&lt;h3 id=&#34;做好工作-而不是死守工作时间&#34;&gt;做好工作，而不是死守工作时间。&lt;/h3&gt;

&lt;p&gt;远程工作，不是一个新鲜事物。至少在作者这个书出版之时，到2020年，已经过去了7年。远程工作改变了集中式办公的缺点，时间被切割，无穷无尽的会议。但其自身也有适用范围，比如写作、编程、设计和客户支持等工作。像制造业，可能就不太现实。很多人对远程工作嗤之以鼻，常抱着努力干活，等我退休了，再来享受生活的态度。老板们顾及远程工作，很可能是担心没了约束，员工的拖延症很可能无限放大，毕竟谁都有拖延的时候。做好工作，而不是死守工作时间。&lt;/p&gt;

&lt;h3 id=&#34;如果我能看见他-我就能控制他&#34;&gt;如果我能看见他，我就能控制他。&lt;/h3&gt;

&lt;p&gt;远程工作，在2020春节之前，一定是有很多反对声音的。比如，缺乏讨论的氛围，公司没有源源不断的点子，这怎么行。没准下一个点子就能颠覆乔布斯。但实际上，我们知道，很多人还在执行几个月甚至几年前的一个点子。有员工认为，家里的干扰太多，琐事不断打扰。但实际上一份有成就感的工作，不会让你轻易被打断。而管理者，会觉得，没有盯着他们，怎么知道他们是在干活，还是躺在床上玩手机。但实际上，就在眼皮子底下，员工也有无数种方法摸鱼。如果不信任他，一开始就不该雇佣他。&lt;/p&gt;

&lt;h3 id=&#34;不这样做-就没有机会&#34;&gt;不这样做，就没有机会。&lt;/h3&gt;

&lt;p&gt;在团队内部，一个组这样做了，另一个组会嫉妒。但跳出这个逻辑，整个组织目标一致，效率最高才是最终的赢家。再一个，业务部门或者上级会觉得，我现在就要答案，现场能有更高的压迫感。但实际上，并不是所有事情同等重要。再一个，中小型企业会认为，BAT 大公司都没远程工作，肯定有他的不好，马某人都是聪明人，不可能没调研过。但实际上，你跟着大公司的脚步，永远成不了第二个马某人。远程工作能不受地域限制，网罗到世界各地的人才；有些时候，性价比更高。&lt;/p&gt;

&lt;h2 id=&#34;远程工作精要&#34;&gt;远程工作精要&lt;/h2&gt;

&lt;p&gt;远程工作，在2020春节之后，大伙儿已经有了足够多体会。作者的公司长期远程且稳定盈利，他总结了以下内容。&lt;/p&gt;

&lt;h3 id=&#34;及时同步进度&#34;&gt;及时同步进度&lt;/h3&gt;

&lt;p&gt;重要资料公开，而不是让人到处询问，让被询问人工作量加倍。展现工作进度，以成果导向。及时向团队内部公开。承诺往往有更高的约束力，而且，同行肯定比非技术领导更懂所需的工作时长。于此同时，做防灾的准备，诸如数据备份等工作。如果工作需要同客户合作，还需注意，及时将进度同步给客户。&lt;/p&gt;

&lt;h3 id=&#34;打造良好团队氛围&#34;&gt;打造良好团队氛围&lt;/h3&gt;

&lt;p&gt;对于团队内部，保持正向的氛围，阻止消极负面的情绪在团队内部蔓延。聪明且及完成任务，才是合适的好员工。用当地最好的薪水留住他们，而不是因地施策。关心员工的身心健康，担心过度劳累，而不是懒惰，因为可持续才能走更远。最后，保持一个强劲的动力，鼓励员工从事自己喜欢的事物。&lt;/p&gt;

&lt;h3 id=&#34;员工同样可以出众&#34;&gt;员工同样可以出众&lt;/h3&gt;

&lt;p&gt;而对于员工，如果你想在团队内出众，往往有两种方法。一个是在保持活跃，另一个就是高质量的交付任务。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>音频处理之人声提取：分离音频背景声，过滤空白</title>
      <link>https://kuhungio.me/2020/audio_progress/</link>
      <pubDate>Sun, 12 Jan 2020 23:52:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/audio_progress/</guid>
      <description>

&lt;h1 id=&#34;背景需求&#34;&gt;背景需求&lt;/h1&gt;

&lt;p&gt;在处理音频中，我们可能会有这样的场景：随着语音设备的能力越来越强，音频数据越来越大。但实际上，音频中的有效部分却很少，抑或是音频的背景声过大，非目标声音。在这样的场景下，我们希望得到人声，去掉噪声，提高信噪比。&lt;/p&gt;

&lt;h1 id=&#34;问题界定&#34;&gt;问题界定&lt;/h1&gt;

&lt;p&gt;这里将问题进行界定，进行子任务拆分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将音频的背景声音去除，&lt;/li&gt;
&lt;li&gt;去除“无声”阶段。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;解决方案&#34;&gt;解决方案&lt;/h1&gt;

&lt;p&gt;要提高信噪比，这需求在很多场景中有见：比如课堂录音的提取，或者是录音笔的数据存储。&lt;/p&gt;

&lt;p&gt;在使用本领域“高深”的技术前，一定要思考，&lt;strong&gt;切莫手上有锤子，就看啥都像钉子&lt;/strong&gt;。想想该领域的专家会怎么做，如何从专业角度看待该问题；其次想想普通人会怎么做，防止落入经验主义陷阱。&lt;/p&gt;

&lt;p&gt;背景声音的剥离，最简单的其实是音轨分离。其前提是两种声音存为了不同的音轨，在一些场景很合适。比如电话录音。&lt;/p&gt;

&lt;h2 id=&#34;背景声分离&#34;&gt;背景声分离&lt;/h2&gt;

&lt;p&gt;但是若只有一个音轨呢？别担心，机器学习来帮助你。&lt;a href=&#34;https://github.com/deezer/spleeter&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;spleeter&lt;/a&gt; 基于 tensorflow，训练了一套音乐检索系统，能够有效的分离人声和背景音乐声。&lt;/p&gt;

&lt;p&gt;该工具已经进行封装，对于简单的人声分离，采用直接调取的方式即可。代码如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Use audio loader explicitly for loading audio waveform :
from spleeter.audio.adapter import get_default_audio_adapter

audio_loader = get_default_audio_adapter()
sample_rate = 44100
waveform, _ = audio_loader.load(&#39;/path/to/audio/file&#39;, sample_rate=sample_rate)

# Perform the separation :
prediction = separator.separate(waveform)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;空白切割&#34;&gt;空白切割&lt;/h2&gt;

&lt;p&gt;在分离之后，得到人声和背景声。人声分离后，仔细听，就会发现里面有很多空白。对于空白部分，进行切割分离。&lt;/p&gt;

&lt;p&gt;这里参考 &lt;a href=&#34;https://stackoverflow.com/questions/23730796/using-pydub-to-chop-up-a-long-audio-file&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;stackoverflow&lt;/a&gt; 的代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydub import AudioSegment
from pydub.utils import db_to_float

# Let&#39;s load up the audio we need...
podcast = AudioSegment.from_mp3(&amp;quot;podcast.mp3&amp;quot;)
intro = AudioSegment.from_wav(&amp;quot;intro.wav&amp;quot;)
outro = AudioSegment.from_wav(&amp;quot;outro.wav&amp;quot;)

# Let&#39;s consider anything that is 30 decibels quieter than
# the average volume of the podcast to be silence
average_loudness = podcast.rms
silence_threshold = average_loudness * db_to_float(-30)

# filter out the silence
podcast_parts = (ms for ms in podcast if ms.rms &amp;gt; silence_threshold)

# combine all the chunks back together
podcast = reduce(lambda a, b: a + b, podcast_parts)

# add on the bumpers
podcast = intro + podcast + outro

# save the result
podcast.export(&amp;quot;podcast_processed.mp3&amp;quot;, format=&amp;quot;mp3&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后，得到完整的人声部分。&lt;/p&gt;

&lt;h1 id=&#34;其它参考&#34;&gt;其它参考&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://timsainburg.com/noise-reduction-python.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Noise reduction using spectral gating in python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mikesmales/Udacity-ML-Capstone&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Udacity 2018 Machine Learning Nanodegree Capstone project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>如何计算用户生命周期价值（CLV）</title>
      <link>https://kuhungio.me/2019/lifetimes/</link>
      <pubDate>Wed, 25 Dec 2019 23:28:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/lifetimes/</guid>
      <description>

&lt;p&gt;在用户关系管理中，常会遇到些直击灵魂的问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;这批用户到底价值几何？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为什么要用这种措施去干预用户，而不是另一种方式。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为什么干预这类用户，而不去干预另一类，他们的划分标准是什么。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有这些问题，实质是因为对客户价值不够了解，缺乏行之有效的划分方式。&lt;/p&gt;

&lt;h2 id=&#34;用户精细化运营价值巨大&#34;&gt;用户精细化运营价值巨大&lt;/h2&gt;

&lt;p&gt;随着人口红利的消失，增长逐渐见顶，急需在现有用户池做学问。过去粗放式的买量策略已经不再生效，一是买量成本逐渐高企，二是买量带来的用户忠诚度极低。对现有客户群体的划分和互相倒流，成为重中之重。行业中的黑话“洗用户”，即是讲的这一策略。&lt;/p&gt;

&lt;p&gt;对于如何划分用户，不用的职能会有不同的看法。产品有产品的看法，可能基于某项功能偏好；运营有运营的看法，是各种活动玩法的定义；甚至领导还有他的一套看法。但是，无论怎么切入，商业的核心拿捏住，才会八九不离十。&lt;/p&gt;

&lt;p&gt;什么是商业的本质：商业的本质是获利。因此，我们从用户的货币价值切入，评估和划分用户的生命周期。&lt;/p&gt;

&lt;p&gt;用户生命周期价值，这并不是学界的新鲜产物，该理论在上世纪80年代就已经提出。但对于互联网，网上可搜寻到的资料少之又少。可能的原因有两个：一是互联网在过去20年快速爆发，风口上躺着也能赚钱；二是各家的策略内部不统一，无法形成统一的口径。&lt;/p&gt;

&lt;p&gt;但这些都不是不去应用他的理由，反而说明其中价值巨大。这里，我们剥离开复杂的商业逻辑，仅从交易入手，分析用户的生命周期价值，以及用户所处的状态。&lt;/p&gt;

&lt;h2 id=&#34;用户生命周期价值-clv&#34;&gt;用户生命周期价值（CLV）&lt;/h2&gt;

&lt;p&gt;随着精细化运营的铺开，过去粗放式的、买量用户已经不再买账。每个用户所能接受的最低服务各不相同。如何根据用户价值，进行资源的有效利用。最大化杠杆的使用，成为企业生死的关键。&lt;/p&gt;

&lt;p&gt;过去，没有统一的理论出现在互联网应用或是游戏中。但是，运用跨学科的思维，就可以发现：市场营销领域已进行过研究，并给出了精度极高、可解释性强的模型方法。&lt;/p&gt;

&lt;p&gt;这种方法，就叫做用户生命周期价值，英文名称 Customer Life Time Value，简称 CLV 或者 LTV。&lt;/p&gt;

&lt;h2 id=&#34;clv-是什么&#34;&gt;CLV 是什么&lt;/h2&gt;

&lt;p&gt;用户生命周期，是一种刻画用户的方法。一般用来解决两类问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;用户还有多少价值、用以衡量投入产出比&lt;/li&gt;
&lt;li&gt;在干预用户后，根据用户生命周期价值的变化，优化资源的投放。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;即用户管理的两个核心问题：用户所具备的价值以及策略的有效性。&lt;/p&gt;

&lt;p&gt;需要注意的是，CLV 的产品形态要求非合约。合约在国内最有代表的是合约手机。一般互联网产品，合约形态较为少见。&lt;/p&gt;

&lt;p&gt;CLV 的用户群体需已经产生交易，未付费用户不纳入考量。当然，概念迁移，将付费换成活跃或内容消费，该模型也能处理。&lt;/p&gt;

&lt;h2 id=&#34;clv-回答哪些问题&#34;&gt;CLV 回答哪些问题&lt;/h2&gt;

&lt;p&gt;用户活跃还是流失，用户还有多少付费潜力，用户在未来某段时间会否再次购买。这三个问题，是用户生命周期价值能够回答的。&lt;/p&gt;

&lt;h2 id=&#34;如何在自家产品中引入-clv&#34;&gt;如何在自家产品中引入 CLV&lt;/h2&gt;

&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;判断用户所处生命周期阶段&lt;/li&gt;
&lt;li&gt;预测用户指定周期内购买概率&lt;/li&gt;
&lt;li&gt;预测用户的生命周期价值&lt;/li&gt;
&lt;li&gt;通过历史付费数据，预测未来付费&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;活跃与流失的定义&#34;&gt;活跃与流失的定义&lt;/h3&gt;

&lt;p&gt;定义：&lt;/p&gt;

&lt;p&gt;用户有交互为活跃&lt;/p&gt;

&lt;p&gt;用户一段时间不交互，即为流失&lt;/p&gt;

&lt;h3 id=&#34;lifetims-工具包引入&#34;&gt;lifetims 工具包引入&lt;/h3&gt;

&lt;p&gt;安装 python 的工具包：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install lifetimes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;clv-数据挖掘&#34;&gt;CLV 数据挖掘&lt;/h2&gt;

&lt;p&gt;用户生命周期判定，需要三个指标&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;frequency 用户登录的频率，这里为周期内的天数&lt;/li&gt;
&lt;li&gt;recency 用户的最大周期，即第一次活跃到最后一次活跃&lt;/li&gt;
&lt;li&gt;T 用户所处阶段，第一次活跃到观察周期结束&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于付费预测，还需要用户的平均付费金额。&lt;/p&gt;

&lt;h3 id=&#34;数据获取&#34;&gt;数据获取&lt;/h3&gt;

&lt;h4 id=&#34;从数据库获取&#34;&gt;从数据库获取&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;    SELECT
      customer_id,
      COUNT(distinct date(transaction_at)) - 1 as frequency,
      datediff(&#39;day&#39;, MIN(transaction_at), MAX(transaction_at)) as recency,
      AVG(total_price) as monetary_value,
      datediff(&#39;day&#39;, CURRENT_DATE, MIN(transaction_at)) as T
    FROM orders
    GROUP BY customer_id
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;python-处理&#34;&gt;python 处理&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    from lifetimes.datasets import load_transaction_data
    from lifetimes.utils import summary_data_from_transaction_data
    
    transaction_data = load_transaction_data()
    print(transaction_data.head())
    &amp;quot;&amp;quot;&amp;quot;
                      date  id
    0  2014-03-08 00:00:00   0
    1  2014-05-21 00:00:00   1
    2  2014-03-14 00:00:00   2
    3  2014-04-09 00:00:00   2
    4  2014-05-21 00:00:00   2
    &amp;quot;&amp;quot;&amp;quot;
    
    summary = summary_data_from_transaction_data(transaction_data, &#39;id&#39;, &#39;date&#39;, observation_period_end=&#39;2014-12-31&#39;)
    
    print(summary.head())
    &amp;quot;&amp;quot;&amp;quot;
    frequency  recency      T
    id
    0         0.0      0.0  298.0
    1         0.0      0.0  224.0
    2         6.0    142.0  292.0
    3         0.0      0.0  147.0
    4         2.0      9.0  183.0
    &amp;quot;&amp;quot;&amp;quot;
    
    bgf.fit(summary[&#39;frequency&#39;], summary[&#39;recency&#39;], summary[&#39;T&#39;])
    # &amp;lt;lifetimes.BetaGeoFitter: fitted with 5000 subjects, a: 1.85, alpha: 1.86, b: 3.18, r: 0.16&amp;gt;


from lifetimes.datasets import load_cdnow_summary
data = load_cdnow_summary(index_col=[0])

print(data.head())
&amp;quot;&amp;quot;&amp;quot;
     frequency   recency      T
ID
1    2           30.43       38.86
2    1            1.71       38.86
3    0            0.00       38.86
4    0            0.00       38.86
5    0            0.00       38.86
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;bg-nbd-模型&#34;&gt;BG/NBD 模型&lt;/h3&gt;

&lt;p&gt;BG/NBD 是一个经典模型改进型，详细的数学论证参见：&lt;a href=&#34;http://brucehardie.com/notes/009/pareto_nbd_derivations_2005-11-05.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;A Note on Deriving the Pareto/NBD Model
and Related Expressions&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;该模型有如下假设：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/lifetimes/assumptions.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过模型拟合，得到4个参数。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lifetimes import BetaGeoFitter

# similar API to scikit-learn and lifelines.
bgf = BetaGeoFitter(penalizer_coef=0.0)
bgf.fit(data[&#39;frequency&#39;], data[&#39;recency&#39;], data[&#39;T&#39;])
print(bgf)
&amp;quot;&amp;quot;&amp;quot;
&amp;lt;lifetimes.BetaGeoFitter: fitted with 2357 subjects, a: 0.79, alpha: 4.41, b: 2.43, r: 0.24&amp;gt;
&amp;quot;&amp;quot;&amp;quot;
bgf.summary
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/lifetimes/bgm.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;效果可视化&#34;&gt;效果可视化&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lifetimes.plotting import plot_probability_alive_matrix

plot_probability_alive_matrix(bgf)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/lifetimes/frequency_recency.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;右下角为最佳客户，交易频率高。交易跨度大；右上的客户短时多次交易，极可能已流失。&lt;/p&gt;

&lt;h3 id=&#34;预测单个用户的购买行为&#34;&gt;预测单个用户的购买行为&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;t = 10 #predict purchases in 10 periods
individual = summary.iloc[20]
# The below function is an alias to `bfg.conditional_expected_number_of_purchases_up_to_time`
bgf.predict(t, individual[&#39;frequency&#39;], individual[&#39;recency&#39;], individual[&#39;T&#39;])
# 0.0576511
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;生命周期价值预测&#34;&gt;生命周期价值预测&lt;/h3&gt;

&lt;p&gt;在预测价值时，需要第四个参数：用户交易的次均金额。&lt;/p&gt;

&lt;p&gt;该模型有个重要前提：购买频次和购买金额无相关性。具体可参考 &lt;a href=&#34;http://www.brucehardie.com/notes/025/gamma_gamma.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;The Gamma-Gamma Model of Monetary
Value&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lifetimes.datasets import load_cdnow_summary_data_with_monetary_value

summary_with_money_value = load_cdnow_summary_data_with_monetary_value()
summary_with_money_value.head()
returning_customers_summary = summary_with_money_value[summary_with_money_value[&#39;frequency&#39;]&amp;gt;0]

print(returning_customers_summary.head())
&amp;quot;&amp;quot;&amp;quot;
             frequency  recency      T  monetary_value
customer_id
1                    2    30.43  38.86           22.35
2                    1     1.71  38.86           11.77
6                    7    29.43  38.86           73.74
7                    1     5.00  38.86           11.77
9                    2    35.71  38.86           25.55
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;相关性检验&#34;&gt;&lt;strong&gt;相关性检验&lt;/strong&gt;&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;returning_customers_summary[[&#39;monetary_value&#39;, &#39;frequency&#39;]].corr()
&amp;quot;&amp;quot;&amp;quot;
                monetary_value  frequency
monetary_value        1.000000   0.113884
frequency             0.113884   1.000000
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lifetimes import GammaGammaFitter

ggf = GammaGammaFitter(penalizer_coef = 0)
ggf.fit(returning_customers_summary[&#39;frequency&#39;],
        returning_customers_summary[&#39;monetary_value&#39;])
print(ggf)
&amp;quot;&amp;quot;&amp;quot;
&amp;lt;lifetimes.GammaGammaFitter: fitted with 946 subjects, p: 6.25, q: 3.74, v: 15.45&amp;gt;
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;次均估计&#34;&gt;次均估计&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(ggf.conditional_expected_average_profit(
        summary_with_money_value[&#39;frequency&#39;],
        summary_with_money_value[&#39;monetary_value&#39;]
    ).head(3))
&amp;quot;&amp;quot;&amp;quot;
customer_id
1     24.658619
2     18.911489
3     35.170981
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;总价值估计&#34;&gt;总价值估计&lt;/h4&gt;

&lt;p&gt;最后，使用 DCF 现金流折现，得到用户总体价值的当下估值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# refit the BG model to the summary_with_money_value dataset
bgf.fit(summary_with_money_value[&#39;frequency&#39;], summary_with_money_value[&#39;recency&#39;], summary_with_money_value[&#39;T&#39;])

print(ggf.customer_lifetime_value(
    bgf, #the model to use to predict the number of future transactions
    summary_with_money_value[&#39;frequency&#39;],
    summary_with_money_value[&#39;recency&#39;],
    summary_with_money_value[&#39;T&#39;],
    summary_with_money_value[&#39;monetary_value&#39;],
    time=12, # months
    discount_rate=0.01 # monthly discount rate ~ 12.7% annually
).head(3))
&amp;quot;&amp;quot;&amp;quot;
customer_id
1      140.096211
2       18.943467
3       38.180574
Name: clv, dtype: float64
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;用户生命周期价值模型，不同于其它模型。该模型对每个用户单独建模，而不是硬性的按流失天数划分，有极强的灵活性。在得到用户生命周期阶段、以及用户的生命周期价值，下一步就是具体应用了。&lt;/p&gt;

&lt;p&gt;落地场景多种多样，但要推动上下游，仍需要足够信服的理由。这里给到的建议是，去模拟历史的数据表现，用数据说明效果。&lt;/p&gt;

&lt;p&gt;喜欢本文的朋友，别忘了点赞 👍、喜欢 ❤ +关注 🔔哦，您的小小举动，是对作者最大的支持~💪&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习系统设计 Machine learning system design</title>
      <link>https://kuhungio.me/2019/machine_learning_system_design/</link>
      <pubDate>Sun, 01 Dec 2019 18:26:43 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/machine_learning_system_design/</guid>
      <description>

&lt;h1 id=&#34;导读&#34;&gt;导读&lt;/h1&gt;

&lt;h2 id=&#34;机器学习系统设计&#34;&gt;机器学习系统设计&lt;/h2&gt;

&lt;p&gt;系统设计题，顾名思义，就是考察一个人设计系统的能力。它是一种国外很喜欢的题型，特别是中高级职位，在算法手撕结束后，一般就是系统设计题。&lt;/p&gt;

&lt;p&gt;国外的算法工程师，被称之为 Machine Learning Engineer。国内的名头比较多，算法工程师、数据挖掘工程师、机器学习工程师、深度学习工程师都指的这个。&lt;/p&gt;

&lt;p&gt;这一岗位同开发岗位，SDE 一样，也需要足够的系统设计经验。&lt;/p&gt;

&lt;p&gt;国外的大佬 github.com/chiphuyen 总结了一份机器学习设计的资料，我在这里做本地化整理，同时增加一些自己的从业体会。&lt;/p&gt;

&lt;p&gt;内容分为3个部分，分别是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;机器学习的系统设计部分，这里做了核心概念的摘录；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;系统设计的案例，由于众所周知的原因，很多文章看不了，我这里将其整理放入了 github，同时笔记标注版的放在了公众号：谷粒说数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;练习部分，作者列了27道系统设计题。我这里将其布置在了网页上，方便自查，后续会上评论进行答案收集。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;系统设计应关注的点&#34;&gt;系统设计应关注的点&lt;/h3&gt;

&lt;p&gt;系统设计题，如果没有完整的方案也没关系，主要看表现的思想，着重从以下三个方面考察：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;项目有哪些约束条件，哪些能做，哪些不能做。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;方案的利弊，选择方案时，思考方案利弊的过程。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主要的功能，最后达成什么样的效果。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;系统设计往往很难，这是因为两方面的原因。1. 缺乏有效的评估手段。2. 问题往往模棱两可。面试中的理想候选人应该是这样子的：1. 能够有效的拆解问题，将复杂问题简单化。2. 能够区分该场景是否需要机器学习方案。第二点很重要，因为在当下，受媒体大环境影响，很多人会选择无脑上机器学习，殊不知某些场景简单的方法更有效。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Machine learning methods change every year, solving problems stays the same.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;生产环境不同于学术环境&#34;&gt;生产环境不同于学术环境&lt;/h2&gt;

&lt;p&gt;学术研究的一般有以下两个特点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;想法设法比上一代模型效果更好，而不用思考怎么落地使用它。&lt;/li&gt;
&lt;li&gt;由于效果是第一要务，所以算力没有限制，加钱堆机器即可。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而生产环境不同，它的特点如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;效果并非越好才好&lt;/li&gt;
&lt;li&gt;算力资源常常有限&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作为开发者，要始终牢记生产环境是我们的目标。&lt;/p&gt;

&lt;h2 id=&#34;需着重关注的4类问题&#34;&gt;需着重关注的4类问题&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;如何采集数据、如何处理数据。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;怎么选择的模型、为什么。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如何评估你的模型。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果再来一次，哪些地方会做得不一样。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;设计机器学习系统&#34;&gt;设计机器学习系统&lt;/h1&gt;

&lt;p&gt;系统设计方面，作者将其分为了4个层次，我这里也按她的逻辑进行。
&lt;img src=&#34;https://kuhungio.me/images/ml_sys_design/ml_project_flow.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;项目准备&#34;&gt;项目准备&lt;/h2&gt;

&lt;p&gt;项目准备阶段，一般从三个角度思考。如同写程序一样，首先思考需要达成什么样的目标；其次是有哪些限制条件；最后是特殊例子的考虑。&lt;/p&gt;

&lt;p&gt;展开来讲，需要达成什么样的目标：即最后用户怎么使用你的系统，你的系统吞吐多块、响应多快。&lt;/p&gt;

&lt;p&gt;项目的限制条件包括：项目周期多长，有多少算力，需要何种能力，有哪些可用资源。&lt;/p&gt;

&lt;p&gt;特殊例子即：是否需要结合用户做特殊化处理，例如千人千面。&lt;/p&gt;

&lt;p&gt;最后，如同老师设计考试一样，需要考虑如何评估你的系统性能。&lt;/p&gt;

&lt;h2 id=&#34;数据流&#34;&gt;数据流&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Machine learning is driven more by data than by algorithms&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;数据这里主要涉及数据的采集、存储和处理。&lt;/p&gt;

&lt;p&gt;对于数据的采集，需考虑数据的可获得性和数据的质量。换句话说即，有哪些数据、数据的质量如何、还有哪些数据可以获取到。&lt;/p&gt;

&lt;p&gt;数据存储问题需考虑：数据现在存在哪里、每个样本有多大、需要什么样的数据结构进行存储。&lt;/p&gt;

&lt;p&gt;存储之后是数据处理，这一块原文的问题都很好，建议细读。抛出了以下问题：如何将原始数据转化为需要的数据、需要做特征工程吗、需要归一化吗、如何处理缺失数据等。&lt;/p&gt;

&lt;p&gt;最后是两个值得从业者都重视的问题：用户隐私和系统偏差。&lt;/p&gt;

&lt;p&gt;系统需要反馈，则不可避免需要收集用户数据。这里需思考哪些数据可以收集、哪些数据需要用户的同意，以及采用何种形式收集。&lt;/p&gt;

&lt;p&gt;而对于系统性的偏差，一个成语来形容：管中窥豹。如果你的系统是那根管子，你看到的就会是带有偏差的东西。需要时刻提防系统偏差带来的偏见，防止模型放大这种偏见。&lt;/p&gt;

&lt;h2 id=&#34;建模&#34;&gt;建模&lt;/h2&gt;

&lt;p&gt;建模对于熟悉各类算法竞赛的人来说，问题不大。但还是需要强调，生产环境不同于竞赛或学术。模型选择上，简单模型优先。&lt;/p&gt;

&lt;p&gt;简单模型有如下好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;逐渐增加负责度，有利于调试&lt;/li&gt;
&lt;li&gt;作为 baseline，方便判断模型好坏&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;选择一个好的 baseline，可以帮助判断问题是否适合上模型。baseline 设置有如下三种方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;随机 baseline&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;专家 baseline&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;简单的统计 baseline&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后需要强调的是，深度学习并非万能，非深度学习方法也很管用。比起深度学习需要的大量数据，你可能更需要的是早期的用户。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Deep learning needs data，you might first need users.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;模型的-debug&#34;&gt;模型的 debug&lt;/h3&gt;

&lt;p&gt;不收敛、过拟合、权重大幅波动&lt;/p&gt;

&lt;h5 id=&#34;常见可能&#34;&gt;常见可能&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;理论局限&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;错误的假设前提&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;复杂模型&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;拼写错误&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;超参数不合适&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据问题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;调试的几个建议&#34;&gt;调试的几个建议&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;逐渐增加复杂度&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;刚开始简单一些，用简单模型验证模型&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在小批次数据上过拟合&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;以此验证模型的极限，观察模型是否适合该问题&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;设置随机种子&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;保持结果能够复现&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;服务部署&#34;&gt;服务部署&lt;/h2&gt;

&lt;p&gt;模型走到最后一步，就是 Serving。这里我将其翻译为服务部署。类似的文章我也写过，主要是技术层面，可参考：&lt;a href=&#34;https://kuhungio.me/2019/flask_vue_ml/?utm_source=website&amp;amp;utm_campaign=ml_sys_design&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://kuhungio.me/2019/flask_vue_ml/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里从逻辑层面讲述，主要分为两个部分，以交付用户为分割点。&lt;/p&gt;

&lt;p&gt;交付用户前：从用户收集何种反馈，如何判断模型是否正常。&lt;/p&gt;

&lt;p&gt;交付用户后：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;是否需要拟合最新的反馈结果&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;是否需要个性化服务&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;多久更新一次模型&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后是一些其他问题，诸如：业务是否需要模型的可解释性，潜在的数据偏差是否误导了模型等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;All models are wrong, but some are useful.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;10个经典案例学习&#34;&gt;10个经典案例学习&lt;/h1&gt;

&lt;p&gt;作者罗列了10个精彩案例，知名企业的机器学习系统设计文章。但由于一些技术原因，部分内容加载缓慢或无法加载。我这里将其转成 pdf 同步到了我的 Github 上，笔记标注版放在了我的公众号&amp;ndash;谷粒说数上，欢迎大家捧场。&lt;/p&gt;

&lt;p&gt;就内容而言，简单点评一下：&lt;/p&gt;

&lt;p&gt;读后收获最大的是第五篇文章，讲 Airbnb 搜索排序的迭代过程。该文详细描述了初始版到线上版的迭代过程，辅以详细的特征手法和数据说明。同时也是很好的 CTR 点击率转化教程。其他的不读都可以，这篇强烈建议阅读。
&lt;img src=&#34;https://kuhungio.me/images/ml_sys_design/airbnb.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;做得最好看得要数第七篇文章，instacart 公司在配送货物过程中，利用可视化辅助算法决策。
&lt;img src=&#34;https://kuhungio.me/images/ml_sys_design/visual.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;更多得精彩，有待各位去发现啦。&lt;/p&gt;

&lt;p&gt;案例地址：&lt;a href=&#34;https://github.com/kuhung/machine-learning-systems-design/tree/master/pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/kuhung/machine-learning-systems-design/tree/master/pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;笔记标注版：关注公众号【谷粒说数】，陆续放出。&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;27道练习题&#34;&gt;27道练习题&lt;/h1&gt;

&lt;p&gt;俗话说，学而不思则殆。作者也总结了27道系统设计的练习题，但感觉没有网页看着爽，于是便捣鼓上线了网站，后续将引入评论功能，欢迎贡献答案。合适的答案将整理署名后，反馈给原作者。&lt;/p&gt;

&lt;p&gt;练习网站：&lt;a href=&#34;https://kuhungio.me/machine-learning-systems-design/?utm_source=website&amp;amp;utm_campaign=ml_sys_design&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://kuhungio.me/machine-learning-systems-design/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/ml_sys_design/website.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;不知道对于机器学习系统设计，你有什么想法呢？欢迎在屏幕下方留言。&lt;/p&gt;

&lt;p&gt;喜欢我的朋友，别忘了点赞 👍、喜欢 ❤ +关注 🔔哦，你的鼓励是对我最大的支持~💪
&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于我&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dataops 数据化运维实践</title>
      <link>https://kuhungio.me/2019/dataops/</link>
      <pubDate>Sat, 19 Oct 2019 11:33:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/dataops/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;翻译自：《What is DataOps? Everything You Need to Know》 From Oracle Data Science Blog&lt;/p&gt;

&lt;p&gt;图片自：《DataOps is Not Just DevOps for Data》By DataKitchen in Medium&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;DataOps, 看到它的第一眼，大多数人会觉得陌生。但是提到另一个词——DevOps，做开发的同学可能会有些熟悉。DataOps 的理念与 DevOps 类似：&lt;strong&gt;将开发或者说是数据，与运维、测试相结合，自动化业务的交付以及架构的变更，使得构建、测试和发布能够更加快捷、频繁且可靠。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/dataops.PNG&#34; alt=&#34;DevOps&amp;amp;DataOps&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DataOps，全称 Data Operations，是一种敏捷运维方法，无感知地将IT基础设施和大数据分析技术结合起来。它的目的是通过结合数据管理的目标与过程，加快分析的速度与准确度。&lt;strong&gt;而这一过程，通常会涉及数据的多个流程：数据获取、数据质量检查、自动化、集成，以及最终的模型部署与管理。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/dataopspipeline.PNG&#34; alt=&#34;DataOps pipeline&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最核心的，DataOps 是为了方便管理数据、特别是当你有了一个特定的数据目标的时候。举个例子：为了&lt;strong&gt;降低客户的流失率&lt;/strong&gt;，可以通过利用客户数据构建一个&lt;strong&gt;推荐引擎&lt;/strong&gt;，推荐客户相关的东西，以此来减少浏览到下单的时间，减少客户流失。&lt;/p&gt;

&lt;p&gt;这是一个很自然的想法，但是却并不是一件容易的事情。上面的设想需要以下条件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;你的数据科学团队能够获取到他们需要的数据，同时能够有工具去部署模型。&lt;/li&gt;
&lt;li&gt;除此之外，还需要能够将模型集成到你的网站中去，在新数据上训练以持续的改进。&lt;/li&gt;
&lt;li&gt;最后，需要一套报表系统来监控其表现。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现在比较流行的做法，做好上面的事情，需要多个部门的合作，包括工程师、IT运维人员以及业务团队。&lt;/p&gt;

&lt;h2 id=&#34;谁能从-dataops-中获利&#34;&gt;谁能从 DataOps 中获利？&lt;/h2&gt;

&lt;p&gt;总的来说，&lt;strong&gt;几乎所有人都会从 DataOps 中获利&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更好的数据管理将会带来更多可利用的数据；&lt;/li&gt;
&lt;li&gt;越好的数据质量会有更准确的分析，与之相伴的就是更好的 insights、商业策略以及更高的利润。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DataOps 起一个润滑剂的作用，使数据团队、工程师团队和技术专家之间的工作更加紧密、更加自动化，以此来充分发掘数据价值、减少时间。&lt;/p&gt;

&lt;p&gt;Ashish Thusoo，Qubole 的联合创始人曾在书籍《Creating a Data-Driven Enterprise with DataOps》写道：我在2007年的夏天加入 FaceBook 的数据团队。像平常一样，公司里的任何人想获取无论多小的数据，都不得不找到数据团队，并发起流程。我们的数据团队很优秀，但是他们的精力也有上限。很明显，这是一个&lt;strong&gt;瓶颈&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/operations.PNG&#34; alt=&#34;业务团队与数据团队需要频繁对接&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;dataops-这一概念从何而来&#34;&gt;DataOps 这一概念从何而来？&lt;/h2&gt;

&lt;p&gt;DataOps 起源于 &lt;strong&gt;DevOps&lt;/strong&gt; 这一概念。据了解，财富1000强的公司里，80%的公司已经采用了 DevOps 这一方法。DevOps 的成功主要仰仗于：它把之前独立的两个部门联合在了一起——开发和运维。在 DevOps 的世界里，软件的发布是迅速且持续的，因为整个团队都被整合在了一起，用来检查并处理当下的问题。&lt;/p&gt;

&lt;p&gt;DataOps 继承了这一观念，并将之应用在数据生命周期里。DevOps 的持续集成、交付和运维的理念在数据的处理和产品化过程中也有所体现。具体来讲：&lt;strong&gt;数据科学团队利用软件版本控制工具 git、svn 来记录代码的变更，同时使用 Docker 和 Kubernetes 等容器技术来创建分析和部署模型。将数据科学与 DevOps 相结合的过程，也可被称之为“持续分析”。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;如何在组织中应用-dataops&#34;&gt;如何在组织中应用 DataOps？&lt;/h2&gt;

&lt;p&gt;正如你所看到的，DataOps 的应用，并非某种特定方法，而是一些&lt;strong&gt;关键领域的聚焦&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;以下是相关领域：&lt;/p&gt;

&lt;h3 id=&#34;data-democratization&#34;&gt;Data Democratization&lt;/h3&gt;

&lt;p&gt;根据 Experian Data Quality 调查显示：&lt;strong&gt;96%&lt;/strong&gt; 的首席数据官认为相关人员需要比以往更多的数据权限，&lt;strong&gt;53%&lt;/strong&gt;的人认为数据权限是最大的决策障碍。与之相反的是，我们当下有大量的数据在产生、存储。据测算。截至2020年，我们将会产生 &lt;strong&gt;40 zettabytes&lt;/strong&gt; 的数据，相当于地球上的人每人拥有 &lt;strong&gt;5200 GB&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;正如 thusso 在他 Facebook 工作期间看到的一样，缺少数据权限将是创新的极大障碍。自助的数据权限和相关的基础设施显得尤为重要。机器学习和深度学习应用需要持续不断的新数据以训练和改进；而想成为顶尖公司则需要其数据真正容易获取。&lt;/p&gt;

&lt;h3 id=&#34;leverage-platforms-and-open-source-tools&#34;&gt;Leverage Platforms and Open Source Tools&lt;/h3&gt;

&lt;p&gt;在一期 Forbes 中，Technology Strategy Crystal Valentine 的 VP MapR 描述道这一层次的 DataOps：“首先，在工具层面，DataOps 需要一个社区主导、支持主流语言和框架的&lt;strong&gt;数据科学平台&lt;/strong&gt;。”除此之外，数据迁移、编排、集成、性能监控的平台也同样重要。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/tools.PNG&#34; alt=&#34;数据科学平台&#34; /&gt;&lt;/p&gt;

&lt;p&gt;敏捷并不意味着需要浪费时间开发非必须的东西，或者是重复造一些已经开源的工具轮子。综合考虑你的数据需求且评估你的技术栈，选择合适的开源工具即可。&lt;/p&gt;

&lt;h3 id=&#34;automate-automate-automate&#34;&gt;Automate, Automate,Automate&lt;/h3&gt;

&lt;p&gt;这一理念直接取自 DevOps：为了更及时的评估数据集成的价值，自动化一些步骤是非常重要的。比如说&lt;strong&gt;质量保证测试&lt;/strong&gt;和&lt;strong&gt;数据分析的管道监控&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/monitoring.PNG&#34; alt=&#34;自动化监测&#34; /&gt;&lt;/p&gt;

&lt;p&gt;采用&lt;strong&gt;微服务自给自足&lt;/strong&gt;也是同样的道理。 举个例子：让你的数据分析师能够以 &lt;strong&gt;API&lt;/strong&gt; 的方式自行部署模型，这意味着开发团队能够在不重构的基础上集成该功能。这将带来生产力的提升。&lt;/p&gt;

&lt;h3 id=&#34;govern-with-care&#34;&gt;Govern With Care&lt;/h3&gt;

&lt;p&gt;越来越多的公司开始采用 Center of Excellence 的方法来实现数据科学管理，这并非是偶然。只有在建立一套数据的处理、工具平台、基础设施、权限划分以及性能监控后，才能真正获取数据科学、或者说是 DataOps 的投资回报。&lt;/p&gt;

&lt;p&gt;因此，在该领域&lt;strong&gt;62%&lt;/strong&gt;的优秀人士有一个清晰且正确的数据科学发展计划。与之相对应的是仅仅28%的普通人和29%的公司有这么一个想法。&lt;/p&gt;

&lt;h3 id=&#34;smash-silos&#34;&gt;Smash Silos&lt;/h3&gt;

&lt;p&gt;除上面列到的4项以外，&lt;strong&gt;跨部门合作&lt;/strong&gt;也是应用 DataOps 非常重要的一点。DataOps 化过程中引进的工具和平台应该服务于更大的目标：&lt;strong&gt;整合不同的团队以更高效的使用数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/collaboration.PNG&#34; alt=&#34;跨部门合作&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;“注意：数据并不属于 IT、数据科学家或者数据分析师。”Thusso 写道：“它属于业务中的所有人。所以，&lt;strong&gt;你的工具应该允许雇员创造他们自己的分析与可视化报告，并且能够在同事间分享他们的发现。&lt;/strong&gt;”&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于译者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《学习之道》笔记思维导图</title>
      <link>https://kuhungio.me/2019/the_way_to_learn/</link>
      <pubDate>Wed, 16 Oct 2019 07:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the_way_to_learn/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/waytolearn.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习实践--测试驱动开发</title>
      <link>https://kuhungio.me/2019/tdd_drive_ml/</link>
      <pubDate>Sun, 25 Aug 2019 00:22:07 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_drive_ml/</guid>
      <description>

&lt;h2 id=&#34;机器学习现状与问题&#34;&gt;机器学习现状与问题&lt;/h2&gt;

&lt;p&gt;2012年，数据科学击败生命科学，成为”21世界最性感的职业“。2016年，AlphaGo 战胜人类顶尖围棋手，深度学习、人工智能一度占领新闻头版头条，并引起一股机器学习新热潮。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/baidu_index.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这一效应，一直持续到今年：在2019这一年，高考志愿填报金融遇冷，计算机一跃成为抢手专业，在各大工科院校中，有取代传统电气、机械之势；各学院的研究生院，纷纷开始往人工智能、深度学习上贴近。&lt;/p&gt;

&lt;p&gt;这从一个侧面，反应了民众对于计算机、人工智能、机器学习的就业预期。但是，随着原来越多的从业者涌入，项目落地越来越多，机器学习这一领域的问题也开始暴露，亟需解决。&lt;/p&gt;

&lt;h3 id=&#34;机器学习中的常见问题&#34;&gt;机器学习中的常见问题&lt;/h3&gt;

&lt;p&gt;机器学习的问题，由其特性所致。众所周知，机器学习的发展，离不开大数据技术。海量数据的收集、存储，让算法有了更强大的生命力。通过对大量数据的挖掘、学习，机器学习能够猜你所想，提升购物网站的转化率；能够识别障碍，让自动驾驶成为可能；能够识别风险，扩大业务同时减轻坏账。&lt;/p&gt;

&lt;p&gt;由此，针对模型和数据的关系，大致可以分为三类问题。第一种：数据量不足，模型过拟合。算法学习的过程就犹如考前刷题，过拟合相当于只刷一套题，这样的后果就是上一套不同的卷子，算法就懵逼了。第二种：数据量充足，模型欠拟合。欠拟合的算法就像是心思不在学习上的孩子，报再多的补习班，结果也不会太好。最后一种：数据不稳定。算法前期可能很好的学到精髓，但是随着数据的变化，时间的流逝，模型很可能将变得不可预测。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/problem-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;测试驱动开发的解决之道&#34;&gt;测试驱动开发的解决之道&lt;/h2&gt;

&lt;p&gt;机器学习的实现方式还是通过软件工程、代码实现，既然是代码，那就存在应对范式。这里，就不得不提 Test Driven Development（测试驱动开发），简称 TDD。TDD 是一种很朴实的想法，在编码开始前，评估需要交付的功能点并写测试用例，一开始的时候测试会失败，接着编写代码修复测试，最后测试通过，修复代码。这里的方式，通俗来讲就是：&lt;strong&gt;目标导向，先成事，再迭代。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/tdd.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;测试驱动有一个明显的好处就是，能够加快产品发布速度。以往的项目，需求讨论会占据很大时间，讨论完之后，开发方案一旦定下来，后续变更就很难。而现实却是需求常常变更，这往往会导致产品发布的延期。而在机器学习上，测试驱动好处更多体现在保证模型质量上。具体来讲，常通过以下办法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;交叉验证    通过交叉验证来验证拟合效果&lt;/li&gt;
&lt;li&gt;运行速度测试    根据奥卡姆剃刀原则：”如无必要，勿增实体“；简单模型胜过复杂模型&lt;/li&gt;
&lt;li&gt;衔接测试    对数据的输入输入进行检测，以防止数据异常波动对模型影响&lt;/li&gt;
&lt;li&gt;指标追踪    监控关键指标，不断追踪模型的性能，防止失效模型继续运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/tddsolution.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;机器学习的债务危机&#34;&gt;机器学习的债务危机&lt;/h2&gt;

&lt;p&gt;测试驱动开发一定程度上能减轻机器学习中的问题，但是它只是一种表象。测试通过了，不代表算法模型就没有问题了。魔鬼藏在细节中。机器学习目前仍存在一些技术债务，仍需按特定原则对代码修复，迭代演进。&lt;/p&gt;

&lt;h3 id=&#34;什么是技术债务&#34;&gt;什么是技术债务&lt;/h3&gt;

&lt;p&gt;技术债务是一个比方，类比的金融领域的债务。一般指为了加快软件开发速度，折中妥协，选择易于实现的方式，结果是短期加速了软件开发，但长期来讲，开发负担累计，发布逐渐停滞。债务不都是有害的。在业务扩张，市场抢占时期，适当的债务有助于公司扩张。但是若一直不管不顾，最后只能花更大的成本去维护它，直至无法维护。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/debt.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;机器学习中的技术债务&#34;&gt;机器学习中的技术债务&lt;/h3&gt;

&lt;p&gt;机器学习项目中同样存在债务危机，Google 还就此写了篇文章 《Machine Learning: The High interest Credit Card of Technical Debt》。总结起来有三种：一、边界模糊，数据之间彼此依赖关联。二、没有系统级别代码分离，胶水代码处理一切。三、机器学习系统随着外部世界的改变而彻底改变。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/debt-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;偿还债务&#34;&gt;偿还债务&lt;/h2&gt;

&lt;p&gt;代码重构，就犹如对你的资产进行一次清点盘算：清除不良资产、偿还债务、进行资产上的重新配置。重构能够有效减缓技术债务带来的负面影响。&lt;/p&gt;

&lt;h3 id=&#34;面向对象的-solid-原则&#34;&gt;面向对象的 SOLID 原则&lt;/h3&gt;

&lt;p&gt;SOLID 原则由罗伯特·C·马丁提出，是五项原则&amp;ndash;单一职责、开闭原则、替换原则、接口隔离、依赖倒置的缩写，是面向对象设计与开发的五个基本原则。通过这五项原则，写出来的程序可读性、可扩展性都大大提高，软件维护和系统扩展变得更加容易。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SRP 单一职责原则：一片代码只做一件事，及一块代码只实现某一特定功能，尽量减少逻辑的交叉堆叠。&lt;/li&gt;
&lt;li&gt;OCP 开闭原则：对象对于扩展开放，对于修改关闭。即保持最小单元，写完后不去修改它，而是通过扩展或者配置的方式补充功能。&lt;/li&gt;
&lt;li&gt;LSP 替换原则：任何的子类应该轻松由同一对象树的其它对象替代。&lt;/li&gt;
&lt;li&gt;ISP 接口隔离原则：不同的接口做不同的事，软件开发没有银弹，接口也是。解耦能解决掉开发过程中“牵一发而动全身”的情况。&lt;/li&gt;
&lt;li&gt;DIP 依赖倒置原则：抽象来自于细节、来自于底层，开发依赖抽象。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/solid.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;机器学习与-solid-原则&#34;&gt;机器学习与 SOLID 原则&lt;/h3&gt;

&lt;p&gt;将 SOLID 原则应用于机器学习，会发现：机器学习与 SOLID 原则相互交织。诸如机器学习中的降维，是在减少耦合；胶水代码、数据依赖又与 SOLID 原则相抵触。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单一职责

&lt;ul&gt;
&lt;li&gt;机器学习中的数据相互依赖，更有利用 GBDT 生成特征，这一情况与单一职责冲突。所幸可通过降维、正则化的手段减轻影响。&lt;/li&gt;
&lt;li&gt;数据获取、数据处理、特征工程、模型训练、模型预测、数据监控，各模块无系统级代码分离，胶水代码处理一切。开发时应小心谨慎。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;开闭原则

&lt;ul&gt;
&lt;li&gt;代码上可以做到开闭，但机器学习会作用于真实世界，引起的反馈将传导至模型内部。如模型预测出一批”潜在犯罪“，于是加大警力盯住这些人，最后发现他们的犯罪率果然高于常人。但他们就真的比别人更”坏“吗？这里有一个”预测、实施、证实“的偏差存在，算法无形中放大了偏见。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;替换原则

&lt;ul&gt;
&lt;li&gt;机器学习的模型效果常由强特征决定，且特征众多。应用尽可能少的特征和数据，取得稳定结果。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;接口隔离

&lt;ul&gt;
&lt;li&gt;模型的数据上游，可能会多个部门共用，数据源的人为变化，可能会导致模型的突然失效。因而需要对数据输入进行监控。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;依赖倒置

&lt;ul&gt;
&lt;li&gt;测试代码、中间数据大量堆积，各个部分相互依赖。应定时对遗留代码和中间数据进行清理。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/solid-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;机器学习、人工智能在经历这几年的爆发之后，出现了很多病症。测试驱动开发、SOLID 原则重构能够有效的缓解病症，还系统健康。如果你的项目已经落地，用 SOLID原则进行一次检查；如果项目还未实施，不妨尝试下测试驱动开发。系统更好的可读性、可维护性，不仅是程序员的责任，更是评判机器学习从业者的一把尺子。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/Mind-map.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;不知道读者朋友对此怎么看，欢迎就此在评论区发表你的看法。喜欢本文的读者，别忘了点赞、喜欢、加关注哦，你的鼓励，将是我写作分享的动力💪&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/SOLID_(面向对象设计)&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;wikipedia SOLID 原则 &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《Python 机器学习实战&amp;ndash; 测试驱动的开发方法》&lt;/li&gt;
&lt;li&gt;《高效程序员的45个习惯&amp;ndash;敏捷开发修炼之道》&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;关于作者-about&#34;&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;谷粒，华中科技大学毕业，某游戏公司从事数据挖掘工作，常与机器学习、数据系统打交道。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>测试驱动的机器学习思维导图</title>
      <link>https://kuhungio.me/2019/tdd_with_ml/</link>
      <pubDate>Thu, 22 Aug 2019 00:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_with_ml/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/TDD.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>金字塔原理思维导图</title>
      <link>https://kuhungio.me/2019/pyramid/</link>
      <pubDate>Thu, 15 Aug 2019 00:47:36 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/pyramid/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/pyramid.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>敏捷革命思维导图</title>
      <link>https://kuhungio.me/2019/scrum/</link>
      <pubDate>Sat, 10 Aug 2019 00:54:34 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/scrum/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/scrum.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>系统思考与卓有成效的管理者</title>
      <link>https://kuhungio.me/2019/manadement/</link>
      <pubDate>Wed, 17 Jul 2019 17:02:56 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/manadement/</guid>
      <description>

&lt;p&gt;在老一辈的眼中，学而优则仕。学习好了就去当官从政，去服务别人。而在父母这一辈人的眼中，不论你干啥，当“老实人”被人管是不行的，他们的观点有一定的时代背景，但仍然在潜移默化影响着每个人。&lt;/p&gt;

&lt;p&gt;而对于初入职场的新人来说，虽然暂时当不上管理者，但被管理时却也会思考：“如果是自己，将会怎样去做管理？” 对于这一批新的90后甚至00后来说，管理并不再是一场服从性测试，权威性的组织管理方法或不再有效。&lt;/p&gt;

&lt;h2 id=&#34;什么是这些年轻人喜欢的管理风格呢&#34;&gt;什么是这些年轻人喜欢的管理风格呢？&lt;/h2&gt;

&lt;p&gt;如果稍微读过一些管理学的书籍，就会发现，管理其实在近现代发生了较大的变化。厚黑学受人推崇，有它的一定意义，但是小年轻们对里面的技巧似乎并不买账。这点在酒桌或者聚餐时就可以看得出来。这批年轻人有自己的想法，有独立的意识，甚至有些“不懂”人情世故。&lt;/p&gt;

&lt;p&gt;回顾历史，近现代企业管理做得比较好的，要当属日本。日本凭借其精益管理思路，在汽车制造业一举占领美国市场，打得美国的传统汽车巨头没有还手之力。在大学里，作为机械大类的学生，一定多少接触过精益生产。&lt;/p&gt;

&lt;p&gt;这套理念，帮助日本一跃成为制造业强国。而反观国内，作为一个机械大类出身的同学，你一定知道国内的“中国制造”现状是什么。而作为一个跨行的 IT 向工程师，在实践中，也发现，以信息互联标榜自己的互联网，除了开源的代码复制粘贴得挺快，管理模式其实并没有跟上节奏。&lt;/p&gt;

&lt;p&gt;今天，在当下环境中，还有很多管理者是靠着本能在管理，而不是一套系统科学的方法。一个程序员，或者是 IT 企业的中层管理，有时间去研究业务，却少有时间去研究管理。项目短平快上线、管理粗糙莽随意。像极了早期国内自然资源开采，先污染后治理的样子。&lt;/p&gt;

&lt;h2 id=&#34;it-工程师眼中的现代管理究竟应该是什么样的呢&#34;&gt;IT 工程师眼中的现代管理究竟应该是什么样的呢？&lt;/h2&gt;

&lt;p&gt;我们接着从上面的日本制造业说起。在当时，他们推崇一种见 kanban 的工作法。即在看板上列出工作事项，工作流公开透明。而在当下，国内头条、国外谷歌都在推崇 OKR。这里两者的本质是相通的，即：公开透明公司的业务流，每个人都能参与到目标设定里面来。&lt;/p&gt;

&lt;h3 id=&#34;低效的管理者&#34;&gt;低效的管理者&lt;/h3&gt;

&lt;p&gt;在执行这套的同学可能会说，这其实只是形式主义，到头来还是 KPI 导向，面向 PPT 晋升。这在企业中确实存在，而其中的缘由，有以下5点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;管理者不能良好的安排自己的时间，自己的时间属于别人&amp;ndash;无尽的会议、向上汇报、向下沟通&lt;/li&gt;
&lt;li&gt;眼光受限于岗位，注意力集中在流程、规范与控制上，而不是贡献&lt;/li&gt;
&lt;li&gt;没能充分发挥人的长处，无论是自己、上司抑或是下属。总认为下属不能很好地完成工作。从职位出发去设定一个人能做什么、不能做什么。不能容忍人之短。&lt;/li&gt;
&lt;li&gt;零碎容易完成的优先做，根据和需求方的亲疏远近安排优先级，而不是要事优先&lt;/li&gt;
&lt;li&gt;无法有效决策，没有流程，不愿放权。决策没有边界，不设立反馈机制，任由自己的“偏见”主导决策&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;做好了上面的5点，企业就能蒸蒸日上了吗？其实也不是，如果没有一个学习型的组织，单靠个人也是难以推动的。千里马常有，而伯乐不常有。运气好，遇到一个放权给你的领导，做起来是运气，做不起来是常态。企业中的死海效应，“劣币驱逐良币”也同样常见。&lt;/p&gt;

&lt;h3 id=&#34;螺旋沉默的组织团队&#34;&gt;螺旋沉默的组织团队&lt;/h3&gt;

&lt;p&gt;也就是说，还需要一个良好的组织氛围。而变成一个死海的组织氛围常有以下特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安于现状，封闭思想。更愿以主观的视角观察现实，而不是客观。&lt;/li&gt;
&lt;li&gt;心智模式不成熟。对已有的成功盲目崇拜模仿，而忽视掉其潜在的天时地利人和背景。&lt;/li&gt;
&lt;li&gt;各自有各自的小算盘，没有共同的愿景。&lt;/li&gt;
&lt;li&gt;团队内部给自为战，几乎不存在团队学习。&lt;/li&gt;
&lt;li&gt;局部思考而不是系统思考。认为危机的主因是人或事，而不是系统机制的问题。从未留意过系统如何塑造自己的行为。不清楚系统的边界、增长极限、反馈回路以及压力是如何转移的 。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果是想做一个失败的管理者，营造一种糟糕的团队氛围，按照上面做准没错。&lt;/p&gt;

&lt;h3 id=&#34;短期利益驱动的变革&#34;&gt;短期利益驱动的变革&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;学校教育告诉我们：永远不能承认我们不知道的答案。而大多数公司还在强化这种训练，奖励善于推销自己观点的人，却忽视对复杂问题的探寻。（还记得上一次你的组织给对公司现行政策提出难题的人——而不是解决某个紧迫问题的人——颁发奖励是什么时候吗？）&amp;ndash; 《第五项修炼》&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;别急，是不是准备收藏，并在组织中逆向推行以上措施呢？那你可能又陷入了组织变革中的另一个陷阱：在变革过程中，我们不仅难以看到整片森林；甚至，我们还会挑出一两棵我们认为最看好的树，然后就全神贯注在它们身上，为它们而倾注全部的变革努力。&lt;/p&gt;

&lt;p&gt;为什么目前还有很多的 IT 企业管理者，在靠着本能管理呢？一个字：利。 无利不起早。 概念发明以后，还要在有实用价值的成本范围内，以一定的规模进行可靠的复制，它才能够真正落地。&lt;/p&gt;

&lt;p&gt;为什么大家都觉得修正以上的问题是不符合利益的呢？因为很多时候，都是想短期梭哈一波，先用着后面再说，先这样管理出问题了再说。即忽视了系统性的东西，而仅专注于眼前的事物。&lt;/p&gt;

&lt;h2 id=&#34;系统思考&#34;&gt;系统思考&lt;/h2&gt;

&lt;p&gt;如果想在组织中构建学习型组织，成为一个卓有成效的管理者，那肯定不是忽视系统思考的力量。&lt;/p&gt;

&lt;p&gt;关注长期的行为和系统内部的结构，而不是表象和短期事件；世界非线性，不要用线性的思维思考；恰当的划分系统的边界；充分考虑多方的限制因素及相对强弱。&lt;/p&gt;

&lt;p&gt;通过实际行为来推断系统目标，而不能只看表面的言辞或其标榜的目标。时间延迟无所不在，当下的干预很可能一段时间后才会产生影响。没有人能做到充分理性，每个人的理性都是有限的。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在最近和实习生同事的合作过程中，深切的感受到信息差带来的权力膨胀感。实际上，管理也是一门实践课程。一开始可能会走偏，但只要有回顾、有反思，也终究会上正轨。系统思考、长远为重。不仅要问这些年轻人想要什么、也要问自己想要什么。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B test 评价指标的选择</title>
      <link>https://kuhungio.me/2019/abtest-2/</link>
      <pubDate>Sat, 22 Jun 2019 15:28:01 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest-2/</guid>
      <description>

&lt;h2 id=&#34;如何定义一个评价指标&#34;&gt;如何定义一个评价指标&lt;/h2&gt;

&lt;p&gt;这是上一篇文章&lt;a href=&#34;https://kuhungio.me/2019/abtest/?utm_source=self&amp;amp;utm_campaign=abtest2&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;什么是 A/B test&lt;/a&gt;的续集，上一篇主要讲述 A/B 测试的历史，这里接着讲如何选择指标。&lt;/p&gt;

&lt;p&gt;从本人的经验来看，一个指标怎么选择确实重要，但更重要的是需要自上而下理解且落实科学实验。而不是拍脑袋想指标，中途随意更换指标，汇报时仅罗列有利的指标。&lt;/p&gt;

&lt;p&gt;如果要用一句话解释，如何定义一个评价指标，那一定是“以始为终”。在定义一个指标的时候，要想一想为什么要定义这个指标，这个指标的定义是为了说明什么情况，如果这个指标发生变化，将需要怎么去解释它。&lt;/p&gt;

&lt;h3 id=&#34;指标定义的两种情况&#34;&gt;指标定义的两种情况&lt;/h3&gt;

&lt;p&gt;在这里，定义指标的时候有两类：一是不变量，即变量组和对照组的都应该相同；另一个是变量，即需要观察改变的量。&lt;/p&gt;

&lt;p&gt;对于不变量，需要注意两者的总量是否相同，数据的分布是否相同。以上保证实验的正常进行。对于变量，首先思考高层次的商业指标。诸如收益、市场份额、用户量等。接下来就是细节的指标，如用户体验，网页停留时长。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;例如，在游戏中，新手教程没完成的玩家，虽然不能直接知道原因，但根据经验，可能是引导时间太长、网络卡顿或者是别的原因。类似这样的情况，是用户体验上的问题。后面也会有一些方法提到如何去评估它。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在实验中，可能得到的不是想要的信息、或者实验时间太短，得到的结果不准确。甚至有些东西无法衡量，这种情况又该如何去评估它呢。别急，下面的内容会给你回答。&lt;/p&gt;

&lt;h2 id=&#34;自顶向下设计评价指标&#34;&gt;自顶向下设计评价指标&lt;/h2&gt;

&lt;p&gt;如何确定指标来做健全性检验&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;高层次的指标（如：活跃用户数、点击转化率 CTR）&lt;/li&gt;
&lt;li&gt;指标细节（如：如何定义用户活跃）&lt;/li&gt;
&lt;li&gt;使用一组指标，并将他们整合为一个单一指标（如：总体评价指标（OEC））&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于评估，可以选择一个指标或一套指标。如果是使用一套指标，可以把他们聚合成一个指标，比如构造一个目标函数，或者是简单的加权指标。&lt;/p&gt;

&lt;p&gt;最后一点需要考虑的是：指标的普适性有多少。如果你在运用 A/B 测试，最好能有一个指标能够贯穿整个体系。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;举个例子：用户漏斗。&lt;/p&gt;

&lt;p&gt;它表示用户通过站点执行的一系列步骤。 之所以被称为漏斗，是因为每个后续阶段的用户数都少于上面的阶段。 每个阶段都是一个指标——总数，比率和概率。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;数据不足怎么办&#34;&gt;数据不足怎么办&lt;/h2&gt;

&lt;p&gt;有些数据可能难以获得，主要原因如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有数据的权限&lt;/li&gt;
&lt;li&gt;需要较长时间去收集数据&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;使用外部数据&#34;&gt;使用外部数据&lt;/h3&gt;

&lt;p&gt;其它数据收集的技巧：3种公司常用的方法&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;数据中间商&lt;/li&gt;
&lt;li&gt;调研公司&lt;/li&gt;
&lt;li&gt;学术文章&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上能够帮助你依照整个行业设定指标。&lt;/p&gt;

&lt;h3 id=&#34;额外的内部数据&#34;&gt;额外的内部数据&lt;/h3&gt;

&lt;p&gt;额外的内部数据也可被使用，例如：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;回溯性分析：查看历史数据以找寻改变并进行评估&lt;/li&gt;
&lt;li&gt;调研与用户研究：这个帮助你找到你想研究的点&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上办法的缺点是它只告诉了你相关性、没有告诉你因果性，而实验一定程度上可以解释因果。&lt;/p&gt;

&lt;p&gt;最后，别忘了与你的同事交换意见，看看他们认为重要的指标有哪些。&lt;/p&gt;

&lt;p&gt;附：&lt;a href=&#34;https://s3-us-west-2.amazonaws.com/gae-supplemental-media/additional-techniquespdf/additional_techniques.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;其它获得额外数据的方法&lt;/a&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;用户体验研究（UER）——高深度少用户。这也适用于头脑风暴，在 UER 中也可以使用诸如眼动相机的设备，同时回溯历史进行分析。&lt;/li&gt;
&lt;li&gt;焦点小组——中等深度中等规模用户。能够在一些假设上获得反馈，但也容易陷入集体思想的情况（即真正的个人意见难以获得表达）&lt;/li&gt;
&lt;li&gt;调研报告——深度较低但用户规模大。对于一些难以直接衡量的指标很有用。不能用于直接和其它指标比较，因为调研的对象和指标很可能与大盘不同。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;指标的实际例子&#34;&gt;指标的实际例子&lt;/h2&gt;

&lt;p&gt;高层次指标：点击率&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定义一：Cookie 的总点击次数除以 Cookie 去重后的总数&lt;/li&gt;
&lt;li&gt;定义二：被点击的页面数除以总页面数&lt;/li&gt;
&lt;li&gt;定义三：总的页面点击次数除以总页面数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可能还需要过滤爬虫、牟利等行为以消除数据偏差。通过切片来判断数据是需要偏置还是过分偏置。在过滤掉数据后，计算每个切片的评价指标表现。如果数据表现有偏差，那说明数据里可能还需要调整。&lt;/p&gt;

&lt;p&gt;为了消除数据周期带来的周末效应，最好按周或者按年进行数据的划分。&lt;/p&gt;

&lt;h2 id=&#34;指标的特性&#34;&gt;指标的特性&lt;/h2&gt;

&lt;h3 id=&#34;指标的敏感性和鲁棒性&#34;&gt;指标的敏感性和鲁棒性&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;敏感性和鲁棒性：敏感性是指指标对所关系的事物是否足够敏感，而鲁棒性性是指对不关心的事物是否足够不敏感。这可以通过预先小规模实验，来验证指标是否符合直觉。另一个方法是使用 A/A 测试，也就是什么都不改变，以此来排除一些伪关系。&lt;/li&gt;
&lt;li&gt;分布：通过对历史数据的分析得到。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;指标的分类&#34;&gt;指标的分类&lt;/h3&gt;

&lt;p&gt;4类指标&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;计数或者求和（如：访问页面的用户数）&lt;/li&gt;
&lt;li&gt;指标的分布-平均数、中位数和百分位&lt;/li&gt;
&lt;li&gt;概率与比率（rates）&lt;/li&gt;
&lt;li&gt;比例（ratios）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;绝对指标与相对指标的选取&#34;&gt;绝对指标与相对指标的选取&lt;/h3&gt;

&lt;p&gt;比较测试组和控制组的最简单方法是做差。&lt;/p&gt;

&lt;p&gt;如果在做大量的实验，比较好的方法是多做相对的比较。比如百分比的变化情况。&lt;/p&gt;

&lt;p&gt;计算百分比指标的优势在于，你有一个明确的边界，该边界不会随着时间变化。如果同时在运行多组指标，那么你的绝对数据很可能经常变动。这时，使用相对指标的好处就显现出来了，数据不会随着系统的变化发生大幅度的改变。&lt;/p&gt;

&lt;p&gt;相对指标的主要缺点是：其灵活性和比例的相对差异不如绝对指标明显。&lt;/p&gt;

&lt;h3 id=&#34;参数估计&#34;&gt;参数估计&lt;/h3&gt;

&lt;p&gt;在实验前，需要检查指标的分布情况，以决定实验的规模、评估的置信区间以及支撑最后的结论。&lt;/p&gt;

&lt;p&gt;如果要检查的指标分布区间很大，那么最后的结果意义可能不大。&lt;/p&gt;

&lt;p&gt;为了计算置信区间，需要&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;方差（或者标准差）&lt;/li&gt;
&lt;li&gt;分布&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于二项分布，估计的方差为 p(1−p)/N。估计的均值方差为σ^2/N。如果原始数据是正常的，则中位数将是正常的。但如果原始数据不正常，则中位数可能不正常。由于中心极限定理，平均值通常是正态分布的，而与原始数据的分布无关。&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;x &amp;lt;- c(87029, 113407, 84843, 104994, 99327, 92052, 60684)
stder &amp;lt;- sd(x)/sqrt(length(x))
conf95_min = mean(x) -1.96*stder
conf95_max = mean(x) + 1.96*stder
conf95_min
## [1] 79157.54
conf95_max
## [1] 104367
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;非参数方法&#34;&gt;非参数方法&lt;/h3&gt;

&lt;p&gt;这是一种在不对分布进行假设的情况下分析数据的方法。 在谷歌，很少使用上面参数估计的方式，他们使用基于 A/A 测试的结果来评估方差。 如果在 A/A 测试中发现指标存在很多变化，则该指标可能过于敏感，无法使用。&lt;/p&gt;

&lt;p&gt;比起进行多组 A/A 测试，一种方法是进行大量的 A/A 测试，然后进行自助（bootstrap）来生成多组样本并测试变化范围。&lt;/p&gt;

&lt;p&gt;通过 A/A 测试，可以&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将结果与期望进行比较（健全性检验）&lt;/li&gt;
&lt;li&gt;根据经验估计方差，并使用对分布的假设来计算置信度&lt;/li&gt;
&lt;li&gt;直接估计置信区间而不用做任何数据假设&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总之，不同的指标具有不同的变化范围。某些指标的变化范围可能很大，即使它们具有商业或产品意义，也会使它们无法使用。对待他们，需要非常小心。&lt;/p&gt;

&lt;p&gt;对于许多分析师而言，与实际运行实验相比，大部分时间用于验证和选择指标。能够标准化定义指标在测试中至关重要。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;例如：网站延迟测试&lt;/p&gt;

&lt;p&gt;定义：是在谈论加载第一个字节和加载最后一个字节的时间，还是说别的什么东西呢。&lt;/p&gt;

&lt;p&gt;数据分布：此外，对于延迟，平均值可能根本不会改变。信号（例如慢速/快速连接或浏览器）会导致分布中十分集中，并且没有对应的调整方法。&lt;/p&gt;

&lt;p&gt;对策：在这种情况下，就需要查看百分位分布。这里的关键是要建立起直觉，必须了解数据和业务，并与工程师一起理解数据是如何被记录的。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>HIVE 技巧积累之合并重叠日期</title>
      <link>https://kuhungio.me/2019/merge_overlapping_date/</link>
      <pubDate>Sun, 09 Jun 2019 00:17:05 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/merge_overlapping_date/</guid>
      <description>

&lt;p&gt;目前网上流传着一个段子，说算法工程师实际上就是 SQL boy，数据分析师是 PPT boy。艺术来源于现实，实际上的我们真的有很多时间在写 SQL 出数据，或者是针对 bad case 做数据的进一步分析。&lt;/p&gt;

&lt;p&gt;这不，近期这边接到的一个需求就是对玩家的某项行为进行统计。一般来讲，掌握基本 SQL 的技巧，这些需求的难度都不大。但是这个需求需要将玩家用户的多个重叠日期进行拉伸去重。这一下可难到大伙儿。在自个儿思考无果，团队讨论之后也没啥直接的办法。&lt;/p&gt;

&lt;p&gt;在网上搜索一番后，很多都不是很对应。不过好在几轮筛选，找到了一个类似的需求。原文链接在这里：&lt;a href=&#34;https://stewashton.wordpress.com/2015/06/08/merging-overlapping-date-ranges/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;🔗&lt;/a&gt;。为了方便后来的人，在这里做个分析记录，以及后面举一反三该怎么做。毕竟这些东西很少出现在教程和课本里，但是当业务方有这个需求的时候，常常又很紧急，容不得细思慢想。&lt;/p&gt;

&lt;h2 id=&#34;问题定义&#34;&gt;问题定义：&lt;/h2&gt;

&lt;p&gt;在解决一个问题之前，我们需要先明确定义问题。这里的问题是对多个重叠日期，用 SQL 将其进行去重，并在 HIVE 环境中使用。&lt;/p&gt;

&lt;h3 id=&#34;对于日期情况的定义&#34;&gt;对于日期情况的定义&lt;/h3&gt;

&lt;p&gt;这里采用穷举法，可以得出以下13类情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;问题简化&#34;&gt;问题简化&lt;/h3&gt;

&lt;p&gt;解决问题的核心是简化问题。这个问题看起来情况众多，实际上，对于我们的任务，只有两种情况：一个是两个日期有重叠；一个是两个日期没有重叠。&lt;/p&gt;

&lt;p&gt;对于不同的情况，要做不同的处理。重叠日期取最大最小日期即可，非重叠的分段取。剩下的即是通过工具去实现逻辑。&lt;/p&gt;

&lt;h2 id=&#34;数据准备&#34;&gt;数据准备&lt;/h2&gt;

&lt;p&gt;这里采用原作的方式定义数据，创建出上面的13中情况。实际上，如果你的格式和下面的类似，做出对应的调整即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop table t purge;
create table t (
  test_case varchar2(32) not null,
  start_date date not null,
  end_date date not null
);
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义出来的数据如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_sample.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;with grp_starts as (
  select test_case, start_date, end_date,
  case
    when start_date &amp;gt; max(end_date) over(
      partition by test_case order by start_date, end_date
      rows between unbounded preceding and 1 preceding
    )
    then 1 else 0
  end grp_start
  from t
)
, grps as (
  select test_case, start_date, end_date,
  sum(grp_start) over(
    partition by test_case order by start_date, end_date
    rows between unbounded preceding and current row
  ) grp
  from grp_starts
)
select test_case,
min(start_date) start_date,
max(end_date) end_date
from grps
group by test_case, grp
order by 1, 2;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge_result.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里的的核心思想同上：&lt;strong&gt;判断日期是否重叠，重叠日期取最大最小的日期，非重叠日期分段取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里使用了 &lt;code&gt;with&lt;/code&gt; 技巧，通过该技巧，将数据临时存储至内存，加速了执行速度。这句话是网上能直接搜到的，但实际上它还有另一个功能上的作用。即抛开性能作用来说，&lt;code&gt;with&lt;/code&gt; 语法能够对先前的查询结果进行下一步的处理。这意味着不用频繁的建立中间表，省去空间或是简化了逻辑的复杂度。&lt;/p&gt;

&lt;p&gt;这里主要分为三段：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;判断日期是否重叠：对数据以 test_case 为划分依据，按开始日期和结束日期排序。比较当前开始日期和之前的结束日期，若开始日期大于最大的结束日期，说明两日期无重叠，grp_start 标志位记为1，反之记为0。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对相邻重叠日期做区分：按同样的划分排序方式。对当前日期及以前的 grp_start 求和，由于重叠日期被标记为0，因而最后相邻重叠日期的 grp 标志位将相同，其余日期各不相同。起到区分不重叠日期，合并重叠日期的作用。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;分组选取最大最小值，得到结果：按 test_case 与 grp 分组，选取各组最小和最大的日期，最后按第一列和第二列排序，得到目标结果。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;小结：通过拆分的思想+窗口函数的帮助，出色完成组织交代的任务，在 HIVE 中实现了合并重叠日期这一任务。但同时也要注意，在功能保证的同时，该脚本如同算法一样，也是有边界的。比如当 end_date 为空时，将会出现错误。这种情况最好先把空值填充为特殊值 ‘9999-12-31’，结束后再转换为空值。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在 HIVE 中合并重叠日期，一开始看起来很难，但实际上学会分析问题，分解问题，简化问题，其实不难。网上有很多有用的资源，要学会合理利用。在实现基本需求的同时，给自己留些时间，深挖背后的原理，将会给自己、同时也是给组织带来持续性的效率提升。&lt;/p&gt;

&lt;p&gt;例如：搞完这一套后，虽说重写祖传代码不太现实，但对于新的需求，可能会思考 &lt;code&gt;with&lt;/code&gt; 语法带来的好处，将其运用到业务中去，减少中间表冗余，简化逻辑，增强 sql 代码可读性。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B test 揭秘之什么是 A/B test</title>
      <link>https://kuhungio.me/2019/abtest/</link>
      <pubDate>Fri, 24 May 2019 09:02:00 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest/</guid>
      <description>

&lt;p&gt;此文总结自 Udacity 的课程：A/B test，详细而系统地讲述了 Google，Amazon 以及 Netflix 等公司是如何在商业问题中设计 A/B test 并评估效果的，对于国内的业务也有很强的参考意义。这里是总结的的一部分：什么是 A/B test，讲述 A/B Test 的定义、适用范围以及和传统方法的异同。指标选择、实验设计与评估将在后面陆续放出。&lt;/p&gt;

&lt;h2 id=&#34;a-b-概览&#34;&gt;A/B 概览&lt;/h2&gt;

&lt;h3 id=&#34;q-什么是-a-b-test&#34;&gt;Q：什么是 A/B test？&lt;/h3&gt;

&lt;p&gt;A：A/B test 是一种用来测试新产品或新功能的在线测试常规方法。一般分为两组用户，一组对照组，一组实验组。对照组采用已有的产品或功能，实验组采用新功能。要做的是找到他们的不同反应，并以此确定哪个版本更好。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-是否有适用范围-还是说所有情况都适用&#34;&gt;Q：A/B test 是否有适用范围，还是说所有情况都适用？&lt;/h3&gt;

&lt;p&gt;A：A/B test 能帮助你爬上前面的山峰，但如果想弄清楚是爬这座还是另一座，A/B test 可能不太有效。A/B test 能对很大范围的事情进行测试。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如：

&lt;ul&gt;
&lt;li&gt;亚马逊个性化推荐的 A/B test，发现个推能显著提升收益。&lt;/li&gt;
&lt;li&gt;领英对首页流排序的测试，谷歌的搜索广告排名。&lt;/li&gt;
&lt;li&gt;此外还可以对用户难以察觉的东西进行测试，如网站响应速度。亚马逊在07年发现：页面每增加100ms延迟，收入将会下降1个百分点。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;q-a-b-test-不能做什么事情&#34;&gt;Q：A/B test 不能做什么事情？&lt;/h3&gt;

&lt;p&gt;A：上线新的版本，带来完全不同的交互体验；或是低频长周期的产品；以及 A/B test 并不能发现被遗漏了什么。&lt;/p&gt;

&lt;p&gt;测试新的交互体验时，A/B test 可能不太奏效。原因有两个：一、厌恶改变，不是每个人都喜欢改变，这可能导致用户的厌恶和抵触情绪。二、新奇效应，对于新鲜事物，用户可能会挨个尝试所有东西。&lt;/p&gt;

&lt;p&gt;于此同时，这里会有两个问题，一个是你的比较基准是什么？另一个是需要花多少时间得出结论？举个例子：像低频的房屋租赁，在测试推荐流的时候，很难确定用户是为啥回来的。因为这要花的时间太长了，也许是半年，甚至是更久。&lt;/p&gt;

&lt;p&gt;A/B test 无法告诉你是否有遗漏。当我们在某个产品测试信息推荐流时，仅凭 A/B test，无法知道是否该给这个用户推荐地理信息的资讯。于此同时，也无法确定别的产品是否需要推荐流。&lt;/p&gt;

&lt;h3 id=&#34;q-对于-a-b-test-难以胜任的事情-该如何解决&#34;&gt;Q：对于 A/B test 难以胜任的事情，该如何解决？&lt;/h3&gt;

&lt;p&gt;A：通过其它数据源来补充，对日志进行分析假设验证。或是通过其它技术，如用户研究来定性分析。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-的历史是什么样的&#34;&gt;Q：A/B test 的历史是什么样的？&lt;/h3&gt;

&lt;p&gt;A：最先使用 A/B test 的，可能是农业领域。人们将土地分为不同部分，测试哪块地适合哪种作物作物或是作物如何生长。在科研领域。假设检验是确定创新的关键方法。医学上的 A/B test 被称为临床试验，通过此种方法来确定新的治疗方法是否有效。&lt;/p&gt;

&lt;h3 id=&#34;q-传统实验和在线的-a-b-test-有何异同呢&#34;&gt;Q：传统实验和在线的 A/B test 有何异同呢？&lt;/h3&gt;

&lt;p&gt;A：在线上，拥有更多的数据，但是分辨率低。像传统医学试验或用户体验研究，对象可能有10个、50个或100个，对每个参与者的基本信息都很了解。但在线上，我们的用户可能是数百万、上千万的点击交互行为，我们无法确定数据的另一端是谁。是一个人还是几个人，是网吧学校还是别的什么。通过 A/B test，目的是确认用户是否喜欢这个新产品或新功能。所以做 A/B test 的人的目标是设计一个合理且可复现的结果，用来帮助决策。A/B test 无处不在，FLAG 都在不同程度地使用 A/B test，甚至有专门地公司帮助小公司提供这些服务。&lt;/p&gt;

&lt;p&gt;##总结&lt;/p&gt;

&lt;p&gt;通过以上内容，我们知道了 A/B test的定义，明白他是为了更好决策的系统性方法。该方法在很多场景都适用，但在对于一些大的改动和低频次长周期的产品功能，A/B test并不能很好解决。通过数据互补，用户调研等方法，我们一定程度上弥补了 A/B test的短板。相较于传统的控制变量方法，线上的 A/B test数据量更大，但也难以确定真实的数据产生者。这些问题，在使用 A/B test时都要考虑。&lt;/p&gt;

&lt;p&gt;A/B test到底如何做，指标如何设定，如何说明新产品或新功能确实有效或无效？带着这些疑问，我们将进入到下期的内容。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>数据从业者必读的7本书 Booklist for DE</title>
      <link>https://kuhungio.me/2019/book-list-for-ds/</link>
      <pubDate>Tue, 07 May 2019 23:34:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/book-list-for-ds/</guid>
      <description>

&lt;p&gt;之前逛论坛，或者学习网站，看到很多人喜欢推荐书。自己早些时候也是这样，但是只 mark，却很少去看。如今作为一名社会人，虽说工作之余时间少了很多，但业余仍在坚持阅读。其中，支撑学习动力的一本书便是：《穷查理宝典》。书中查理·芒格提到的多学科思维，以及复利思维，一直在影响我的交友、做事和看问题的方式。&lt;/p&gt;

&lt;p&gt;有关注某校友的公众号，他是做爬虫和可视乎的。某天在推荐 Python 学习资料。封面看着挺美，点开一看，书单质量实属一般。倒像是接的推广，很多估计他自己都没有看过，不太负责任。于是乎，便萌生了出一期书单的想法。而定位，便是数据科学家、数据挖掘工程师、算法工程师的书单。&lt;/p&gt;

&lt;p&gt;首先声明，这份书单不是单纯的技术向书籍，不会有什么西瓜书或是算法导论之类的。他们也是好书，但不会出现在这里。因为在工作中大家就会发现，技术只是工具，好的工匠 != 熟练使用工具的熟练工。看见大局，同时有跨学科的思维，能够从事物的本质去出发，理解和思考它，也很重要。&lt;/p&gt;

&lt;p&gt;作为一个数据挖掘工程师，以下是推荐的核心7本书单。为什么是7本呢？因为人一下子能记住的东西是有限的，记不住就忍不住收藏。收藏了就几乎等于很少看了。收藏一时爽，一直收藏一直爽。所以，书单从原来的二十几本变为了现在的7本。&lt;/p&gt;

&lt;p&gt;这7本书的逻辑是从底层到高层。底层是构成我们一部分的东西，是我们的认知。中间则是我们的技能。而高层，则是我们的自我实现。最终又回到我们的认知。简单来说，就是从软技能到硬实力，再到软实力。&lt;/p&gt;

&lt;h2 id=&#34;通识与概念&#34;&gt;通识与概念&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Top 7&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通识趣味读本&amp;ndash;《赤裸裸的统计学》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该书讲了很多身边的例子，让人对统计学的应用有一个初步认识。且是一个检验兴趣点的很好方式。如果你对这些东西都不是很感冒，那么可能这行除了薪水，没有别的能吸引你。后面的内容也就没有读的必要了。&lt;/p&gt;

&lt;p&gt;除了例子以外，本书也有很多反常识反直觉的东西。诸如统计数字会撒谎、因果关系与相关关系的混淆。黑天鹅、三门问题等地很考验一个人的智商。看完之后有醍醐灌顶的感觉。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《大教堂与旧集市》、《编码》等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Top 6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大而全&amp;ndash;《信息论、推理与学习算法》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果你对第一本书的内容感兴趣，想要深入了解背后的原理，那么这本书不容错过。这本书更像是一本大百科全书，涵盖了传统信息论到最新算法的大部分内容。从熵、到编码、再到概率与推理，最后到常见的模型和神经网络。是一本适合高年级学生或者专人人员的查阅宝典。&lt;/p&gt;

&lt;p&gt;这本书说实话有些厚重，限于版面，如果只推荐一本，会推荐它。当然如果想看更多元的内容，附加的书籍📚可不容错过。由于本身的专业偏传统工科，编码、信息压缩也有接触，因而过渡起来不会很困难。&lt;/p&gt;

&lt;p&gt;与之互补的书还有《推荐系统实战》、《信息检索导论》、《集异壁》等。&lt;/p&gt;

&lt;h2 id=&#34;工具与思想&#34;&gt;工具与思想&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;吃饭工具&amp;ndash;《SQL 必知必会》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作为一个工程师，常自嘲自己是 sql boy。那是因为，在实际生产环境中，数据处理花了很大事件。大部分时间都是和sql 打交道。做过比赛的同学可能知道，数据处理、特征提取是很关键的一步。&lt;/p&gt;

&lt;p&gt;在企业中，这一情况越发突出。有时候原始数据分散在各个地方，连规整的数据都没有。因而需要掌握一定的 sql 技能。虽然有些专业会学习数据库这一门课程，但这本书可以起到一个梳理作用，同时也有一些小的注意点。&lt;/p&gt;

&lt;p&gt;掌握了这本书的同学，推荐《 SQL 反模式》，讲 sql 范式更进一步。虽说是给数据库开发人员看的，但是知其然并知其所以然，也是很好的。&lt;/p&gt;

&lt;p&gt;如果想看到更大的图景，那么 ddia 一定不容错过。ddia 在一年前就很火，网上也有他的公开中文翻译。讲解整个数据系统很透彻。适合各类程序开发人员阅读。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 4&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《利用 python 进行数据分析》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书也算是启蒙书。涉及的内容基本面很广，该有的都有了。介绍了 python 在数据科学领域的基础知识，同时也有案例解析。&lt;/p&gt;

&lt;p&gt;读完这本书，参加小型的数据挖掘、机器学习类的比赛不会存在门槛了。与此类似的书还有《集体智慧编程》，以及近期比较火的 hands on ml。&lt;/p&gt;

&lt;h2 id=&#34;思考与呈现&#34;&gt;思考与呈现&lt;/h2&gt;

&lt;p&gt;前面都是技术向、原理向的内容。是不是掌握了以上内容，就可以美滋滋的享受生活了呢？其实这是很多软件从业人员、甚至是工科同学的一个共同误区。觉得把我的技术学好了，就万事大吉，酒香不怕巷子深了。在这里千万不要忽略掉你的软实力。&lt;/p&gt;

&lt;p&gt;在某些头部公司、ppt 文化盛行。虽然有些走极端，这其实也是一种现状。从原则上来讲，只讲 PPT 画大饼而不做事是不对的，所以他们被放在最后讲。与此同时要记住，硬币的反面也是不对的，只埋头苦干，而不去扩大影响力，事情的价值就很可能被低估。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《金字塔原理》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要是逻辑性思维的呈现原则，以及最核心的一点站在对方的角度看问题。书中罗列了很多报告撰写、演讲呈现的方法技巧。比如自上而下思考，自下而上表达，横向概括、纵向分类，独立穷尽。这些机巧用在你的日常生活中的表达和演讲，将会大大加分。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《演说之禅》，以及稍微和职业更靠近的《数据可视化之美》。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《咨询的奥秘》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书是集中在讲思维方式的。咨询也算是数据科学家的一重身份。如何看待问题，如何给出建议，这本书都有很好的示范。&lt;/p&gt;

&lt;p&gt;与之类似的有《你的灯亮着吗》、《学会提问》。&lt;/p&gt;

&lt;h2 id=&#34;实践出真知&#34;&gt;实践出真知&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;实践&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;top 1 没有书，top 1 是实践。收藏了那么多资料，不如潜心研究一两个案例，去实践来的快。追踪学术前沿，去做一些实践；或者是对一些好玩的东西，做一些 demo，收获不会比上面的阅读小。&lt;/p&gt;

&lt;p&gt;如果想要更进一步，那就试着对外输出：无论是看到的知识，或者是方法论，抑或是工具使用技巧，还是对自己有帮助的 demo。这些都能很好的锻炼思维，让人更进一步。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;以上是给大家推荐的从业者的7本书，都是经过本人检验的。从通识到基础概念，从工具到学科思想，最后又回到普罗大众，思考和呈现我们的工作。希望能帮助诸位更进一步，在职业生涯上大放光彩。&lt;/p&gt;

&lt;p&gt;豆瓣书单 &lt;a href=&#34;https://www.douban.com/doulist/113972160/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.douban.com/doulist/113972160/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>