<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kuhung&#39;s Blog on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/</link>
    <description>Recent content in Kuhung&#39;s Blog on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 19 Oct 2019 11:33:09 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>数据分析师写接口竟成一种前沿模式--看 DataOps 如何提升公司数据科学力</title>
      <link>https://kuhungio.me/2019/dataops/</link>
      <pubDate>Sat, 19 Oct 2019 11:33:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/dataops/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;翻译自：《What is DataOps? Everything You Need to Know》 From Oracle Data Science Blog&lt;/p&gt;

&lt;p&gt;图片自：《DataOps is Not Just DevOps for Data》By DataKitchen in Medium&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;DataOps, 看到它的第一眼，大多数人会觉得陌生。但是提到另一个词——DevOps，做开发的同学可能会有些熟悉。DataOps 的理念与 DevOps 类似：&lt;strong&gt;将开发或者说是数据，与运维、测试相结合，自动化业务的交付以及架构的变更，使得构建、测试和发布能够更加快捷、频繁且可靠。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/dataops.PNG&#34; alt=&#34;DevOps&amp;amp;DataOps&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DataOps，全称 Data Operations，是一种敏捷运维方法，无感知地将IT基础设施和大数据分析技术结合起来。它的目的是通过结合数据管理的目标与过程，加快分析的速度与准确度。&lt;strong&gt;而这一过程，通常会涉及数据的多个流程：数据获取、数据质量检查、自动化、集成，以及最终的模型部署与管理。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/dataopspipeline.PNG&#34; alt=&#34;DataOps pipeline&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最核心的，DataOps 是为了方便管理数据、特别是当你有了一个特定的数据目标的时候。举个例子：为了&lt;strong&gt;降低客户的流失率&lt;/strong&gt;，可以通过利用客户数据构建一个&lt;strong&gt;推荐引擎&lt;/strong&gt;，推荐客户相关的东西，以此来减少浏览到下单的时间，减少客户流失。&lt;/p&gt;

&lt;p&gt;这是一个很自然的想法，但是却并不是一件容易的事情。上面的设想需要以下条件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;你的数据科学团队能够获取到他们需要的数据，同时能够有工具去部署模型。&lt;/li&gt;
&lt;li&gt;除此之外，还需要能够将模型集成到你的网站中去，在新数据上训练以持续的改进。&lt;/li&gt;
&lt;li&gt;最后，需要一套报表系统来监控其表现。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现在比较流行的做法，做好上面的事情，需要多个部门的合作，包括工程师、IT运维人员以及业务团队。&lt;/p&gt;

&lt;h2 id=&#34;谁能从-dataops-中获利&#34;&gt;谁能从 DataOps 中获利？&lt;/h2&gt;

&lt;p&gt;总的来说，&lt;strong&gt;几乎所有人都会从 DataOps 中获利&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更好的数据管理将会带来更多可利用的数据；&lt;/li&gt;
&lt;li&gt;越好的数据质量会有更准确的分析，与之相伴的就是更好的 insights、商业策略以及更高的利润。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DataOps 起一个润滑剂的作用，使数据团队、工程师团队和技术专家之间的工作更加紧密、更加自动化，以此来充分发掘数据价值、减少时间。&lt;/p&gt;

&lt;p&gt;Ashish Thusoo，Qubole 的联合创始人曾在书籍《Creating a Data-Driven Enterprise with DataOps》写道：我在2007年的夏天加入 FaceBook 的数据团队。像平常一样，公司里的任何人想获取无论多小的数据，都不得不找到数据团队，并发起流程。我们的数据团队很优秀，但是他们的精力也有上限。很明显，这是一个&lt;strong&gt;瓶颈&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/operations.PNG&#34; alt=&#34;业务团队与数据团队需要频繁对接&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;dataops-这一概念从何而来&#34;&gt;DataOps 这一概念从何而来？&lt;/h2&gt;

&lt;p&gt;DataOps 起源于 &lt;strong&gt;DevOps&lt;/strong&gt; 这一概念。据了解，财富1000强的公司里，80%的公司已经采用了 DevOps 这一方法。DevOps 的成功主要仰仗于：它把之前独立的两个部门联合在了一起——开发和运维。在 DevOps 的世界里，软件的发布是迅速且持续的，因为整个团队都被整合在了一起，用来检查并处理当下的问题。&lt;/p&gt;

&lt;p&gt;DataOps 继承了这一观念，并将之应用在数据生命周期里。DevOps 的持续集成、交付和运维的理念在数据的处理和产品化过程中也有所体现。具体来讲：&lt;strong&gt;数据科学团队利用软件版本控制工具 git、svn 来记录代码的变更，同时使用 Docker 和 Kubernetes 等容器技术来创建分析和部署模型。将数据科学与 DevOps 相结合的过程，也可被称之为“持续分析”。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;如何在组织中应用-dataops&#34;&gt;如何在组织中应用 DataOps？&lt;/h2&gt;

&lt;p&gt;正如你所看到的，DataOps 的应用，并非某种特定方法，而是一些&lt;strong&gt;关键领域的聚焦&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;以下是相关领域：&lt;/p&gt;

&lt;h3 id=&#34;data-democratization&#34;&gt;Data Democratization&lt;/h3&gt;

&lt;p&gt;根据 Experian Data Quality 调查显示：&lt;strong&gt;96%&lt;/strong&gt; 的首席数据官认为相关人员需要比以往更多的数据权限，&lt;strong&gt;53%&lt;/strong&gt;的人认为数据权限是最大的决策障碍。与之相反的是，我们当下有大量的数据在产生、存储。据测算。截至2020年，我们将会产生 &lt;strong&gt;40 zettabytes&lt;/strong&gt; 的数据，相当于地球上的人每人拥有 &lt;strong&gt;5200 GB&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;正如 thusso 在他 Facebook 工作期间看到的一样，缺少数据权限将是创新的极大障碍。自助的数据权限和相关的基础设施显得尤为重要。机器学习和深度学习应用需要持续不断的新数据以训练和改进；而想成为顶尖公司则需要其数据真正容易获取。&lt;/p&gt;

&lt;h3 id=&#34;leverage-platforms-and-open-source-tools&#34;&gt;Leverage Platforms and Open Source Tools&lt;/h3&gt;

&lt;p&gt;在一期 Forbes 中，Technology Strategy Crystal Valentine 的 VP MapR 描述道这一层次的 DataOps：“首先，在工具层面，DataOps 需要一个社区主导、支持主流语言和框架的&lt;strong&gt;数据科学平台&lt;/strong&gt;。”除此之外，数据迁移、编排、集成、性能监控的平台也同样重要。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/tools.PNG&#34; alt=&#34;数据科学平台&#34; /&gt;&lt;/p&gt;

&lt;p&gt;敏捷并不意味着需要浪费时间开发非必须的东西，或者是重复造一些已经开源的工具轮子。综合考虑你的数据需求且评估你的技术栈，选择合适的开源工具即可。&lt;/p&gt;

&lt;h3 id=&#34;automate-automate-automate&#34;&gt;Automate, Automate,Automate&lt;/h3&gt;

&lt;p&gt;这一理念直接取自 DevOps：为了更及时的评估数据集成的价值，自动化一些步骤是非常重要的。比如说&lt;strong&gt;质量保证测试&lt;/strong&gt;和&lt;strong&gt;数据分析的管道监控&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/monitoring.PNG&#34; alt=&#34;自动化监测&#34; /&gt;&lt;/p&gt;

&lt;p&gt;采用&lt;strong&gt;微服务自给自足&lt;/strong&gt;也是同样的道理。 举个例子：让你的数据分析师能够以 &lt;strong&gt;API&lt;/strong&gt; 的方式自行部署模型，这意味着开发团队能够在不重构的基础上集成该功能。这将带来生产力的提升。&lt;/p&gt;

&lt;h3 id=&#34;govern-with-care&#34;&gt;Govern With Care&lt;/h3&gt;

&lt;p&gt;越来越多的公司开始采用 Center of Excellence 的方法来实现数据科学管理，这并非是偶然。只有在建立一套数据的处理、工具平台、基础设施、权限划分以及性能监控后，才能真正获取数据科学、或者说是 DataOps 的投资回报。&lt;/p&gt;

&lt;p&gt;因此，在该领域&lt;strong&gt;62%&lt;/strong&gt;的优秀人士有一个清晰且正确的数据科学发展计划。与之相对应的是仅仅28%的普通人和29%的公司有这么一个想法。&lt;/p&gt;

&lt;h3 id=&#34;smash-silos&#34;&gt;Smash Silos&lt;/h3&gt;

&lt;p&gt;除上面列到的4项以外，&lt;strong&gt;跨部门合作&lt;/strong&gt;也是应用 DataOps 非常重要的一点。DataOps 化过程中引进的工具和平台应该服务于更大的目标：&lt;strong&gt;整合不同的团队以更高效的使用数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/dataops/collaboration.PNG&#34; alt=&#34;跨部门合作&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;“注意：数据并不属于 IT、数据科学家或者数据分析师。”Thusso 写道：“它属于业务中的所有人。所以，&lt;strong&gt;你的工具应该允许雇员创造他们自己的分析与可视化报告，并且能够在同事间分享他们的发现。&lt;/strong&gt;”&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于译者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《学习之道》笔记思维导图</title>
      <link>https://kuhungio.me/2019/the_way_to_learn/</link>
      <pubDate>Wed, 16 Oct 2019 07:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the_way_to_learn/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/waytolearn.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>机器学习实践--测试驱动开发</title>
      <link>https://kuhungio.me/2019/tdd_drive_ml/</link>
      <pubDate>Sun, 25 Aug 2019 00:22:07 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_drive_ml/</guid>
      <description>

&lt;h2 id=&#34;机器学习现状与问题&#34;&gt;机器学习现状与问题&lt;/h2&gt;

&lt;p&gt;2012年，数据科学击败生命科学，成为”21世界最性感的职业“。2016年，AlphaGo 战胜人类顶尖围棋手，深度学习、人工智能一度占领新闻头版头条，并引起一股机器学习新热潮。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/baidu_index.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这一效应，一直持续到今年：在2019这一年，高考志愿填报金融遇冷，计算机一跃成为抢手专业，在各大工科院校中，有取代传统电气、机械之势；各学院的研究生院，纷纷开始往人工智能、深度学习上贴近。&lt;/p&gt;

&lt;p&gt;这从一个侧面，反应了民众对于计算机、人工智能、机器学习的就业预期。但是，随着原来越多的从业者涌入，项目落地越来越多，机器学习这一领域的问题也开始暴露，亟需解决。&lt;/p&gt;

&lt;h3 id=&#34;机器学习中的常见问题&#34;&gt;机器学习中的常见问题&lt;/h3&gt;

&lt;p&gt;机器学习的问题，由其特性所致。众所周知，机器学习的发展，离不开大数据技术。海量数据的收集、存储，让算法有了更强大的生命力。通过对大量数据的挖掘、学习，机器学习能够猜你所想，提升购物网站的转化率；能够识别障碍，让自动驾驶成为可能；能够识别风险，扩大业务同时减轻坏账。&lt;/p&gt;

&lt;p&gt;由此，针对模型和数据的关系，大致可以分为三类问题。第一种：数据量不足，模型过拟合。算法学习的过程就犹如考前刷题，过拟合相当于只刷一套题，这样的后果就是上一套不同的卷子，算法就懵逼了。第二种：数据量充足，模型欠拟合。欠拟合的算法就像是心思不在学习上的孩子，报再多的补习班，结果也不会太好。最后一种：数据不稳定。算法前期可能很好的学到精髓，但是随着数据的变化，时间的流逝，模型很可能将变得不可预测。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/problem-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;测试驱动开发的解决之道&#34;&gt;测试驱动开发的解决之道&lt;/h2&gt;

&lt;p&gt;机器学习的实现方式还是通过软件工程、代码实现，既然是代码，那就存在应对范式。这里，就不得不提 Test Driven Development（测试驱动开发），简称 TDD。TDD 是一种很朴实的想法，在编码开始前，评估需要交付的功能点并写测试用例，一开始的时候测试会失败，接着编写代码修复测试，最后测试通过，修复代码。这里的方式，通俗来讲就是：&lt;strong&gt;目标导向，先成事，再迭代。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/tdd.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;测试驱动有一个明显的好处就是，能够加快产品发布速度。以往的项目，需求讨论会占据很大时间，讨论完之后，开发方案一旦定下来，后续变更就很难。而现实却是需求常常变更，这往往会导致产品发布的延期。而在机器学习上，测试驱动好处更多体现在保证模型质量上。具体来讲，常通过以下办法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;交叉验证    通过交叉验证来验证拟合效果&lt;/li&gt;
&lt;li&gt;运行速度测试    根据奥卡姆剃刀原则：”如无必要，勿增实体“；简单模型胜过复杂模型&lt;/li&gt;
&lt;li&gt;衔接测试    对数据的输入输入进行检测，以防止数据异常波动对模型影响&lt;/li&gt;
&lt;li&gt;指标追踪    监控关键指标，不断追踪模型的性能，防止失效模型继续运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/tddsolution.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;机器学习的债务危机&#34;&gt;机器学习的债务危机&lt;/h2&gt;

&lt;p&gt;测试驱动开发一定程度上能减轻机器学习中的问题，但是它只是一种表象。测试通过了，不代表算法模型就没有问题了。魔鬼藏在细节中。机器学习目前仍存在一些技术债务，仍需按特定原则对代码修复，迭代演进。&lt;/p&gt;

&lt;h3 id=&#34;什么是技术债务&#34;&gt;什么是技术债务&lt;/h3&gt;

&lt;p&gt;技术债务是一个比方，类比的金融领域的债务。一般指为了加快软件开发速度，折中妥协，选择易于实现的方式，结果是短期加速了软件开发，但长期来讲，开发负担累计，发布逐渐停滞。债务不都是有害的。在业务扩张，市场抢占时期，适当的债务有助于公司扩张。但是若一直不管不顾，最后只能花更大的成本去维护它，直至无法维护。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/debt.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;机器学习中的技术债务&#34;&gt;机器学习中的技术债务&lt;/h3&gt;

&lt;p&gt;机器学习项目中同样存在债务危机，Google 还就此写了篇文章 《Machine Learning: The High interest Credit Card of Technical Debt》。总结起来有三种：一、边界模糊，数据之间彼此依赖关联。二、没有系统级别代码分离，胶水代码处理一切。三、机器学习系统随着外部世界的改变而彻底改变。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/debt-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;偿还债务&#34;&gt;偿还债务&lt;/h2&gt;

&lt;p&gt;代码重构，就犹如对你的资产进行一次清点盘算：清除不良资产、偿还债务、进行资产上的重新配置。重构能够有效减缓技术债务带来的负面影响。&lt;/p&gt;

&lt;h3 id=&#34;面向对象的-solid-原则&#34;&gt;面向对象的 SOLID 原则&lt;/h3&gt;

&lt;p&gt;SOLID 原则由罗伯特·C·马丁提出，是五项原则&amp;ndash;单一职责、开闭原则、替换原则、接口隔离、依赖倒置的缩写，是面向对象设计与开发的五个基本原则。通过这五项原则，写出来的程序可读性、可扩展性都大大提高，软件维护和系统扩展变得更加容易。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SRP 单一职责原则：一片代码只做一件事，及一块代码只实现某一特定功能，尽量减少逻辑的交叉堆叠。&lt;/li&gt;
&lt;li&gt;OCP 开闭原则：对象对于扩展开放，对于修改关闭。即保持最小单元，写完后不去修改它，而是通过扩展或者配置的方式补充功能。&lt;/li&gt;
&lt;li&gt;LSP 替换原则：任何的子类应该轻松由同一对象树的其它对象替代。&lt;/li&gt;
&lt;li&gt;ISP 接口隔离原则：不同的接口做不同的事，软件开发没有银弹，接口也是。解耦能解决掉开发过程中“牵一发而动全身”的情况。&lt;/li&gt;
&lt;li&gt;DIP 依赖倒置原则：抽象来自于细节、来自于底层，开发依赖抽象。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/solid.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;机器学习与-solid-原则&#34;&gt;机器学习与 SOLID 原则&lt;/h3&gt;

&lt;p&gt;将 SOLID 原则应用于机器学习，会发现：机器学习与 SOLID 原则相互交织。诸如机器学习中的降维，是在减少耦合；胶水代码、数据依赖又与 SOLID 原则相抵触。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单一职责

&lt;ul&gt;
&lt;li&gt;机器学习中的数据相互依赖，更有利用 GBDT 生成特征，这一情况与单一职责冲突。所幸可通过降维、正则化的手段减轻影响。&lt;/li&gt;
&lt;li&gt;数据获取、数据处理、特征工程、模型训练、模型预测、数据监控，各模块无系统级代码分离，胶水代码处理一切。开发时应小心谨慎。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;开闭原则

&lt;ul&gt;
&lt;li&gt;代码上可以做到开闭，但机器学习会作用于真实世界，引起的反馈将传导至模型内部。如模型预测出一批”潜在犯罪“，于是加大警力盯住这些人，最后发现他们的犯罪率果然高于常人。但他们就真的比别人更”坏“吗？这里有一个”预测、实施、证实“的偏差存在，算法无形中放大了偏见。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;替换原则

&lt;ul&gt;
&lt;li&gt;机器学习的模型效果常由强特征决定，且特征众多。应用尽可能少的特征和数据，取得稳定结果。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;接口隔离

&lt;ul&gt;
&lt;li&gt;模型的数据上游，可能会多个部门共用，数据源的人为变化，可能会导致模型的突然失效。因而需要对数据输入进行监控。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;依赖倒置

&lt;ul&gt;
&lt;li&gt;测试代码、中间数据大量堆积，各个部分相互依赖。应定时对遗留代码和中间数据进行清理。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/solid-in-ml.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;机器学习、人工智能在经历这几年的爆发之后，出现了很多病症。测试驱动开发、SOLID 原则重构能够有效的缓解病症，还系统健康。如果你的项目已经落地，用 SOLID原则进行一次检查；如果项目还未实施，不妨尝试下测试驱动开发。系统更好的可读性、可维护性，不仅是程序员的责任，更是评判机器学习从业者的一把尺子。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/tdd_ml/Mind-map.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;不知道读者朋友对此怎么看，欢迎就此在评论区发表你的看法。喜欢本文的读者，别忘了点赞、喜欢、加关注哦，你的鼓励，将是我写作分享的动力💪&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/SOLID_(面向对象设计)&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;wikipedia SOLID 原则 &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《Python 机器学习实战&amp;ndash; 测试驱动的开发方法》&lt;/li&gt;
&lt;li&gt;《高效程序员的45个习惯&amp;ndash;敏捷开发修炼之道》&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;关于作者-about&#34;&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;谷粒，华中科技大学毕业，某游戏公司从事数据挖掘工作，常与机器学习、数据系统打交道。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>测试驱动的机器学习思维导图</title>
      <link>https://kuhungio.me/2019/tdd_with_ml/</link>
      <pubDate>Thu, 22 Aug 2019 00:56:13 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/tdd_with_ml/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/TDD.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>金字塔原理思维导图</title>
      <link>https://kuhungio.me/2019/pyramid/</link>
      <pubDate>Thu, 15 Aug 2019 00:47:36 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/pyramid/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/pyramid.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>敏捷革命思维导图</title>
      <link>https://kuhungio.me/2019/scrum/</link>
      <pubDate>Sat, 10 Aug 2019 00:54:34 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/scrum/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/mindmap/scrum.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://kuhungio.me/about/&#34;&gt;关于作者&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>系统思考与卓有成效的管理者</title>
      <link>https://kuhungio.me/2019/manadement/</link>
      <pubDate>Wed, 17 Jul 2019 17:02:56 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/manadement/</guid>
      <description>

&lt;p&gt;在老一辈的眼中，学而优则仕。学习好了就去当官从政，去服务别人。而在父母这一辈人的眼中，不论你干啥，当“老实人”被人管是不行的，他们的观点有一定的时代背景，但仍然在潜移默化影响着每个人。&lt;/p&gt;

&lt;p&gt;而对于初入职场的新人来说，虽然暂时当不上管理者，但被管理时却也会思考：“如果是自己，将会怎样去做管理？” 对于这一批新的90后甚至00后来说，管理并不再是一场服从性测试，权威性的组织管理方法或不再有效。&lt;/p&gt;

&lt;h2 id=&#34;什么是这些年轻人喜欢的管理风格呢&#34;&gt;什么是这些年轻人喜欢的管理风格呢？&lt;/h2&gt;

&lt;p&gt;如果稍微读过一些管理学的书籍，就会发现，管理其实在近现代发生了较大的变化。厚黑学受人推崇，有它的一定意义，但是小年轻们对里面的技巧似乎并不买账。这点在酒桌或者聚餐时就可以看得出来。这批年轻人有自己的想法，有独立的意识，甚至有些“不懂”人情世故。&lt;/p&gt;

&lt;p&gt;回顾历史，近现代企业管理做得比较好的，要当属日本。日本凭借其精益管理思路，在汽车制造业一举占领美国市场，打得美国的传统汽车巨头没有还手之力。在大学里，作为机械大类的学生，一定多少接触过精益生产。&lt;/p&gt;

&lt;p&gt;这套理念，帮助日本一跃成为制造业强国。而反观国内，作为一个机械大类出身的同学，你一定知道国内的“中国制造”现状是什么。而作为一个跨行的 IT 向工程师，在实践中，也发现，以信息互联标榜自己的互联网，除了开源的代码复制粘贴得挺快，管理模式其实并没有跟上节奏。&lt;/p&gt;

&lt;p&gt;今天，在当下环境中，还有很多管理者是靠着本能在管理，而不是一套系统科学的方法。一个程序员，或者是 IT 企业的中层管理，有时间去研究业务，却少有时间去研究管理。项目短平快上线、管理粗糙莽随意。像极了早期国内自然资源开采，先污染后治理的样子。&lt;/p&gt;

&lt;h2 id=&#34;it-工程师眼中的现代管理究竟应该是什么样的呢&#34;&gt;IT 工程师眼中的现代管理究竟应该是什么样的呢？&lt;/h2&gt;

&lt;p&gt;我们接着从上面的日本制造业说起。在当时，他们推崇一种见 kanban 的工作法。即在看板上列出工作事项，工作流公开透明。而在当下，国内头条、国外谷歌都在推崇 OKR。这里两者的本质是相通的，即：公开透明公司的业务流，每个人都能参与到目标设定里面来。&lt;/p&gt;

&lt;h3 id=&#34;低效的管理者&#34;&gt;低效的管理者&lt;/h3&gt;

&lt;p&gt;在执行这套的同学可能会说，这其实只是形式主义，到头来还是 KPI 导向，面向 PPT 晋升。这在企业中确实存在，而其中的缘由，有以下5点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;管理者不能良好的安排自己的时间，自己的时间属于别人&amp;ndash;无尽的会议、向上汇报、向下沟通&lt;/li&gt;
&lt;li&gt;眼光受限于岗位，注意力集中在流程、规范与控制上，而不是贡献&lt;/li&gt;
&lt;li&gt;没能充分发挥人的长处，无论是自己、上司抑或是下属。总认为下属不能很好地完成工作。从职位出发去设定一个人能做什么、不能做什么。不能容忍人之短。&lt;/li&gt;
&lt;li&gt;零碎容易完成的优先做，根据和需求方的亲疏远近安排优先级，而不是要事优先&lt;/li&gt;
&lt;li&gt;无法有效决策，没有流程，不愿放权。决策没有边界，不设立反馈机制，任由自己的“偏见”主导决策&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;做好了上面的5点，企业就能蒸蒸日上了吗？其实也不是，如果没有一个学习型的组织，单靠个人也是难以推动的。千里马常有，而伯乐不常有。运气好，遇到一个放权给你的领导，做起来是运气，做不起来是常态。企业中的死海效应，“劣币驱逐良币”也同样常见。&lt;/p&gt;

&lt;h3 id=&#34;螺旋沉默的组织团队&#34;&gt;螺旋沉默的组织团队&lt;/h3&gt;

&lt;p&gt;也就是说，还需要一个良好的组织氛围。而变成一个死海的组织氛围常有以下特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安于现状，封闭思想。更愿以主观的视角观察现实，而不是客观。&lt;/li&gt;
&lt;li&gt;心智模式不成熟。对已有的成功盲目崇拜模仿，而忽视掉其潜在的天时地利人和背景。&lt;/li&gt;
&lt;li&gt;各自有各自的小算盘，没有共同的愿景。&lt;/li&gt;
&lt;li&gt;团队内部给自为战，几乎不存在团队学习。&lt;/li&gt;
&lt;li&gt;局部思考而不是系统思考。认为危机的主因是人或事，而不是系统机制的问题。从未留意过系统如何塑造自己的行为。不清楚系统的边界、增长极限、反馈回路以及压力是如何转移的 。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果是想做一个失败的管理者，营造一种糟糕的团队氛围，按照上面做准没错。&lt;/p&gt;

&lt;h3 id=&#34;短期利益驱动的变革&#34;&gt;短期利益驱动的变革&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;学校教育告诉我们：永远不能承认我们不知道的答案。而大多数公司还在强化这种训练，奖励善于推销自己观点的人，却忽视对复杂问题的探寻。（还记得上一次你的组织给对公司现行政策提出难题的人——而不是解决某个紧迫问题的人——颁发奖励是什么时候吗？）&amp;ndash; 《第五项修炼》&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;别急，是不是准备收藏，并在组织中逆向推行以上措施呢？那你可能又陷入了组织变革中的另一个陷阱：在变革过程中，我们不仅难以看到整片森林；甚至，我们还会挑出一两棵我们认为最看好的树，然后就全神贯注在它们身上，为它们而倾注全部的变革努力。&lt;/p&gt;

&lt;p&gt;为什么目前还有很多的 IT 企业管理者，在靠着本能管理呢？一个字：利。 无利不起早。 概念发明以后，还要在有实用价值的成本范围内，以一定的规模进行可靠的复制，它才能够真正落地。&lt;/p&gt;

&lt;p&gt;为什么大家都觉得修正以上的问题是不符合利益的呢？因为很多时候，都是想短期梭哈一波，先用着后面再说，先这样管理出问题了再说。即忽视了系统性的东西，而仅专注于眼前的事物。&lt;/p&gt;

&lt;h2 id=&#34;系统思考&#34;&gt;系统思考&lt;/h2&gt;

&lt;p&gt;如果想在组织中构建学习型组织，成为一个卓有成效的管理者，那肯定不是忽视系统思考的力量。&lt;/p&gt;

&lt;p&gt;关注长期的行为和系统内部的结构，而不是表象和短期事件；世界非线性，不要用线性的思维思考；恰当的划分系统的边界；充分考虑多方的限制因素及相对强弱。&lt;/p&gt;

&lt;p&gt;通过实际行为来推断系统目标，而不能只看表面的言辞或其标榜的目标。时间延迟无所不在，当下的干预很可能一段时间后才会产生影响。没有人能做到充分理性，每个人的理性都是有限的。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在最近和实习生同事的合作过程中，深切的感受到信息差带来的权力膨胀感。实际上，管理也是一门实践课程。一开始可能会走偏，但只要有回顾、有反思，也终究会上正轨。系统思考、长远为重。不仅要问这些年轻人想要什么、也要问自己想要什么。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B test 评价指标的选择</title>
      <link>https://kuhungio.me/2019/abtest-2/</link>
      <pubDate>Sat, 22 Jun 2019 15:28:01 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest-2/</guid>
      <description>

&lt;h2 id=&#34;如何定义一个评价指标&#34;&gt;如何定义一个评价指标&lt;/h2&gt;

&lt;p&gt;这是上一篇文章&lt;a href=&#34;https://kuhungio.me/2019/abtest/?utm_source=self&amp;amp;utm_campaign=abtest2&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;什么是 A/B test&lt;/a&gt;的续集，上一篇主要讲述 A/B 测试的历史，这里接着讲如何选择指标。&lt;/p&gt;

&lt;p&gt;从本人的经验来看，一个指标怎么选择确实重要，但更重要的是需要自上而下理解且落实科学实验。而不是拍脑袋想指标，中途随意更换指标，汇报时仅罗列有利的指标。&lt;/p&gt;

&lt;p&gt;如果要用一句话解释，如何定义一个评价指标，那一定是“以始为终”。在定义一个指标的时候，要想一想为什么要定义这个指标，这个指标的定义是为了说明什么情况，如果这个指标发生变化，将需要怎么去解释它。&lt;/p&gt;

&lt;h3 id=&#34;指标定义的两种情况&#34;&gt;指标定义的两种情况&lt;/h3&gt;

&lt;p&gt;在这里，定义指标的时候有两类：一是不变量，即变量组和对照组的都应该相同；另一个是变量，即需要观察改变的量。&lt;/p&gt;

&lt;p&gt;对于不变量，需要注意两者的总量是否相同，数据的分布是否相同。以上保证实验的正常进行。对于变量，首先思考高层次的商业指标。诸如收益、市场份额、用户量等。接下来就是细节的指标，如用户体验，网页停留时长。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;例如，在游戏中，新手教程没完成的玩家，虽然不能直接知道原因，但根据经验，可能是引导时间太长、网络卡顿或者是别的原因。类似这样的情况，是用户体验上的问题。后面也会有一些方法提到如何去评估它。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在实验中，可能得到的不是想要的信息、或者实验时间太短，得到的结果不准确。甚至有些东西无法衡量，这种情况又该如何去评估它呢。别急，下面的内容会给你回答。&lt;/p&gt;

&lt;h2 id=&#34;自顶向下设计评价指标&#34;&gt;自顶向下设计评价指标&lt;/h2&gt;

&lt;p&gt;如何确定指标来做健全性检验&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;高层次的指标（如：活跃用户数、点击转化率 CTR）&lt;/li&gt;
&lt;li&gt;指标细节（如：如何定义用户活跃）&lt;/li&gt;
&lt;li&gt;使用一组指标，并将他们整合为一个单一指标（如：总体评价指标（OEC））&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于评估，可以选择一个指标或一套指标。如果是使用一套指标，可以把他们聚合成一个指标，比如构造一个目标函数，或者是简单的加权指标。&lt;/p&gt;

&lt;p&gt;最后一点需要考虑的是：指标的普适性有多少。如果你在运用 A/B 测试，最好能有一个指标能够贯穿整个体系。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;举个例子：用户漏斗。&lt;/p&gt;

&lt;p&gt;它表示用户通过站点执行的一系列步骤。 之所以被称为漏斗，是因为每个后续阶段的用户数都少于上面的阶段。 每个阶段都是一个指标——总数，比率和概率。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;数据不足怎么办&#34;&gt;数据不足怎么办&lt;/h2&gt;

&lt;p&gt;有些数据可能难以获得，主要原因如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有数据的权限&lt;/li&gt;
&lt;li&gt;需要较长时间去收集数据&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;使用外部数据&#34;&gt;使用外部数据&lt;/h3&gt;

&lt;p&gt;其它数据收集的技巧：3种公司常用的方法&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;数据中间商&lt;/li&gt;
&lt;li&gt;调研公司&lt;/li&gt;
&lt;li&gt;学术文章&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上能够帮助你依照整个行业设定指标。&lt;/p&gt;

&lt;h3 id=&#34;额外的内部数据&#34;&gt;额外的内部数据&lt;/h3&gt;

&lt;p&gt;额外的内部数据也可被使用，例如：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;回溯性分析：查看历史数据以找寻改变并进行评估&lt;/li&gt;
&lt;li&gt;调研与用户研究：这个帮助你找到你想研究的点&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上办法的缺点是它只告诉了你相关性、没有告诉你因果性，而实验一定程度上可以解释因果。&lt;/p&gt;

&lt;p&gt;最后，别忘了与你的同事交换意见，看看他们认为重要的指标有哪些。&lt;/p&gt;

&lt;p&gt;附：&lt;a href=&#34;https://s3-us-west-2.amazonaws.com/gae-supplemental-media/additional-techniquespdf/additional_techniques.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;其它获得额外数据的方法&lt;/a&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;用户体验研究（UER）——高深度少用户。这也适用于头脑风暴，在 UER 中也可以使用诸如眼动相机的设备，同时回溯历史进行分析。&lt;/li&gt;
&lt;li&gt;焦点小组——中等深度中等规模用户。能够在一些假设上获得反馈，但也容易陷入集体思想的情况（即真正的个人意见难以获得表达）&lt;/li&gt;
&lt;li&gt;调研报告——深度较低但用户规模大。对于一些难以直接衡量的指标很有用。不能用于直接和其它指标比较，因为调研的对象和指标很可能与大盘不同。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;指标的实际例子&#34;&gt;指标的实际例子&lt;/h2&gt;

&lt;p&gt;高层次指标：点击率&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定义一：Cookie 的总点击次数除以 Cookie 去重后的总数&lt;/li&gt;
&lt;li&gt;定义二：被点击的页面数除以总页面数&lt;/li&gt;
&lt;li&gt;定义三：总的页面点击次数除以总页面数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可能还需要过滤爬虫、牟利等行为以消除数据偏差。通过切片来判断数据是需要偏置还是过分偏置。在过滤掉数据后，计算每个切片的评价指标表现。如果数据表现有偏差，那说明数据里可能还需要调整。&lt;/p&gt;

&lt;p&gt;为了消除数据周期带来的周末效应，最好按周或者按年进行数据的划分。&lt;/p&gt;

&lt;h2 id=&#34;指标的特性&#34;&gt;指标的特性&lt;/h2&gt;

&lt;h3 id=&#34;指标的敏感性和鲁棒性&#34;&gt;指标的敏感性和鲁棒性&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;敏感性和鲁棒性：敏感性是指指标对所关系的事物是否足够敏感，而鲁棒性性是指对不关心的事物是否足够不敏感。这可以通过预先小规模实验，来验证指标是否符合直觉。另一个方法是使用 A/A 测试，也就是什么都不改变，以此来排除一些伪关系。&lt;/li&gt;
&lt;li&gt;分布：通过对历史数据的分析得到。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;指标的分类&#34;&gt;指标的分类&lt;/h3&gt;

&lt;p&gt;4类指标&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;计数或者求和（如：访问页面的用户数）&lt;/li&gt;
&lt;li&gt;指标的分布-平均数、中位数和百分位&lt;/li&gt;
&lt;li&gt;概率与比率（rates）&lt;/li&gt;
&lt;li&gt;比例（ratios）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;绝对指标与相对指标的选取&#34;&gt;绝对指标与相对指标的选取&lt;/h3&gt;

&lt;p&gt;比较测试组和控制组的最简单方法是做差。&lt;/p&gt;

&lt;p&gt;如果在做大量的实验，比较好的方法是多做相对的比较。比如百分比的变化情况。&lt;/p&gt;

&lt;p&gt;计算百分比指标的优势在于，你有一个明确的边界，该边界不会随着时间变化。如果同时在运行多组指标，那么你的绝对数据很可能经常变动。这时，使用相对指标的好处就显现出来了，数据不会随着系统的变化发生大幅度的改变。&lt;/p&gt;

&lt;p&gt;相对指标的主要缺点是：其灵活性和比例的相对差异不如绝对指标明显。&lt;/p&gt;

&lt;h3 id=&#34;参数估计&#34;&gt;参数估计&lt;/h3&gt;

&lt;p&gt;在实验前，需要检查指标的分布情况，以决定实验的规模、评估的置信区间以及支撑最后的结论。&lt;/p&gt;

&lt;p&gt;如果要检查的指标分布区间很大，那么最后的结果意义可能不大。&lt;/p&gt;

&lt;p&gt;为了计算置信区间，需要&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;方差（或者标准差）&lt;/li&gt;
&lt;li&gt;分布&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于二项分布，估计的方差为 p(1−p)/N。估计的均值方差为σ^2/N。如果原始数据是正常的，则中位数将是正常的。但如果原始数据不正常，则中位数可能不正常。由于中心极限定理，平均值通常是正态分布的，而与原始数据的分布无关。&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;x &amp;lt;- c(87029, 113407, 84843, 104994, 99327, 92052, 60684)
stder &amp;lt;- sd(x)/sqrt(length(x))
conf95_min = mean(x) -1.96*stder
conf95_max = mean(x) + 1.96*stder
conf95_min
## [1] 79157.54
conf95_max
## [1] 104367
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;非参数方法&#34;&gt;非参数方法&lt;/h3&gt;

&lt;p&gt;这是一种在不对分布进行假设的情况下分析数据的方法。 在谷歌，很少使用上面参数估计的方式，他们使用基于 A/A 测试的结果来评估方差。 如果在 A/A 测试中发现指标存在很多变化，则该指标可能过于敏感，无法使用。&lt;/p&gt;

&lt;p&gt;比起进行多组 A/A 测试，一种方法是进行大量的 A/A 测试，然后进行自助（bootstrap）来生成多组样本并测试变化范围。&lt;/p&gt;

&lt;p&gt;通过 A/A 测试，可以&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将结果与期望进行比较（健全性检验）&lt;/li&gt;
&lt;li&gt;根据经验估计方差，并使用对分布的假设来计算置信度&lt;/li&gt;
&lt;li&gt;直接估计置信区间而不用做任何数据假设&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总之，不同的指标具有不同的变化范围。某些指标的变化范围可能很大，即使它们具有商业或产品意义，也会使它们无法使用。对待他们，需要非常小心。&lt;/p&gt;

&lt;p&gt;对于许多分析师而言，与实际运行实验相比，大部分时间用于验证和选择指标。能够标准化定义指标在测试中至关重要。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;例如：网站延迟测试&lt;/p&gt;

&lt;p&gt;定义：是在谈论加载第一个字节和加载最后一个字节的时间，还是说别的什么东西呢。&lt;/p&gt;

&lt;p&gt;数据分布：此外，对于延迟，平均值可能根本不会改变。信号（例如慢速/快速连接或浏览器）会导致分布中十分集中，并且没有对应的调整方法。&lt;/p&gt;

&lt;p&gt;对策：在这种情况下，就需要查看百分位分布。这里的关键是要建立起直觉，必须了解数据和业务，并与工程师一起理解数据是如何被记录的。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>HIVE 技巧积累之合并重叠日期</title>
      <link>https://kuhungio.me/2019/merge_overlapping_date/</link>
      <pubDate>Sun, 09 Jun 2019 00:17:05 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/merge_overlapping_date/</guid>
      <description>

&lt;p&gt;目前网上流传着一个段子，说算法工程师实际上就是 SQL boy，数据分析师是 PPT boy。艺术来源于现实，实际上的我们真的有很多时间在写 SQL 出数据，或者是针对 bad case 做数据的进一步分析。&lt;/p&gt;

&lt;p&gt;这不，近期这边接到的一个需求就是对玩家的某项行为进行统计。一般来讲，掌握基本 SQL 的技巧，这些需求的难度都不大。但是这个需求需要将玩家用户的多个重叠日期进行拉伸去重。这一下可难到大伙儿。在自个儿思考无果，团队讨论之后也没啥直接的办法。&lt;/p&gt;

&lt;p&gt;在网上搜索一番后，很多都不是很对应。不过好在几轮筛选，找到了一个类似的需求。原文链接在这里：&lt;a href=&#34;https://stewashton.wordpress.com/2015/06/08/merging-overlapping-date-ranges/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;🔗&lt;/a&gt;。为了方便后来的人，在这里做个分析记录，以及后面举一反三该怎么做。毕竟这些东西很少出现在教程和课本里，但是当业务方有这个需求的时候，常常又很紧急，容不得细思慢想。&lt;/p&gt;

&lt;h2 id=&#34;问题定义&#34;&gt;问题定义：&lt;/h2&gt;

&lt;p&gt;在解决一个问题之前，我们需要先明确定义问题。这里的问题是对多个重叠日期，用 SQL 将其进行去重，并在 HIVE 环境中使用。&lt;/p&gt;

&lt;h3 id=&#34;对于日期情况的定义&#34;&gt;对于日期情况的定义&lt;/h3&gt;

&lt;p&gt;这里采用穷举法，可以得出以下13类情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;问题简化&#34;&gt;问题简化&lt;/h3&gt;

&lt;p&gt;解决问题的核心是简化问题。这个问题看起来情况众多，实际上，对于我们的任务，只有两种情况：一个是两个日期有重叠；一个是两个日期没有重叠。&lt;/p&gt;

&lt;p&gt;对于不同的情况，要做不同的处理。重叠日期取最大最小日期即可，非重叠的分段取。剩下的即是通过工具去实现逻辑。&lt;/p&gt;

&lt;h2 id=&#34;数据准备&#34;&gt;数据准备&lt;/h2&gt;

&lt;p&gt;这里采用原作的方式定义数据，创建出上面的13中情况。实际上，如果你的格式和下面的类似，做出对应的调整即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop table t purge;
create table t (
  test_case varchar2(32) not null,
  start_date date not null,
  end_date date not null
);
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义出来的数据如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_sample.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;with grp_starts as (
  select test_case, start_date, end_date,
  case
    when start_date &amp;gt; max(end_date) over(
      partition by test_case order by start_date, end_date
      rows between unbounded preceding and 1 preceding
    )
    then 1 else 0
  end grp_start
  from t
)
, grps as (
  select test_case, start_date, end_date,
  sum(grp_start) over(
    partition by test_case order by start_date, end_date
    rows between unbounded preceding and current row
  ) grp
  from grp_starts
)
select test_case,
min(start_date) start_date,
max(end_date) end_date
from grps
group by test_case, grp
order by 1, 2;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge_result.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里的的核心思想同上：&lt;strong&gt;判断日期是否重叠，重叠日期取最大最小的日期，非重叠日期分段取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里使用了 &lt;code&gt;with&lt;/code&gt; 技巧，通过该技巧，将数据临时存储至内存，加速了执行速度。这句话是网上能直接搜到的，但实际上它还有另一个功能上的作用。即抛开性能作用来说，&lt;code&gt;with&lt;/code&gt; 语法能够对先前的查询结果进行下一步的处理。这意味着不用频繁的建立中间表，省去空间或是简化了逻辑的复杂度。&lt;/p&gt;

&lt;p&gt;这里主要分为三段：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;判断日期是否重叠：对数据以 test_case 为划分依据，按开始日期和结束日期排序。比较当前开始日期和之前的结束日期，若开始日期大于最大的结束日期，说明两日期无重叠，grp_start 标志位记为1，反之记为0。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对相邻重叠日期做区分：按同样的划分排序方式。对当前日期及以前的 grp_start 求和，由于重叠日期被标记为0，因而最后相邻重叠日期的 grp 标志位将相同，其余日期各不相同。起到区分不重叠日期，合并重叠日期的作用。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;分组选取最大最小值，得到结果：按 test_case 与 grp 分组，选取各组最小和最大的日期，最后按第一列和第二列排序，得到目标结果。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;小结：通过拆分的思想+窗口函数的帮助，出色完成组织交代的任务，在 HIVE 中实现了合并重叠日期这一任务。但同时也要注意，在功能保证的同时，该脚本如同算法一样，也是有边界的。比如当 end_date 为空时，将会出现错误。这种情况最好先把空值填充为特殊值 ‘9999-12-31’，结束后再转换为空值。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在 HIVE 中合并重叠日期，一开始看起来很难，但实际上学会分析问题，分解问题，简化问题，其实不难。网上有很多有用的资源，要学会合理利用。在实现基本需求的同时，给自己留些时间，深挖背后的原理，将会给自己、同时也是给组织带来持续性的效率提升。&lt;/p&gt;

&lt;p&gt;例如：搞完这一套后，虽说重写祖传代码不太现实，但对于新的需求，可能会思考 &lt;code&gt;with&lt;/code&gt; 语法带来的好处，将其运用到业务中去，减少中间表冗余，简化逻辑，增强 sql 代码可读性。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B test 揭秘之什么是 A/B test</title>
      <link>https://kuhungio.me/2019/abtest/</link>
      <pubDate>Fri, 24 May 2019 09:02:00 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest/</guid>
      <description>

&lt;p&gt;此文总结自 Udacity 的课程：A/B test，详细而系统地讲述了 Google，Amazon 以及 Netflix 等公司是如何在商业问题中设计 A/B test 并评估效果的，对于国内的业务也有很强的参考意义。这里是总结的的一部分：什么是 A/B test，讲述 A/B Test 的定义、适用范围以及和传统方法的异同。指标选择、实验设计与评估将在后面陆续放出。&lt;/p&gt;

&lt;h2 id=&#34;a-b-概览&#34;&gt;A/B 概览&lt;/h2&gt;

&lt;h3 id=&#34;q-什么是-a-b-test&#34;&gt;Q：什么是 A/B test？&lt;/h3&gt;

&lt;p&gt;A：A/B test 是一种用来测试新产品或新功能的在线测试常规方法。一般分为两组用户，一组对照组，一组实验组。对照组采用已有的产品或功能，实验组采用新功能。要做的是找到他们的不同反应，并以此确定哪个版本更好。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-是否有适用范围-还是说所有情况都适用&#34;&gt;Q：A/B test 是否有适用范围，还是说所有情况都适用？&lt;/h3&gt;

&lt;p&gt;A：A/B test 能帮助你爬上前面的山峰，但如果想弄清楚是爬这座还是另一座，A/B test 可能不太有效。A/B test 能对很大范围的事情进行测试。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如：

&lt;ul&gt;
&lt;li&gt;亚马逊个性化推荐的 A/B test，发现个推能显著提升收益。&lt;/li&gt;
&lt;li&gt;领英对首页流排序的测试，谷歌的搜索广告排名。&lt;/li&gt;
&lt;li&gt;此外还可以对用户难以察觉的东西进行测试，如网站响应速度。亚马逊在07年发现：页面每增加100ms延迟，收入将会下降1个百分点。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;q-a-b-test-不能做什么事情&#34;&gt;Q：A/B test 不能做什么事情？&lt;/h3&gt;

&lt;p&gt;A：上线新的版本，带来完全不同的交互体验；或是低频长周期的产品；以及 A/B test 并不能发现被遗漏了什么。&lt;/p&gt;

&lt;p&gt;测试新的交互体验时，A/B test 可能不太奏效。原因有两个：一、厌恶改变，不是每个人都喜欢改变，这可能导致用户的厌恶和抵触情绪。二、新奇效应，对于新鲜事物，用户可能会挨个尝试所有东西。&lt;/p&gt;

&lt;p&gt;于此同时，这里会有两个问题，一个是你的比较基准是什么？另一个是需要花多少时间得出结论？举个例子：像低频的房屋租赁，在测试推荐流的时候，很难确定用户是为啥回来的。因为这要花的时间太长了，也许是半年，甚至是更久。&lt;/p&gt;

&lt;p&gt;A/B test 无法告诉你是否有遗漏。当我们在某个产品测试信息推荐流时，仅凭 A/B test，无法知道是否该给这个用户推荐地理信息的资讯。于此同时，也无法确定别的产品是否需要推荐流。&lt;/p&gt;

&lt;h3 id=&#34;q-对于-a-b-test-难以胜任的事情-该如何解决&#34;&gt;Q：对于 A/B test 难以胜任的事情，该如何解决？&lt;/h3&gt;

&lt;p&gt;A：通过其它数据源来补充，对日志进行分析假设验证。或是通过其它技术，如用户研究来定性分析。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-的历史是什么样的&#34;&gt;Q：A/B test 的历史是什么样的？&lt;/h3&gt;

&lt;p&gt;A：最先使用 A/B test 的，可能是农业领域。人们将土地分为不同部分，测试哪块地适合哪种作物作物或是作物如何生长。在科研领域。假设检验是确定创新的关键方法。医学上的 A/B test 被称为临床试验，通过此种方法来确定新的治疗方法是否有效。&lt;/p&gt;

&lt;h3 id=&#34;q-传统实验和在线的-a-b-test-有何异同呢&#34;&gt;Q：传统实验和在线的 A/B test 有何异同呢？&lt;/h3&gt;

&lt;p&gt;A：在线上，拥有更多的数据，但是分辨率低。像传统医学试验或用户体验研究，对象可能有10个、50个或100个，对每个参与者的基本信息都很了解。但在线上，我们的用户可能是数百万、上千万的点击交互行为，我们无法确定数据的另一端是谁。是一个人还是几个人，是网吧学校还是别的什么。通过 A/B test，目的是确认用户是否喜欢这个新产品或新功能。所以做 A/B test 的人的目标是设计一个合理且可复现的结果，用来帮助决策。A/B test 无处不在，FLAG 都在不同程度地使用 A/B test，甚至有专门地公司帮助小公司提供这些服务。&lt;/p&gt;

&lt;p&gt;##总结&lt;/p&gt;

&lt;p&gt;通过以上内容，我们知道了 A/B test的定义，明白他是为了更好决策的系统性方法。该方法在很多场景都适用，但在对于一些大的改动和低频次长周期的产品功能，A/B test并不能很好解决。通过数据互补，用户调研等方法，我们一定程度上弥补了 A/B test的短板。相较于传统的控制变量方法，线上的 A/B test数据量更大，但也难以确定真实的数据产生者。这些问题，在使用 A/B test时都要考虑。&lt;/p&gt;

&lt;p&gt;A/B test到底如何做，指标如何设定，如何说明新产品或新功能确实有效或无效？带着这些疑问，我们将进入到下期的内容。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>数据从业者必读的7本书 Booklist for DE</title>
      <link>https://kuhungio.me/2019/book-list-for-ds/</link>
      <pubDate>Tue, 07 May 2019 23:34:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/book-list-for-ds/</guid>
      <description>

&lt;p&gt;之前逛论坛，或者学习网站，看到很多人喜欢推荐书。自己早些时候也是这样，但是只 mark，却很少去看。如今作为一名社会人，虽说工作之余时间少了很多，但业余仍在坚持阅读。其中，支撑学习动力的一本书便是：《穷查理宝典》。书中查理·芒格提到的多学科思维，以及复利思维，一直在影响我的交友、做事和看问题的方式。&lt;/p&gt;

&lt;p&gt;有关注某校友的公众号，他是做爬虫和可视乎的。某天在推荐 Python 学习资料。封面看着挺美，点开一看，书单质量实属一般。倒像是接的推广，很多估计他自己都没有看过，不太负责任。于是乎，便萌生了出一期书单的想法。而定位，便是数据科学家、数据挖掘工程师、算法工程师的书单。&lt;/p&gt;

&lt;p&gt;首先声明，这份书单不是单纯的技术向书籍，不会有什么西瓜书或是算法导论之类的。他们也是好书，但不会出现在这里。因为在工作中大家就会发现，技术只是工具，好的工匠 != 熟练使用工具的熟练工。看见大局，同时有跨学科的思维，能够从事物的本质去出发，理解和思考它，也很重要。&lt;/p&gt;

&lt;p&gt;作为一个数据挖掘工程师，以下是推荐的核心7本书单。为什么是7本呢？因为人一下子能记住的东西是有限的，记不住就忍不住收藏。收藏了就几乎等于很少看了。收藏一时爽，一直收藏一直爽。所以，书单从原来的二十几本变为了现在的7本。&lt;/p&gt;

&lt;p&gt;这7本书的逻辑是从底层到高层。底层是构成我们一部分的东西，是我们的认知。中间则是我们的技能。而高层，则是我们的自我实现。最终又回到我们的认知。简单来说，就是从软技能到硬实力，再到软实力。&lt;/p&gt;

&lt;h2 id=&#34;通识与概念&#34;&gt;通识与概念&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Top 7&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通识趣味读本&amp;ndash;《赤裸裸的统计学》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该书讲了很多身边的例子，让人对统计学的应用有一个初步认识。且是一个检验兴趣点的很好方式。如果你对这些东西都不是很感冒，那么可能这行除了薪水，没有别的能吸引你。后面的内容也就没有读的必要了。&lt;/p&gt;

&lt;p&gt;除了例子以外，本书也有很多反常识反直觉的东西。诸如统计数字会撒谎、因果关系与相关关系的混淆。黑天鹅、三门问题等地很考验一个人的智商。看完之后有醍醐灌顶的感觉。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《大教堂与旧集市》、《编码》等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Top 6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大而全&amp;ndash;《信息论、推理与学习算法》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果你对第一本书的内容感兴趣，想要深入了解背后的原理，那么这本书不容错过。这本书更像是一本大百科全书，涵盖了传统信息论到最新算法的大部分内容。从熵、到编码、再到概率与推理，最后到常见的模型和神经网络。是一本适合高年级学生或者专人人员的查阅宝典。&lt;/p&gt;

&lt;p&gt;这本书说实话有些厚重，限于版面，如果只推荐一本，会推荐它。当然如果想看更多元的内容，附加的书籍📚可不容错过。由于本身的专业偏传统工科，编码、信息压缩也有接触，因而过渡起来不会很困难。&lt;/p&gt;

&lt;p&gt;与之互补的书还有《推荐系统实战》、《信息检索导论》、《集异壁》等。&lt;/p&gt;

&lt;h2 id=&#34;工具与思想&#34;&gt;工具与思想&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;吃饭工具&amp;ndash;《SQL 必知必会》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作为一个工程师，常自嘲自己是 sql boy。那是因为，在实际生产环境中，数据处理花了很大事件。大部分时间都是和sql 打交道。做过比赛的同学可能知道，数据处理、特征提取是很关键的一步。&lt;/p&gt;

&lt;p&gt;在企业中，这一情况越发突出。有时候原始数据分散在各个地方，连规整的数据都没有。因而需要掌握一定的 sql 技能。虽然有些专业会学习数据库这一门课程，但这本书可以起到一个梳理作用，同时也有一些小的注意点。&lt;/p&gt;

&lt;p&gt;掌握了这本书的同学，推荐《 SQL 反模式》，讲 sql 范式更进一步。虽说是给数据库开发人员看的，但是知其然并知其所以然，也是很好的。&lt;/p&gt;

&lt;p&gt;如果想看到更大的图景，那么 ddia 一定不容错过。ddia 在一年前就很火，网上也有他的公开中文翻译。讲解整个数据系统很透彻。适合各类程序开发人员阅读。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 4&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《利用 python 进行数据分析》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书也算是启蒙书。涉及的内容基本面很广，该有的都有了。介绍了 python 在数据科学领域的基础知识，同时也有案例解析。&lt;/p&gt;

&lt;p&gt;读完这本书，参加小型的数据挖掘、机器学习类的比赛不会存在门槛了。与此类似的书还有《集体智慧编程》，以及近期比较火的 hands on ml。&lt;/p&gt;

&lt;h2 id=&#34;思考与呈现&#34;&gt;思考与呈现&lt;/h2&gt;

&lt;p&gt;前面都是技术向、原理向的内容。是不是掌握了以上内容，就可以美滋滋的享受生活了呢？其实这是很多软件从业人员、甚至是工科同学的一个共同误区。觉得把我的技术学好了，就万事大吉，酒香不怕巷子深了。在这里千万不要忽略掉你的软实力。&lt;/p&gt;

&lt;p&gt;在某些头部公司、ppt 文化盛行。虽然有些走极端，这其实也是一种现状。从原则上来讲，只讲 PPT 画大饼而不做事是不对的，所以他们被放在最后讲。与此同时要记住，硬币的反面也是不对的，只埋头苦干，而不去扩大影响力，事情的价值就很可能被低估。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《金字塔原理》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要是逻辑性思维的呈现原则，以及最核心的一点站在对方的角度看问题。书中罗列了很多报告撰写、演讲呈现的方法技巧。比如自上而下思考，自下而上表达，横向概括、纵向分类，独立穷尽。这些机巧用在你的日常生活中的表达和演讲，将会大大加分。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《演说之禅》，以及稍微和职业更靠近的《数据可视化之美》。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《咨询的奥秘》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书是集中在讲思维方式的。咨询也算是数据科学家的一重身份。如何看待问题，如何给出建议，这本书都有很好的示范。&lt;/p&gt;

&lt;p&gt;与之类似的有《你的灯亮着吗》、《学会提问》。&lt;/p&gt;

&lt;h2 id=&#34;实践出真知&#34;&gt;实践出真知&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;实践&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;top 1 没有书，top 1 是实践。收藏了那么多资料，不如潜心研究一两个案例，去实践来的快。追踪学术前沿，去做一些实践；或者是对一些好玩的东西，做一些 demo，收获不会比上面的阅读小。&lt;/p&gt;

&lt;p&gt;如果想要更进一步，那就试着对外输出：无论是看到的知识，或者是方法论，抑或是工具使用技巧，还是对自己有帮助的 demo。这些都能很好的锻炼思维，让人更进一步。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;以上是给大家推荐的从业者的7本书，都是经过本人检验的。从通识到基础概念，从工具到学科思想，最后又回到普罗大众，思考和呈现我们的工作。希望能帮助诸位更进一步，在职业生涯上大放光彩。&lt;/p&gt;

&lt;p&gt;豆瓣书单 &lt;a href=&#34;https://www.douban.com/doulist/113972160/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.douban.com/doulist/113972160/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>

&lt;h1 id=&#34;深度强化学习技巧-hacks-for-training-deep-rl&#34;&gt;深度强化学习技巧 hacks for training deep RL&lt;/h1&gt;

&lt;p&gt;这是一篇旧文，&lt;a href=&#34;http://joschu.net/?utm_source=kuhungio&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;John Schulman&lt;/a&gt; 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。  &lt;/p&gt;

&lt;h2 id=&#34;测试新算法的技巧&#34;&gt;测试新算法的技巧&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;简化问题，使用低维变量。

&lt;ul&gt;
&lt;li&gt;使用类似只有角度和速度两个变量的 &lt;a href=&#34;https://gym.openai.com/envs/Pendulum-v0&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Pendulum problem&lt;/a&gt; 问题。&lt;/li&gt;
&lt;li&gt;这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。&lt;/li&gt;
&lt;li&gt;当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;构造一个 demo 来测试你的算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。&lt;/li&gt;
&lt;li&gt;这样能够轻易地发现那里出了问题。&lt;/li&gt;
&lt;li&gt;注意：不要在这样的小问题上过分的尝试。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在熟悉的场景中测试&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随着时间的推移，你将能预估训练所需的时间。&lt;/li&gt;
&lt;li&gt;明白你的奖赏是如何变化的。&lt;/li&gt;
&lt;li&gt;能够设定一个基线，以便让你知道相对过去改进了多少。&lt;/li&gt;
&lt;li&gt;作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;快速上手新任务的技巧&#34;&gt;快速上手新任务的技巧&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;简化问题

&lt;ul&gt;
&lt;li&gt;从简单的开始，直到回到问题。&lt;/li&gt;
&lt;li&gt;途径1： 简化特征空间

&lt;ul&gt;
&lt;li&gt;举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。&lt;/li&gt;
&lt;li&gt;一旦起步，逐步还原问题直到解决问题。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;途径2：简化奖赏函数

&lt;ul&gt;
&lt;li&gt;简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。&lt;/li&gt;
&lt;li&gt;比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;将一个问题转化为强化学习的技巧&#34;&gt;将一个问题转化为强化学习的技巧&lt;/h2&gt;

&lt;p&gt;可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;第一步：将这个问题使用随机策略可视化出来。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;看看那些部分吸引了你。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果这个随机策略在某些情况下做了正确的事，那么很大概率，强化学习也可以做到。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;策略的更新将会发现这里面的行为，并促使稳定下来。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果随机策略永远都做不到，那么强化学习也不可能。
   &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确保可观测&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;确保你能够掌控系统，且给 agent 的也是同样的系统环境。

&lt;ul&gt;
&lt;li&gt;举个例子： 亲自查看处理过图片，以确保你没有移出掉关键信息或者是在某种程度上阻碍算法。
 &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确保所有的事物都在合理的尺度&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;经验法则：

&lt;ul&gt;
&lt;li&gt;观测环境： 确保均值为0，方差为1。&lt;/li&gt;
&lt;li&gt;奖赏： 如果你能控制它，就把他缩放到一个合理的维度。&lt;/li&gt;
&lt;li&gt;在所有的数据上都做同样的处理。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;检查所有的观测环境以及奖赏，以确保没有特别离奇的异常值。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;建立一个好的基线&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一开始并不清楚哪些算法会起作用，所以设定一系列的基线（从其他方法）。

&lt;ul&gt;
&lt;li&gt;交叉熵&lt;/li&gt;
&lt;li&gt;策略更新&lt;/li&gt;
&lt;li&gt;一些类型的 Q-learning 算法: &lt;a href=&#34;https://github.com/openai/baselines&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;OpenAI Baselines&lt;/a&gt; 或者 &lt;a href=&#34;https://github.com/rll/rllab&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;RLLab&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;复现论文&#34;&gt;复现论文&lt;/h2&gt;

&lt;p&gt;某些时候（经常的事），复现论文结果特别困难。有如下一些技巧：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用比预计更多的样本。&lt;/li&gt;
&lt;li&gt;策略正确，但又不完全正确。

&lt;ul&gt;
&lt;li&gt;尝试让模型运行更久一点。&lt;/li&gt;
&lt;li&gt;调整超参数以达到公开的效果。&lt;/li&gt;
&lt;li&gt;如果想让他在所有数据上都奏效，使用更大的 batch sizes。

&lt;ul&gt;
&lt;li&gt;如果 batch size 太小，噪声将会压过真正有用的信号。&lt;/li&gt;
&lt;li&gt;比如： TRPO，作者使用了一个特别小的 batch size，然后不得不训练10万次迭代。&lt;/li&gt;
&lt;li&gt;对于 DQN，最好的参数：一万次迭代，10亿左右的缓存存储。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;对于训练中的一些处理&#34;&gt;对于训练中的一些处理&lt;/h2&gt;

&lt;p&gt;检查你的训练是否正常：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查每个超参数的鲁棒性&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果一个算法太过敏感，那么它可能不太鲁棒，并且不容乐观。&lt;/li&gt;
&lt;li&gt;有些时候，某个策略生效，可能仅仅是因为巧合而已，它并不足以推广。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;关注优化过程是否正常的指标&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;变动情况&lt;/li&gt;
&lt;li&gt;关注目标函数是否正确

&lt;ul&gt;
&lt;li&gt;是否预测正确？&lt;/li&gt;
&lt;li&gt;它的返回是否正确？&lt;/li&gt;
&lt;li&gt;每次的更新有多大？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;一些标准的深度神经网络的诊断方法&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有一套能够连续记录代码的系统&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;有成型的规则。&lt;/li&gt;
&lt;li&gt;注意过去所作的所有尝试。

&lt;ul&gt;
&lt;li&gt;有些时候，我们关注一个问题，最后却把注意力放在了其他问题上。&lt;/li&gt;
&lt;li&gt;对于一个问题，很容易过拟合。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;有一大推之前时不时测试的基准。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有时候会觉得系统运行正常，但很可能只是巧合。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如： 有3套算法处理7个任务，可能会有一个算法看起来能很好地处理所有问题，但实际上，它们不过是一套算法，不同的仅仅是随机种子而已。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用不同的随机种子&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;运行多次取平均。&lt;/li&gt;
&lt;li&gt;在多个种子的基础上运行多次。

&lt;ul&gt;
&lt;li&gt;如果不这样做，那你很有可能是过拟合了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;额外的算法修改可能并不重要&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大部分的技巧都是在正则化处理某些对象，或者是在改进你的优化算法。&lt;/li&gt;
&lt;li&gt;许多技巧有相同的效果&amp;hellip;&amp;hellip;所以，你可以通过移除它们，来简化你的算法（很关键）。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;简化你的算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将会取得更好的泛化效果。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自动化你的实验&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不要整天盯着你的代码读取和写入数据。&lt;/li&gt;
&lt;li&gt;将实验部署在云端并分析结果。&lt;/li&gt;
&lt;li&gt;追踪实验与结果的框架：

&lt;ul&gt;
&lt;li&gt;大部分使用 iPython notebooks。&lt;/li&gt;
&lt;li&gt;数据库对于存储结果来说不是很重要。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总的训练策略&#34;&gt;总的训练策略&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;数据的白化与标准化（一开始就这样做，对所有数据）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;训练数据（Obervation）：

&lt;ul&gt;
&lt;li&gt;计算均值与标准差，然后做标准化转变。&lt;/li&gt;
&lt;li&gt;对于全体数据（不仅仅是当前的数据）。

&lt;ul&gt;
&lt;li&gt;至少它减轻了随时间的变化波动情况。&lt;/li&gt;
&lt;li&gt;如果不断地改变对象的话，可能会使优化器迷糊。&lt;/li&gt;
&lt;li&gt;缩放（仅最近的数据）意味着你的优化器不知道这个情况，训练将会失败。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;奖赏（Rewards）：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;缩放但不要转变对象。

&lt;ul&gt;
&lt;li&gt;影响 agent 的继续下去的可能。&lt;/li&gt;
&lt;li&gt;将会改变问题（你想让它持续多久）。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;归一化目标（Standardize targets）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;与 rewards 相同。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PCA 白化&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以起作用。&lt;/li&gt;
&lt;li&gt;开始时的时候要看看它是否真的对神经网络起作用。&lt;/li&gt;
&lt;li&gt;大规模的缩放（-1000，1000）到（-0.001，0.001）必然会使学习减缓。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;衰减因子的调参&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;判断分配多少权重。&lt;/li&gt;
&lt;li&gt;举个例子：如果因子是0.99，那么你将忽略100步以前的事情，这意味着某种程度的短视。

&lt;ul&gt;
&lt;li&gt;最好是看看对应多少的现实时间。

&lt;ul&gt;
&lt;li&gt;直觉上，我们通常在强化学习中离散时间。&lt;/li&gt;
&lt;li&gt;换句话说，100步是指3秒前吗？&lt;/li&gt;
&lt;li&gt;在这个过程中发生了什么？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果是用于 fx 估计的策略更新 TD 算法，gamma 可以选择靠近1（比如0.999）。

&lt;ul&gt;
&lt;li&gt;算法将非常稳健。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;观察问题是否真的能被离散化处理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如：在一个游戏有跳帧。&lt;/li&gt;
&lt;li&gt;作为一个人类，你能控制还是不能控制。&lt;/li&gt;
&lt;li&gt;查看随机情况是怎么样的。

&lt;ul&gt;
&lt;li&gt;离散化程度决定了你的随机布朗运动能有多远。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果连续性地运动，往往模型会走很远。&lt;/li&gt;
&lt;li&gt;选择一个起作用的时间离散化分。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;密切关注返回的 episode&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不仅仅是均值，还包括极大极小值

&lt;ul&gt;
&lt;li&gt;最大返回是你的策略能做到的最好程度&lt;/li&gt;
&lt;li&gt;看看你的策略是否工作正常？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;查看 episode 时长（有时比 episode reward 更为重要）

&lt;ul&gt;
&lt;li&gt;在一场游戏中你场场都输，从未赢过，但是 episode 时长可以告诉你是不是输得越来越慢&lt;/li&gt;
&lt;li&gt;一开始可能看见 episode 时长有改进，但 reward 无反应&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;策略优化诊断&#34;&gt;策略优化诊断&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;仔仔细细地观察 entropy&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;action 层面的 entropy

&lt;ul&gt;
&lt;li&gt;留意状态空间 entropy 的变化，虽然没有好的计量办法&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果快速地下降，策略很快便会固定然后失效&lt;/li&gt;
&lt;li&gt;如果没有下降，那么这个策略可能不是很好，因为它是随机的&lt;/li&gt;
&lt;li&gt;通过以下方式补救：

&lt;ul&gt;
&lt;li&gt;KL penalty

&lt;ul&gt;
&lt;li&gt;使 entropy 远离快速下降&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;增加 entropy bonus&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如何测量 entropy

&lt;ul&gt;
&lt;li&gt;对于大部分策略，可以采用分析式方法

&lt;ul&gt;
&lt;li&gt;对于连续变量，通常使用高斯分布，这样可以通过微分计算 entropy&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;观察 KL 散度&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;观察 KL 散度的更新尺度&lt;/li&gt;
&lt;li&gt;例如：

&lt;ul&gt;
&lt;li&gt;如果 KL 是0.01，那它是相当小的。&lt;/li&gt;
&lt;li&gt;如果是10，那它又非常的大。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过基线解释方差&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查看价值函数是不是好的预测或者给予回报

&lt;ul&gt;
&lt;li&gt;如果是负数，可能是过拟合了或者是噪声

&lt;ul&gt;
&lt;li&gt;可能需要超参数调节
 &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;初始化策略&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;非常重要（比监督学习更重要）&lt;/li&gt;
&lt;li&gt;最后一层取0或者是一个很小的值来最大化 entropy

&lt;ul&gt;
&lt;li&gt;初始最大化随机 exploration&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;q-learning-策略&#34;&gt;Q-Learning 策略&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;留意 replay buffer 存储的使用情况&lt;/li&gt;

&lt;li&gt;&lt;p&gt;你可能需要一个非常大的 buffer，依代码而定&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;手边常备 learing rate 表&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果收敛很慢或者一开始有一个很慢的启动&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;保持耐心，DQNs 收敛非常慢&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;Translated by &lt;a href=&#34;https://github.com/kuhung&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung&lt;/a&gt; 2017/08/29&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/deepRL/deepRL.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号【谷粒先生】，回复【强化学习】获取 PPT 原版&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>机器学习模型部署--打通前后端任督二脉</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;h3 id=&#34;学历与定位&#34;&gt;学历与定位&lt;/h3&gt;

&lt;p&gt;近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个小本就工作的人，没有较为丰富的实战经验，有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/flask_vue_ML/mobile.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;模型算法的实用主义&#34;&gt;模型算法的实用主义&lt;/h3&gt;

&lt;p&gt;机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 &lt;a href=&#34;https://github.com/kuhung/flask_vue_ML&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung/flask_vue_ML&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;后端-flask&#34;&gt;后端 flask&lt;/h2&gt;

&lt;h3 id=&#34;相关依赖的安装&#34;&gt;相关依赖的安装&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;核心函数&#34;&gt;核心函数&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;导入函数包&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flask import Flask, jsonify, request
from flask_cors import CORS # 做跨域的准备
from flask import session # 追踪客户端会话

from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类
from flair.data import Sentence

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;准备工作&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = Flask(__name__) # 声明准备
app.secret_key = &amp;quot;super_secret_key&amp;quot;

CORS(app)
classifier = TextClassifier.load_from_file(&#39;models/best-model.pt&#39;) # 模型加载

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;配置 flask 的路由&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 根路由配置
@app.route(&#39;/&#39;, methods=[&#39;GET&#39;])
def index():
    return jsonify(&amp;quot;welcome to Kuhung API&amp;quot;)

# GET 方法，这里 session 的作用是追踪客户端会话，防止重复请求模型
@app.route(&#39;/api/tasks&#39;, methods=[&#39;GET&#39;])
def get_result():
    result = []
    try:
        data_result = session[&#39;my_result&#39;]
        result.append ({&#39;title&#39;: data_result[&#39;title&#39;], &#39;tag&#39;: data_result[&#39;tag&#39;] })
    except:
        result.append ({&#39;title&#39;: &#39;The txt you input&#39;, &#39;tag&#39;: &#39;spam or ham&#39; })
    return jsonify(result)

# POST 方法
@app.route(&#39;/api/task&#39;, methods=[&#39;POST&#39;])
def input_predict_text():

    title = request.get_json()[&#39;title&#39;] # 解析请求

    sentence = Sentence(title) # 对请求做数据预处理
    classifier.predict(sentence) # 调用模型，做预测，返回带标签的数据

    text = sentence.to_plain_string() # 解析出原始数据
    label = sentence.labels[0] # 解析出标签
    result = {&#39;title&#39; : text, &#39;tag&#39; : label.value} # 拼接成字典格式
    session[&#39;my_result&#39;] = result # 存入 session ，以减少重复请求对模型的压力
    
    return jsonify(result) # 返回 json 格式的数据

if __name__ == &#39;__main__&#39;:
    app.run(debug=True)  # 开发过程中开启 debug 调试模式
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动服务&#34;&gt;启动服务&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;python app.py&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;前端-vue&#34;&gt;前端 vue&lt;/h2&gt;

&lt;p&gt;前端采用 Vue 框架，与后端分离。使用 Webpack 进行资源管理与打包。&lt;/p&gt;

&lt;h3 id=&#34;相关依赖的安装-1&#34;&gt;相关依赖的安装&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install -g vue-cli
npm install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;自定义组件&#34;&gt;自定义组件&lt;/h3&gt;

&lt;p&gt;通过 &lt;code&gt;vue init webpack flask_vue_ML&lt;/code&gt; 后，进入项目文件夹，增加自定义内容。&lt;/p&gt;

&lt;h4 id=&#34;index-html&#34;&gt;index.html&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width,initial-scale=1.0&amp;quot;&amp;gt;
    &amp;lt;title&amp;gt;exposemodel&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;!-- 其它文件会自动注入这里 --&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;src-文件夹&#34;&gt;src 文件夹&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;components

&lt;ul&gt;
&lt;li&gt;Home.vue  // 自定义组件，增加&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;router

&lt;ul&gt;
&lt;li&gt;index.js  // 路由，修改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;App.vue  // 主组件，修改&lt;/li&gt;
&lt;li&gt;main.js  // 入口文件，修改&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##### Home.vue&lt;/p&gt;

&lt;p&gt;这里定义页面的基本样式，以及获取数据的逻辑。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vue&#34;&gt;&amp;lt;template&amp;gt;
  &amp;lt;div id=&amp;quot;todo-list-example&amp;quot; class=&amp;quot;container&amp;quot;&amp;gt;
    &amp;lt;!-- 我是进度条，最上方的 --&amp;gt;
    &amp;lt;vue-progress-bar&amp;gt;&amp;lt;/vue-progress-bar&amp;gt;
    &amp;lt;div class=&amp;quot;row&amp;quot;&amp;gt;
      &amp;lt;div class=&amp;quot;col-md-6 mx-auto&amp;quot;&amp;gt;
        &amp;lt;h1 class=&amp;quot;text-center&amp;quot;&amp;gt;Natural Language Processing (NLP)&amp;lt;/h1&amp;gt;
        &amp;lt;form v-on:submit.prevent=&amp;quot;addNewTask&amp;quot;&amp;gt;
          &amp;lt;label for=&amp;quot;tasknameinput&amp;quot;&amp;gt;Spam Classification&amp;lt;/label&amp;gt;
          &amp;lt;input v-model=&amp;quot;taskname&amp;quot; type=&amp;quot;text&amp;quot; id=&amp;quot;tasknameinput&amp;quot; class=&amp;quot;form-control&amp;quot; placeholder=&amp;quot;Enter Sentence&amp;quot;&amp;gt;
          &amp;lt;button type=&amp;quot;submit&amp;quot; class=&amp;quot;btn btn-success btn-block mt-3&amp;quot;&amp;gt;
            Submit
          &amp;lt;/button&amp;gt;
        &amp;lt;/form&amp;gt;
          
&amp;lt;!-- 省略表格定义内容 --&amp;gt;


&amp;lt;script&amp;gt;
// 这里解决跨域请求问题，向后端发起请求
import axios from &#39;axios&#39;

export default {
  data () {
    return {
      textClassify: [],
      id: &#39;&#39;,
      taskname: &#39;&#39;,
      isEdit: false
    }
  },
  mounted () {
    this.getTasks()
  },
    
// 省略进度条内容
    
// 请求任务相关操作
    getTasks () {
      axios({ method: &#39;GET&#39;, url: &#39;/api/tasks&#39; }).then(
        result =&amp;gt; {
          console.log(result.data)
          this.textClassify = result.data
        },
        error =&amp;gt; {
          console.error(error)
        }
      )
    },
&amp;lt;/script&amp;gt;
​```
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;index-js&#34;&gt;index.js&lt;/h5&gt;

&lt;p&gt;定义路由，设定访问路径，并将路径和组件关联&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import Vue from &#39;vue&#39;
import Router from &#39;vue-router&#39;
import Home from &#39;@/components/Home&#39;

Vue.use(Router)

export default new Router({
  routes: [
    {
      path: &#39;/&#39;,
      name: &#39;Home&#39;,
      component: Home
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;app-vue&#34;&gt;App.vue&lt;/h5&gt;

&lt;p&gt;主组件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vue&#34;&gt;&amp;lt;template&amp;gt;
  &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;
    &amp;lt;router-view/&amp;gt;
    &amp;lt;!-- 植入一波广告：微信搜索：谷粒先生，关注我的公众号 --&amp;gt;
    &amp;lt;img src=&amp;quot;./assets/wechat.jpg&amp;quot;&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;

&amp;lt;script&amp;gt;
export default {
  name: &#39;App&#39;
}
&amp;lt;/script&amp;gt;

&amp;lt;style&amp;gt;
#app {
  font-family: &#39;Avenir&#39;, Helvetica, Arial, sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  text-align: center;
  color: #2c3e50;
  margin-top: 60px;
}
&amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;main-js&#34;&gt;main.js&lt;/h5&gt;

&lt;p&gt;初始化实例并加载必要插件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// The Vue build version to load with the `import` command
// (runtime-only or standalone) has been set in webpack.base.conf with an alias.
import Vue from &#39;vue&#39;
import App from &#39;./App&#39;
import router from &#39;./router&#39;
import VueProgressBar from &#39;vue-progressbar&#39;
require(&#39;../node_modules/bootstrap/dist/css/bootstrap.css&#39;)

Vue.config.productionTip = false

// 这是进度条
Vue.use(VueProgressBar, {
  color: &#39;rgb(143, 255, 199)&#39;,
  failedColor: &#39;red&#39;,
  height: &#39;10px&#39;
})

/* eslint-disable no-new */
new Vue({
  el: &#39;#app&#39;,
  router,
  components: { App },
  template: &#39;&amp;lt;App/&amp;gt;&#39;
})

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动服务-1&#34;&gt;启动服务&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;npm run dev&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;模型-flair&#34;&gt;模型 flair&lt;/h2&gt;

&lt;p&gt;模型这里采用 fair 框架，该框架在 2018 年底发布，易用性和效果都较前方案有了较大提升。这里直接采用官方样例训练好的垃圾邮件分类模型的权重，也就是在上文后端所读取的文件。关注我的公众号：谷粒先生，回复&lt;strong&gt;权重&lt;/strong&gt;，即可获得权重文件🔗链接。&lt;/p&gt;

&lt;h3 id=&#34;模型调用&#34;&gt;模型调用&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类
from flair.data import Sentence

classifier = TextClassifier.load_from_file(&#39;models/best-model.pt&#39;) # 模型加载

sentence = Sentence(title) # 对请求做数据预处理
classifier.predict(sentence) # 调用模型，做预测，返回带标签的数据
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;效果展示&#34;&gt;效果展示&lt;/h2&gt;

&lt;p&gt;本教程针对文本分类这个场景，构建了一套前后端分离的“完整”框架，能够给到一个最直观的感受。当然，这里还有很多优化空间，还有后续部署等事宜没有详细展开，有心的同学可以自行检索学习。通过这套流程，可以在测试服搭建一套实用主义哲学的算法模型。给到领导做展示或是公司内部使用，已经足够。项目地址 &lt;a href=&#34;https://github.com/kuhung/flask_vue_ML&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung/flask_vue_ML&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;终端端网站访问&#34;&gt;终端端网站访问&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/flask_vue_ML/flask_vue_ml.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;喜欢我的朋友，别忘了点赞 👍、喜欢 ❤ +关注 🔔哦，你的鼓励是对我最大的支持~💪&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>如何设计一套类似视觉中国鹰眼的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>

&lt;p&gt;这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/vgc/vgc 不敢配图.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;“鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。&lt;/p&gt;

&lt;p&gt;爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。&lt;/p&gt;

&lt;p&gt;首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/vgc/vgc 图像工程与相关学科领域的联系与区别.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。&lt;/p&gt;

&lt;p&gt;首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。&lt;/p&gt;

&lt;p&gt;从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。&lt;/p&gt;

&lt;p&gt;第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。&lt;/p&gt;

&lt;p&gt;而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35868882&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;教 AI 学会看图说话：Image Caption&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。&lt;/p&gt;

&lt;p&gt;这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。&lt;/p&gt;

&lt;p&gt;最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。&lt;/p&gt;

&lt;h3 id=&#34;附录&#34;&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://36kr.com/p/5194005&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;视觉中国图片侵权追踪系统曝光：鹰眼系统&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kw.beijing.gov.cn/art/2018/12/27/art_841_75909.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;2018年度市科委第四季度项目(课题)验收公开清单&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://file.finance.sina.com.cn/211.154.219.97:9494/MRGG/CNSESZ_STOCK/2017/2017-4/2017-04-29/3366645.PDF&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;视觉（中国）文化发展股份有限公司 2016 年年度报告&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋&lt;/p&gt;

&lt;p&gt;《基于内容的图象和视频检索》&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hands On Machine Learning in Industry 一文看懂机器学习项目的完整生命周期</title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>

&lt;p&gt;机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。&lt;/p&gt;

&lt;h1 id=&#34;机器学习项目的生命周期&#34;&gt;机器学习项目的生命周期&lt;/h1&gt;

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;p&gt;问题定义&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 定义问题，并关注大局&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据处理&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 获取数据&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 探索性的数据分析&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 清洗数据，为接下来的模型做准备&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;模型方案&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 探索不同的模型并挑选合适的模型&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 对模型进行微调，并集成为更好的模型&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 解决方案呈现&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;部署维护&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 部署、监控并维护系统

&lt;br /&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;定义问题-从大局出发&#34;&gt;定义问题，从大局出发&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;和业务团队一起定义问题目标&lt;/li&gt;
&lt;li&gt;我们的解决方案将会如何发挥作用&lt;/li&gt;
&lt;li&gt;现在的解决方案是什么样的（如果有）&lt;/li&gt;
&lt;li&gt;你将如何定义这个问题（有监督、无监督，在线还是离线）&lt;/li&gt;
&lt;li&gt;结果该如何衡量&lt;/li&gt;
&lt;li&gt;衡量方法是否和商业目标一致&lt;/li&gt;
&lt;li&gt;要达成这一目标，至少的表现该是什么样子的&lt;/li&gt;
&lt;li&gt;类似的问题是什么？有无可复用的经验与工具&lt;/li&gt;
&lt;li&gt;我们有专家知识吗&lt;/li&gt;
&lt;li&gt;你将如何着手解决这个问题&lt;/li&gt;
&lt;li&gt;列出你或者别人目前所作的努力&lt;/li&gt;
&lt;li&gt;如果可能，对假说进行验证&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;获取数据&#34;&gt;获取数据&lt;/h2&gt;

&lt;p&gt;建议：尽量自动化以更容易地方式获取最新的数据&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;列出你所需的数据以及体量&lt;/li&gt;
&lt;li&gt;找寻并记录下获取数据的方式&lt;/li&gt;
&lt;li&gt;检查数据将占据多少空间&lt;/li&gt;
&lt;li&gt;检查是否有法律风险，如有必要请获得许可&lt;/li&gt;
&lt;li&gt;获取许可&lt;/li&gt;
&lt;li&gt;创建工作空间，确保存储足够大&lt;/li&gt;
&lt;li&gt;获取数据&lt;/li&gt;
&lt;li&gt;转换数据的格式以便能够方便操作（不需要改变数据本身）&lt;/li&gt;
&lt;li&gt;确保敏感信息被删除或保护加密（匿名）&lt;/li&gt;
&lt;li&gt;检查数据的大小和类型（时间序列、采样、地理信息等）&lt;/li&gt;
&lt;li&gt;划分测试集，把他放一边，并且不再去动他（防止数据泄露）&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;探索数据&#34;&gt;探索数据&lt;/h2&gt;

&lt;p&gt;建议：在该阶段尽量获取领域专家的意见&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建数据的副本以便做数据探索（如果数据量太大，做降采样处理）&lt;/li&gt;
&lt;li&gt;创建 Jupyter notebook 以便保存探索记录&lt;/li&gt;
&lt;li&gt;研究每个属性及其特征

&lt;ul&gt;
&lt;li&gt;名称&lt;/li&gt;
&lt;li&gt;类型（类别，整型/浮点，有无上下界，文本，结构化等）&lt;/li&gt;
&lt;li&gt;缺失值&lt;/li&gt;
&lt;li&gt;噪声数据（随机数，异常值，四舍五入的误差）&lt;/li&gt;
&lt;li&gt;对本任务可能有用的数据&lt;/li&gt;
&lt;li&gt;分布类型（高斯分布，均匀分布，指数分布）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;对于有监督问题：确定目标对象&lt;/li&gt;
&lt;li&gt;可视化数据&lt;/li&gt;
&lt;li&gt;研究变量间的相关性&lt;/li&gt;
&lt;li&gt;研究你将如何着手解决此问题&lt;/li&gt;
&lt;li&gt;确认比较有希望的解决方案&lt;/li&gt;
&lt;li&gt;确认有用的外部数据&lt;/li&gt;
&lt;li&gt;将以上信息存档记录下来&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;准备数据&#34;&gt;准备数据&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在数据的副本上操作（保持原始数据不被影响）&lt;/li&gt;
&lt;li&gt;将你所作的数据变换写成函数，有以下5个原因

&lt;ul&gt;
&lt;li&gt;便于在本项目的新数据上复用&lt;/li&gt;
&lt;li&gt;便于在别的项目中复用&lt;/li&gt;
&lt;li&gt;快速清洗和准备测试集&lt;/li&gt;
&lt;li&gt;在立项后，能够及时对数据进行处理&lt;/li&gt;
&lt;li&gt;让数据变换过程也能作为超参数的一份子，进行调参&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;数据清洗

&lt;ul&gt;
&lt;li&gt;调整或移除异常值（可选）&lt;/li&gt;
&lt;li&gt;填补缺失值（0，平均数、中位数），或者简单的去掉缺失的样本或特征&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征选择（可选）

&lt;ul&gt;
&lt;li&gt;去掉对本任务无用的信息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征工程，适度

&lt;ul&gt;
&lt;li&gt;连续数值离散化&lt;/li&gt;
&lt;li&gt;特征分解（分类特征、时间特征等）&lt;/li&gt;
&lt;li&gt;特征变换（log(x),sqrt(x),x^2等）&lt;/li&gt;
&lt;li&gt;特征组合&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征尺度变换：标准化或归一化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;挑选合适的模型&#34;&gt;挑选合适的模型&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果数据很大，做降采样，以便能够在合理时间内尝试多个模型（不过要注意，这样的操作对于复杂模型不太友好，比如神经网络和随机森林）&lt;/li&gt;
&lt;li&gt;再一次的，尽量自动化以上流程&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;训练很多模型，快且原始地使用模型参数，训练尽可能多的模型（线性模型、朴素贝叶斯、SVM、随机森林、神经网络等等）&lt;/li&gt;
&lt;li&gt;测量并评估他们的表现

&lt;ul&gt;
&lt;li&gt;对于每个模型，使用 N-fold 交叉验证，计算表现的均值与方差&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;分析每个模型上最为显著的特征&lt;/li&gt;
&lt;li&gt;分析模型所犯的错误类型

&lt;ul&gt;
&lt;li&gt;如果是人类，会采用什么样的方法避免犯错？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;快速地做一波特征选择和特征工程&lt;/li&gt;
&lt;li&gt;前面步骤重复一两次&lt;/li&gt;
&lt;li&gt;列出表现最好的3-5个模型，最好他们的错误情况不同以便集成&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;微调系统&#34;&gt;微调系统&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随着微调的进行，你将会使用尽可能多的数据&lt;/li&gt;
&lt;li&gt;总是使你的操作自动化&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;使用交叉验证进行超参数的微调

&lt;ul&gt;
&lt;li&gt;将你的数据变换也变成超参数的一部分，特别是当你对数据不熟悉的时候（比如：我应该用0还是中位数填补缺失值，还是仅仅去掉那个样本？）&lt;/li&gt;
&lt;li&gt;除非超参数非常少，使用随机搜索而不是网格搜索。如果训练耗时非常久，你可能会想用贝叶斯优化方法。（比如使用高斯过程）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;采用集成方法。集成最优的方案，往往表现会超过单独模型方案。&lt;/li&gt;
&lt;li&gt;一旦你对自己的模型很有信心，那就在测试集上验证其泛化误差。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;方案呈现&#34;&gt;方案呈现&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;记下你所做的努力，文档化&lt;/li&gt;
&lt;li&gt;起草一份漂亮的展示稿

&lt;ul&gt;
&lt;li&gt;确保先强调大局&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;解释为何你的方案达到了商业目标&lt;/li&gt;
&lt;li&gt;不要忘记展现整个过程中你认为的有趣部分

&lt;ul&gt;
&lt;li&gt;讲述什么有效、以及什么没起作用&lt;/li&gt;
&lt;li&gt;列出你的前提条件，并说明边界&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;通过可视乎，确保你的关键发现易于理解和传播；或是利用容易记住的表达&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;部署&#34;&gt;部署&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;准备将你的解决方案接入生产环境（接入生产环境的数据，写单元测试等）&lt;/li&gt;
&lt;li&gt;写监控代码以监测系统的表现，当系统宕机时发出警告

&lt;ul&gt;
&lt;li&gt;要意识到，随着数据的更新，模型的效果也会衰减&lt;/li&gt;
&lt;li&gt;可能需要人工检测数据的表现&lt;/li&gt;
&lt;li&gt;同样监控输入数据（例如：失灵的传感器会传回随机的数据，而其他的传感器的输出会是一个稳定值）这对于在线学习系统尤为重要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;当模型达到一定偏差时，重新在新数据上训练（尽可能自动化）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上，我们从立项、数据准备、模型准备到模型的部署，全面梳理的真实项目中的机器学习模型生命周期。在真实的工业场景中，我们所作的可能有些许差别，但都差不多。例如：我们会对问题定义、会对数据进行探索、会给需求方呈现我们的解决方案、会监控我们的模型表现。&lt;/p&gt;

&lt;p&gt;在梳理过程中我也发现自身团队的不足：对大背景商业目标的认识不到位、很多时候是拿着锤子（模型）去找钉子（场景）、方案呈现上理工科思维偏重、系统迭代不足。除此之外，还有些细节不是很规范。简单来说就是有些跑马圈地、急功近利的感觉。业务向较重，算法模型潜力并未完全释放，在团队内推行以上规范非常有必要。&lt;/p&gt;

&lt;p&gt;不知道看本文的读者，你们的团队会有这样的情况吗？欢迎就此在评论区发表你的看法。喜欢本文的读者，别忘了点赞、喜欢、加关注哦，你的鼓励，将是我写作分享的动力(&lt;em&gt;^_^&lt;/em&gt;)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>