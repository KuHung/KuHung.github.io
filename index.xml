<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kuhung&#39;s Blog on Kuhung&#39;s Blog</title>
    <link>https://kuhungio.me/</link>
    <description>Recent content in Kuhung&#39;s Blog on Kuhung&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 09 Jun 2019 00:17:05 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>HIVE 技巧积累之合并重叠日期</title>
      <link>https://kuhungio.me/2019/merge_overlapping_date/</link>
      <pubDate>Sun, 09 Jun 2019 00:17:05 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/merge_overlapping_date/</guid>
      <description>

&lt;p&gt;目前网上流传着一个段子，说算法工程师实际上就是 SQL boy，数据分析师是 PPT girl。当然艺术来源于现实，实际上的我们真的有很多时间在写 SQL 出数据，或者是针对 bad case 做数据的进一步分析。&lt;/p&gt;

&lt;p&gt;这不，近期这边接到的一个需求就是对玩家的某项行为进行统计。一般来讲，掌握基本 SQL 的技巧，这些需求的难度都不大。但是这个需求需要将玩家用户的多个重叠日期进行拉伸去重。这一下可难到大伙儿。在自个儿思考无果，团队讨论之后也没啥直接的办法。&lt;/p&gt;

&lt;p&gt;在网上搜索一番后，很多都不是很对应。不过好在几轮筛选，找到了一个类似的需求。原文链接在这里：&lt;a href=&#34;https://stewashton.wordpress.com/2015/06/08/merging-overlapping-date-ranges/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;🔗&lt;/a&gt;。为了方便后来的人，在这里做个分析记录，以及后面举一反三该怎么做。毕竟这些东西很少出现在教程和课本里，但是当业务方有这个需求的时候，常常又很紧急，容不得细思慢想。&lt;/p&gt;

&lt;h2 id=&#34;问题定义&#34;&gt;问题定义：&lt;/h2&gt;

&lt;p&gt;在解决一个问题之前，我们需要先明确定义问题。这里的问题是对多个重叠日期，用 SQL 将其进行去重，并在 HIVE 环境中使用。&lt;/p&gt;

&lt;h3 id=&#34;对于日期情况的定义&#34;&gt;对于日期情况的定义&lt;/h3&gt;

&lt;p&gt;这里采用穷举法，可以得出以下13类情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;问题简化&#34;&gt;问题简化&lt;/h3&gt;

&lt;p&gt;解决问题的核心是简化问题。这个问题看起来情况众多，实际上，对于我们的任务，只有两种情况：一个是两个日期有重叠；一个是两个日期没有重叠。&lt;/p&gt;

&lt;p&gt;对于不同的情况，要做不同的处理。重叠日期取最大最小日期即可，非重叠的分段取。剩下的即是通过工具去实现逻辑。&lt;/p&gt;

&lt;h2 id=&#34;数据准备&#34;&gt;数据准备&lt;/h2&gt;

&lt;p&gt;这里采用原作的方式定义数据，创建出上面的13中情况。实际上，如果你的格式和下面的类似，做出对应的调整即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop table t purge;
create table t (
  test_case varchar2(32) not null,
  start_date date not null,
  end_date date not null
);
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;01:precedes&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;02:meets&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;03:overlaps&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;04:finished by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;05:contains&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;06:starts&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;07:equals&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;08:started by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;09:during&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;10:finishes&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;11:overlapped by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;02&#39;,&#39;DD&#39;),to_date(&#39;03&#39;,&#39;DD&#39;));
Insert into t values (&#39;12:met by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;03&#39;,&#39;DD&#39;),to_date(&#39;04&#39;,&#39;DD&#39;));
Insert into t values (&#39;13:preceded by&#39;,to_date(&#39;01&#39;,&#39;DD&#39;),to_date(&#39;02&#39;,&#39;DD&#39;));
commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义出来的数据如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_sample.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;with grp_starts as (
  select test_case, start_date, end_date,
  case
    when start_date &amp;gt; max(end_date) over(
      partition by test_case order by start_date, end_date
      rows between unbounded preceding and 1 preceding
    )
    then 1 else 0
  end grp_start
  from t
)
, grps as (
  select test_case, start_date, end_date,
  sum(grp_start) over(
    partition by test_case order by start_date, end_date
    rows between unbounded preceding and current row
  ) grp
  from grp_starts
)
select test_case,
min(start_date) start_date,
max(end_date) end_date
from grps
group by test_case, grp
order by 1, 2;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/merge_date/date_merge_result.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里的的核心思想同上：&lt;strong&gt;判断日期是否重叠，重叠日期取最大最小的日期，非重叠日期分段取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里使用了 &lt;code&gt;with&lt;/code&gt; 技巧，通过该技巧，将数据临时存储至内存，加速了执行速度。这句话是网上能直接搜到的，但实际上它还有另一个功能上的作用。即抛开性能作用来说，&lt;code&gt;with&lt;/code&gt; 语法能够对先前的查询结果进行下一步的处理。这意味着不用频繁的建立中间表，省去空间或是简化了逻辑的复杂度。&lt;/p&gt;

&lt;p&gt;这里主要分为三段：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;判断日期是否重叠：对数据以 test_case 为划分依据，按开始日期和结束日期排序。比较当前开始日期和之前的结束日期，若开始日期大于最大的结束日期，说明两日期无重叠，grp_start 标志位记为1，反之记为0。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对相邻重叠日期做区分：按同样的划分排序方式。对当前日期及以前的 grp_start 求和，由于重叠日期被标记为0，因而最后相邻重叠日期的 grp 标志位将相同，其余日期各不相同。起到区分不重叠日期，合并重叠日期的作用。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;分组选取最大最小值，得到结果：按 test_case 与 grp 分组，选取各组最小和最大的日期，最后按第一列和第二列排序，得到目标结果。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;小结：通过拆分的思想+窗口函数的帮助，出色完成组织交代的任务，在 HIVE 中实现了合并重叠日期这一任务。但同时也要注意，在功能保证的同时，该脚本如同算法一样，也是有边界的。比如当 end_date 为空时，将会出现错误。这种情况最好先把空值填充为特殊值 ‘9999-12-31’，结束后再转换为空值&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在 HIVE 中合并重叠日期，一开始看起来很难，但实际上学会分析问题，分解问题，简化问题，其实不难。网上有很多有用的资源，要学会合理利用。在实现基本需求的同时，给自己留些时间，深挖背后的原理，将会给自己、同时也是给组织带来持续性的效率提升。&lt;/p&gt;

&lt;p&gt;比如：搞完这一套后，重写祖传代码不太现实，但对于新的需求，可能会思考 &lt;code&gt;with&lt;/code&gt; 语法带来的好处，将其运用到业务中去，减少中间表冗余，简化逻辑，增强 sql 代码可读性。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A/B test 揭秘之什么是 A/B test</title>
      <link>https://kuhungio.me/2019/abtest/</link>
      <pubDate>Fri, 24 May 2019 09:02:00 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/abtest/</guid>
      <description>

&lt;p&gt;此文总结自 Udacity 的课程：A/B test，详细而系统地讲述了 Google，Amazon 以及 Netflix 等公司是如何在商业问题中设计 A/B test 并评估效果的，对于国内的业务也有很强的参考意义。这里是总结的的一部分：什么是 A/B test，讲述 A/B Test 的定义、适用范围以及和传统方法的异同。指标选择、实验设计与评估将在后面陆续放出。&lt;/p&gt;

&lt;h2 id=&#34;a-b-概览&#34;&gt;A/B 概览&lt;/h2&gt;

&lt;h3 id=&#34;q-什么是-a-b-test&#34;&gt;Q：什么是 A/B test？&lt;/h3&gt;

&lt;p&gt;A：A/B test 是一种用来测试新产品或新功能的在线测试常规方法。一般分为两组用户，一组对照组，一组实验组。对照组采用已有的产品或功能，实验组采用新功能。要做的是找到他们的不同反应，并以此确定哪个版本更好。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-是否有适用范围-还是说所有情况都适用&#34;&gt;Q：A/B test 是否有适用范围，还是说所有情况都适用？&lt;/h3&gt;

&lt;p&gt;A：A/B test 能帮助你爬上前面的山峰，但如果想弄清楚是爬这座还是另一座，A/B test 可能不太有效。A/B test 能对很大范围的事情进行测试。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如：

&lt;ul&gt;
&lt;li&gt;亚马逊个性化推荐的 A/B test，发现个推能显著提升收益。&lt;/li&gt;
&lt;li&gt;领英对首页流排序的测试，谷歌的搜索广告排名。&lt;/li&gt;
&lt;li&gt;此外还可以对用户难以察觉的东西进行测试，如网站响应速度。亚马逊在07年发现：页面每增加100ms延迟，收入将会下降1个百分点。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;q-a-b-test-不能做什么事情&#34;&gt;Q：A/B test 不能做什么事情？&lt;/h3&gt;

&lt;p&gt;A：上线新的版本，带来完全不同的交互体验；或是低频长周期的产品；以及 A/B test 并不能发现被遗漏了什么。&lt;/p&gt;

&lt;p&gt;测试新的交互体验时，A/B test 可能不太奏效。原因有两个：一、厌恶改变，不是每个人都喜欢改变，这可能导致用户的厌恶和抵触情绪。二、新奇效应，对于新鲜事物，用户可能会挨个尝试所有东西。&lt;/p&gt;

&lt;p&gt;于此同时，这里会有两个问题，一个是你的比较基准是什么？另一个是需要花多少时间得出结论？举个例子：像低频的房屋租赁，在测试推荐流的时候，很难确定用户是为啥回来的。因为这要花的时间太长了，也许是半年，甚至是更久。&lt;/p&gt;

&lt;p&gt;A/B test 无法告诉你是否有遗漏。当我们在某个产品测试信息推荐流时，仅凭 A/B test，无法知道是否该给这个用户推荐地理信息的资讯。于此同时，也无法确定别的产品是否需要推荐流。&lt;/p&gt;

&lt;h3 id=&#34;q-对于-a-b-test-难以胜任的事情-该如何解决&#34;&gt;Q：对于 A/B test 难以胜任的事情，该如何解决？&lt;/h3&gt;

&lt;p&gt;A：通过其它数据源来补充，对日志进行分析假设验证。或是通过其它技术，如用户研究来定性分析。&lt;/p&gt;

&lt;h3 id=&#34;q-a-b-test-的历史是什么样的&#34;&gt;Q：A/B test 的历史是什么样的？&lt;/h3&gt;

&lt;p&gt;A：最先使用 A/B test 的，可能是农业领域。人们将土地分为不同部分，测试哪块地适合哪种作物作物或是作物如何生长。在科研领域。假设检验是确定创新的关键方法。医学上的 A/B test 被称为临床试验，通过此种方法来确定新的治疗方法是否有效。&lt;/p&gt;

&lt;h3 id=&#34;q-传统实验和在线的-a-b-test-有何异同呢&#34;&gt;Q：传统实验和在线的 A/B test 有何异同呢？&lt;/h3&gt;

&lt;p&gt;A：在线上，拥有更多的数据，但是分辨率低。像传统医学试验或用户体验研究，对象可能有10个、50个或100个，对每个参与者的基本信息都很了解。但在线上，我们的用户可能是数百万、上千万的点击交互行为，我们无法确定数据的另一端是谁。是一个人还是几个人，是网吧学校还是别的什么。通过 A/B test，目的是确认用户是否喜欢这个新产品或新功能。所以做 A/B test 的人的目标是设计一个合理且可复现的结果，用来帮助决策。A/B test 无处不在，FLAG 都在不同程度地使用 A/B test，甚至有专门地公司帮助小公司提供这些服务。&lt;/p&gt;

&lt;p&gt;##总结&lt;/p&gt;

&lt;p&gt;通过以上内容，我们知道了 A/B test的定义，明白他是为了更好决策的系统性方法。该方法在很多场景都适用，但在对于一些大的改动和低频次长周期的产品功能，A/B test并不能很好解决。通过数据互补，用户调研等方法，我们一定程度上弥补了 A/B test的短板。相较于传统的控制变量方法，线上的 A/B test数据量更大，但也难以确定真实的数据产生者。这些问题，在使用 A/B test时都要考虑。&lt;/p&gt;

&lt;p&gt;A/B test到底如何做，指标如何设定，如何说明新产品或新功能确实有效或无效？带着这些疑问，我们将进入到下期的内容。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>数据从业者必读的7本书 Booklist for DE</title>
      <link>https://kuhungio.me/2019/book-list-for-ds/</link>
      <pubDate>Tue, 07 May 2019 23:34:54 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/book-list-for-ds/</guid>
      <description>

&lt;p&gt;之前逛论坛，或者学习网站，看到很多人喜欢推荐书。自己早些时候也是这样，但是只 mark，却很少去看。如今作为一名社会人，虽说工作之余时间少了很多，但业余仍在坚持阅读。其中，支撑学习动力的一本书便是：《穷查理宝典》。书中查理·芒格提到的多学科思维，以及复利思维，一直在影响我的交友、做事和看问题的方式。&lt;/p&gt;

&lt;p&gt;有关注某校友的公众号，他是做爬虫和可视乎的。某天在推荐 Python 学习资料。封面看着挺美，点开一看，书单质量实属一般。倒像是接的推广，很多估计他自己都没有看过，不太负责任。于是乎，便萌生了出一期书单的想法。而定位，便是数据科学家、数据挖掘工程师、算法工程师的书单。&lt;/p&gt;

&lt;p&gt;首先声明，这份书单不是单纯的技术向书籍，不会有什么西瓜书或是算法导论之类的。他们也是好书，但不会出现在这里。因为在工作中大家就会发现，技术只是工具，好的工匠 != 熟练使用工具的熟练工。看见大局，同时有跨学科的思维，能够从事物的本质去出发，理解和思考它，也很重要。&lt;/p&gt;

&lt;p&gt;作为一个数据挖掘工程师，以下是推荐的核心7本书单。为什么是7本呢？因为人一下子能记住的东西是有限的，记不住就忍不住收藏。收藏了就几乎等于很少看了。收藏一时爽，一直收藏一直爽。所以，书单从原来的二十几本变为了现在的7本。&lt;/p&gt;

&lt;p&gt;这7本书的逻辑是从底层到高层。底层是构成我们一部分的东西，是我们的认知。中间则是我们的技能。而高层，则是我们的自我实现。最终又回到我们的认知。简单来说，就是从软技能到硬实力，再到软实力。&lt;/p&gt;

&lt;h2 id=&#34;通识与概念&#34;&gt;通识与概念&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Top 7&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通识趣味读本&amp;ndash;《赤裸裸的统计学》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该书讲了很多身边的例子，让人对统计学的应用有一个初步认识。且是一个检验兴趣点的很好方式。如果你对这些东西都不是很感冒，那么可能这行除了薪水，没有别的能吸引你。后面的内容也就没有读的必要了。&lt;/p&gt;

&lt;p&gt;除了例子以外，本书也有很多反常识反直觉的东西。诸如统计数字会撒谎、因果关系与相关关系的混淆。黑天鹅、三门问题等地很考验一个人的智商。看完之后有醍醐灌顶的感觉。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《大教堂与旧集市》、《编码》等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Top 6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大而全&amp;ndash;《信息论、推理与学习算法》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果你对第一本书的内容感兴趣，想要深入了解背后的原理，那么这本书不容错过。这本书更像是一本大百科全书，涵盖了传统信息论到最新算法的大部分内容。从熵、到编码、再到概率与推理，最后到常见的模型和神经网络。是一本适合高年级学生或者专人人员的查阅宝典。&lt;/p&gt;

&lt;p&gt;这本书说实话有些厚重，限于版面，如果只推荐一本，会推荐它。当然如果想看更多元的内容，附加的书籍📚可不容错过。由于本身的专业偏传统工科，编码、信息压缩也有接触，因而过渡起来不会很困难。&lt;/p&gt;

&lt;p&gt;与之互补的书还有《推荐系统实战》、《信息检索导论》、《集异壁》等。&lt;/p&gt;

&lt;h2 id=&#34;工具与思想&#34;&gt;工具与思想&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;吃饭工具&amp;ndash;《SQL 必知必会》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作为一个工程师，常自嘲自己是 sql boy。那是因为，在实际生产环境中，数据处理花了很大事件。大部分时间都是和sql 打交道。做过比赛的同学可能知道，数据处理、特征提取是很关键的一步。&lt;/p&gt;

&lt;p&gt;在企业中，这一情况越发突出。有时候原始数据分散在各个地方，连规整的数据都没有。因而需要掌握一定的 sql 技能。虽然有些专业会学习数据库这一门课程，但这本书可以起到一个梳理作用，同时也有一些小的注意点。&lt;/p&gt;

&lt;p&gt;掌握了这本书的同学，推荐《 SQL 反模式》，讲 sql 范式更进一步。虽说是给数据库开发人员看的，但是知其然并知其所以然，也是很好的。&lt;/p&gt;

&lt;p&gt;如果想看到更大的图景，那么 ddia 一定不容错过。ddia 在一年前就很火，网上也有他的公开中文翻译。讲解整个数据系统很透彻。适合各类程序开发人员阅读。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 4&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《利用 python 进行数据分析》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书也算是启蒙书。涉及的内容基本面很广，该有的都有了。介绍了 python 在数据科学领域的基础知识，同时也有案例解析。&lt;/p&gt;

&lt;p&gt;读完这本书，参加小型的数据挖掘、机器学习类的比赛不会存在门槛了。与此类似的书还有《集体智慧编程》，以及近期比较火的 hands on ml。&lt;/p&gt;

&lt;h2 id=&#34;思考与呈现&#34;&gt;思考与呈现&lt;/h2&gt;

&lt;p&gt;前面都是技术向、原理向的内容。是不是掌握了以上内容，就可以美滋滋的享受生活了呢？其实这是很多软件从业人员、甚至是工科同学的一个共同误区。觉得把我的技术学好了，就万事大吉，酒香不怕巷子深了。在这里千万不要忽略掉你的软实力。&lt;/p&gt;

&lt;p&gt;在某些头部公司、ppt 文化盛行。虽然有些走极端，这其实也是一种现状。从原则上来讲，只讲 PPT 画大饼而不做事是不对的，所以他们被放在最后讲。与此同时要记住，硬币的反面也是不对的，只埋头苦干，而不去扩大影响力，事情的价值就很可能被低估。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《金字塔原理》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主要是逻辑性思维的呈现原则，以及最核心的一点站在对方的角度看问题。书中罗列了很多报告撰写、演讲呈现的方法技巧。比如自上而下思考，自下而上表达，横向概括、纵向分类，独立穷尽。这些机巧用在你的日常生活中的表达和演讲，将会大大加分。&lt;/p&gt;

&lt;p&gt;与之类似的书还有《演说之禅》，以及稍微和职业更靠近的《数据可视化之美》。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;top 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;《咨询的奥秘》&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/booklist/book_6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这本书是集中在讲思维方式的。咨询也算是数据科学家的一重身份。如何看待问题，如何给出建议，这本书都有很好的示范。&lt;/p&gt;

&lt;p&gt;与之类似的有《你的灯亮着吗》、《学会提问》。&lt;/p&gt;

&lt;h2 id=&#34;实践出真知&#34;&gt;实践出真知&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;top 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;实践&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;top 1 没有书，top 1 是实践。收藏了那么多资料，不如潜心研究一两个案例，去实践来的快。追踪学术前沿，去做一些实践；或者是对一些好玩的东西，做一些 demo，收获不会比上面的阅读小。&lt;/p&gt;

&lt;p&gt;如果想要更进一步，那就试着对外输出：无论是看到的知识，或者是方法论，抑或是工具使用技巧，还是对自己有帮助的 demo。这些都能很好的锻炼思维，让人更进一步。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;以上是给大家推荐的从业者的7本书，都是经过本人检验的。从通识到基础概念，从工具到学科思想，最后又回到普罗大众，思考和呈现我们的工作。希望能帮助诸位更进一步，在职业生涯上大放光彩。&lt;/p&gt;

&lt;p&gt;豆瓣书单 &lt;a href=&#34;https://www.douban.com/doulist/113972160/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.douban.com/doulist/113972160/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>

&lt;h1 id=&#34;深度强化学习技巧-hacks-for-training-deep-rl&#34;&gt;深度强化学习技巧 hacks for training deep RL&lt;/h1&gt;

&lt;p&gt;这是一篇旧文，&lt;a href=&#34;http://joschu.net/?utm_source=kuhungio&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;John Schulman&lt;/a&gt; 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。  &lt;/p&gt;

&lt;h2 id=&#34;测试新算法的技巧&#34;&gt;测试新算法的技巧&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;简化问题，使用低维变量。

&lt;ul&gt;
&lt;li&gt;使用类似只有角度和速度两个变量的 &lt;a href=&#34;https://gym.openai.com/envs/Pendulum-v0&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Pendulum problem&lt;/a&gt; 问题。&lt;/li&gt;
&lt;li&gt;这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。&lt;/li&gt;
&lt;li&gt;当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;构造一个 demo 来测试你的算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。&lt;/li&gt;
&lt;li&gt;这样能够轻易地发现那里出了问题。&lt;/li&gt;
&lt;li&gt;注意：不要在这样的小问题上过分的尝试。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在熟悉的场景中测试&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随着时间的推移，你将能预估训练所需的时间。&lt;/li&gt;
&lt;li&gt;明白你的奖赏是如何变化的。&lt;/li&gt;
&lt;li&gt;能够设定一个基线，以便让你知道相对过去改进了多少。&lt;/li&gt;
&lt;li&gt;作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;快速上手新任务的技巧&#34;&gt;快速上手新任务的技巧&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;简化问题

&lt;ul&gt;
&lt;li&gt;从简单的开始，直到回到问题。&lt;/li&gt;
&lt;li&gt;途径1： 简化特征空间

&lt;ul&gt;
&lt;li&gt;举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。&lt;/li&gt;
&lt;li&gt;一旦起步，逐步还原问题直到解决问题。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;途径2：简化奖赏函数

&lt;ul&gt;
&lt;li&gt;简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。&lt;/li&gt;
&lt;li&gt;比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;将一个问题转化为强化学习的技巧&#34;&gt;将一个问题转化为强化学习的技巧&lt;/h2&gt;

&lt;p&gt;可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;第一步：将这个问题使用随机策略可视化出来。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;看看那些部分吸引了你。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果这个随机策略在某些情况下做了正确的事，那么很大概率，强化学习也可以做到。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;策略的更新将会发现这里面的行为，并促使稳定下来。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果随机策略永远都做不到，那么强化学习也不可能。
   &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确保可观测&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;确保你能够掌控系统，且给 agent 的也是同样的系统环境。

&lt;ul&gt;
&lt;li&gt;举个例子： 亲自查看处理过图片，以确保你没有移出掉关键信息或者是在某种程度上阻碍算法。
 &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;确保所有的事物都在合理的尺度&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;经验法则：

&lt;ul&gt;
&lt;li&gt;观测环境： 确保均值为0，方差为1。&lt;/li&gt;
&lt;li&gt;奖赏： 如果你能控制它，就把他缩放到一个合理的维度。&lt;/li&gt;
&lt;li&gt;在所有的数据上都做同样的处理。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;检查所有的观测环境以及奖赏，以确保没有特别离奇的异常值。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;建立一个好的基线&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一开始并不清楚哪些算法会起作用，所以设定一系列的基线（从其他方法）。

&lt;ul&gt;
&lt;li&gt;交叉熵&lt;/li&gt;
&lt;li&gt;策略更新&lt;/li&gt;
&lt;li&gt;一些类型的 Q-learning 算法: &lt;a href=&#34;https://github.com/openai/baselines&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;OpenAI Baselines&lt;/a&gt; 或者 &lt;a href=&#34;https://github.com/rll/rllab&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;RLLab&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;复现论文&#34;&gt;复现论文&lt;/h2&gt;

&lt;p&gt;某些时候（经常的事），复现论文结果特别困难。有如下一些技巧：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用比预计更多的样本。&lt;/li&gt;
&lt;li&gt;策略正确，但又不完全正确。

&lt;ul&gt;
&lt;li&gt;尝试让模型运行更久一点。&lt;/li&gt;
&lt;li&gt;调整超参数以达到公开的效果。&lt;/li&gt;
&lt;li&gt;如果想让他在所有数据上都奏效，使用更大的 batch sizes。

&lt;ul&gt;
&lt;li&gt;如果 batch size 太小，噪声将会压过真正有用的信号。&lt;/li&gt;
&lt;li&gt;比如： TRPO，作者使用了一个特别小的 batch size，然后不得不训练10万次迭代。&lt;/li&gt;
&lt;li&gt;对于 DQN，最好的参数：一万次迭代，10亿左右的缓存存储。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;对于训练中的一些处理&#34;&gt;对于训练中的一些处理&lt;/h2&gt;

&lt;p&gt;检查你的训练是否正常：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查每个超参数的鲁棒性&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果一个算法太过敏感，那么它可能不太鲁棒，并且不容乐观。&lt;/li&gt;
&lt;li&gt;有些时候，某个策略生效，可能仅仅是因为巧合而已，它并不足以推广。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;关注优化过程是否正常的指标&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;变动情况&lt;/li&gt;
&lt;li&gt;关注目标函数是否正确

&lt;ul&gt;
&lt;li&gt;是否预测正确？&lt;/li&gt;
&lt;li&gt;它的返回是否正确？&lt;/li&gt;
&lt;li&gt;每次的更新有多大？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;一些标准的深度神经网络的诊断方法&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有一套能够连续记录代码的系统&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;有成型的规则。&lt;/li&gt;
&lt;li&gt;注意过去所作的所有尝试。

&lt;ul&gt;
&lt;li&gt;有些时候，我们关注一个问题，最后却把注意力放在了其他问题上。&lt;/li&gt;
&lt;li&gt;对于一个问题，很容易过拟合。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;有一大推之前时不时测试的基准。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有时候会觉得系统运行正常，但很可能只是巧合。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如： 有3套算法处理7个任务，可能会有一个算法看起来能很好地处理所有问题，但实际上，它们不过是一套算法，不同的仅仅是随机种子而已。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用不同的随机种子&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;运行多次取平均。&lt;/li&gt;
&lt;li&gt;在多个种子的基础上运行多次。

&lt;ul&gt;
&lt;li&gt;如果不这样做，那你很有可能是过拟合了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;额外的算法修改可能并不重要&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大部分的技巧都是在正则化处理某些对象，或者是在改进你的优化算法。&lt;/li&gt;
&lt;li&gt;许多技巧有相同的效果&amp;hellip;&amp;hellip;所以，你可以通过移除它们，来简化你的算法（很关键）。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;简化你的算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将会取得更好的泛化效果。
   &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;自动化你的实验&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不要整天盯着你的代码读取和写入数据。&lt;/li&gt;
&lt;li&gt;将实验部署在云端并分析结果。&lt;/li&gt;
&lt;li&gt;追踪实验与结果的框架：

&lt;ul&gt;
&lt;li&gt;大部分使用 iPython notebooks。&lt;/li&gt;
&lt;li&gt;数据库对于存储结果来说不是很重要。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总的训练策略&#34;&gt;总的训练策略&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;数据的白化与标准化（一开始就这样做，对所有数据）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;训练数据（Obervation）：

&lt;ul&gt;
&lt;li&gt;计算均值与标准差，然后做标准化转变。&lt;/li&gt;
&lt;li&gt;对于全体数据（不仅仅是当前的数据）。

&lt;ul&gt;
&lt;li&gt;至少它减轻了随时间的变化波动情况。&lt;/li&gt;
&lt;li&gt;如果不断地改变对象的话，可能会使优化器迷糊。&lt;/li&gt;
&lt;li&gt;缩放（仅最近的数据）意味着你的优化器不知道这个情况，训练将会失败。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;奖赏（Rewards）：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;缩放但不要转变对象。

&lt;ul&gt;
&lt;li&gt;影响 agent 的继续下去的可能。&lt;/li&gt;
&lt;li&gt;将会改变问题（你想让它持续多久）。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;归一化目标（Standardize targets）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;与 rewards 相同。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PCA 白化&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以起作用。&lt;/li&gt;
&lt;li&gt;开始时的时候要看看它是否真的对神经网络起作用。&lt;/li&gt;
&lt;li&gt;大规模的缩放（-1000，1000）到（-0.001，0.001）必然会使学习减缓。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;衰减因子的调参&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;判断分配多少权重。&lt;/li&gt;
&lt;li&gt;举个例子：如果因子是0.99，那么你将忽略100步以前的事情，这意味着某种程度的短视。

&lt;ul&gt;
&lt;li&gt;最好是看看对应多少的现实时间。

&lt;ul&gt;
&lt;li&gt;直觉上，我们通常在强化学习中离散时间。&lt;/li&gt;
&lt;li&gt;换句话说，100步是指3秒前吗？&lt;/li&gt;
&lt;li&gt;在这个过程中发生了什么？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果是用于 fx 估计的策略更新 TD 算法，gamma 可以选择靠近1（比如0.999）。

&lt;ul&gt;
&lt;li&gt;算法将非常稳健。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;观察问题是否真的能被离散化处理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;例如：在一个游戏有跳帧。&lt;/li&gt;
&lt;li&gt;作为一个人类，你能控制还是不能控制。&lt;/li&gt;
&lt;li&gt;查看随机情况是怎么样的。

&lt;ul&gt;
&lt;li&gt;离散化程度决定了你的随机布朗运动能有多远。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果连续性地运动，往往模型会走很远。&lt;/li&gt;
&lt;li&gt;选择一个起作用的时间离散化分。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;密切关注返回的 episode&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不仅仅是均值，还包括极大极小值

&lt;ul&gt;
&lt;li&gt;最大返回是你的策略能做到的最好程度&lt;/li&gt;
&lt;li&gt;看看你的策略是否工作正常？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;查看 episode 时长（有时比 episode reward 更为重要）

&lt;ul&gt;
&lt;li&gt;在一场游戏中你场场都输，从未赢过，但是 episode 时长可以告诉你是不是输得越来越慢&lt;/li&gt;
&lt;li&gt;一开始可能看见 episode 时长有改进，但 reward 无反应&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;策略优化诊断&#34;&gt;策略优化诊断&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;仔仔细细地观察 entropy&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;action 层面的 entropy

&lt;ul&gt;
&lt;li&gt;留意状态空间 entropy 的变化，虽然没有好的计量办法&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果快速地下降，策略很快便会固定然后失效&lt;/li&gt;
&lt;li&gt;如果没有下降，那么这个策略可能不是很好，因为它是随机的&lt;/li&gt;
&lt;li&gt;通过以下方式补救：

&lt;ul&gt;
&lt;li&gt;KL penalty

&lt;ul&gt;
&lt;li&gt;使 entropy 远离快速下降&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;增加 entropy bonus&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如何测量 entropy

&lt;ul&gt;
&lt;li&gt;对于大部分策略，可以采用分析式方法

&lt;ul&gt;
&lt;li&gt;对于连续变量，通常使用高斯分布，这样可以通过微分计算 entropy&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;观察 KL 散度&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;观察 KL 散度的更新尺度&lt;/li&gt;
&lt;li&gt;例如：

&lt;ul&gt;
&lt;li&gt;如果 KL 是0.01，那它是相当小的。&lt;/li&gt;
&lt;li&gt;如果是10，那它又非常的大。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过基线解释方差&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查看价值函数是不是好的预测或者给予回报

&lt;ul&gt;
&lt;li&gt;如果是负数，可能是过拟合了或者是噪声

&lt;ul&gt;
&lt;li&gt;可能需要超参数调节
 &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;初始化策略&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;非常重要（比监督学习更重要）&lt;/li&gt;
&lt;li&gt;最后一层取0或者是一个很小的值来最大化 entropy

&lt;ul&gt;
&lt;li&gt;初始最大化随机 exploration&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;q-learning-策略&#34;&gt;Q-Learning 策略&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;留意 replay buffer 存储的使用情况&lt;/li&gt;

&lt;li&gt;&lt;p&gt;你可能需要一个非常大的 buffer，依代码而定&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;手边常备 learing rate 表&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果收敛很慢或者一开始有一个很慢的启动&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;保持耐心，DQNs 收敛非常慢&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;Translated by &lt;a href=&#34;https://github.com/kuhung&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung&lt;/a&gt; 2017/08/29&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/deepRL/deepRL.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号【谷粒先生】，回复【强化学习】获取 PPT 原版&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>机器学习模型部署--打通前后端任督二脉</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;h3 id=&#34;学历与定位&#34;&gt;学历与定位&lt;/h3&gt;

&lt;p&gt;近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个小本就工作的人，没有较为丰富的实战经验，有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/flask_vue_ML/mobile.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;模型算法的实用主义&#34;&gt;模型算法的实用主义&lt;/h3&gt;

&lt;p&gt;机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 &lt;a href=&#34;https://github.com/kuhung/flask_vue_ML&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung/flask_vue_ML&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;后端-flask&#34;&gt;后端 flask&lt;/h2&gt;

&lt;h3 id=&#34;相关依赖的安装&#34;&gt;相关依赖的安装&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;核心函数&#34;&gt;核心函数&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;导入函数包&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flask import Flask, jsonify, request
from flask_cors import CORS # 做跨域的准备
from flask import session # 追踪客户端会话

from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类
from flair.data import Sentence

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;准备工作&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = Flask(__name__) # 声明准备
app.secret_key = &amp;quot;super_secret_key&amp;quot;

CORS(app)
classifier = TextClassifier.load_from_file(&#39;models/best-model.pt&#39;) # 模型加载

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;配置 flask 的路由&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 根路由配置
@app.route(&#39;/&#39;, methods=[&#39;GET&#39;])
def index():
    return jsonify(&amp;quot;welcome to Kuhung API&amp;quot;)

# GET 方法，这里 session 的作用是追踪客户端会话，防止重复请求模型
@app.route(&#39;/api/tasks&#39;, methods=[&#39;GET&#39;])
def get_result():
    result = []
    try:
        data_result = session[&#39;my_result&#39;]
        result.append ({&#39;title&#39;: data_result[&#39;title&#39;], &#39;tag&#39;: data_result[&#39;tag&#39;] })
    except:
        result.append ({&#39;title&#39;: &#39;The txt you input&#39;, &#39;tag&#39;: &#39;spam or ham&#39; })
    return jsonify(result)

# POST 方法
@app.route(&#39;/api/task&#39;, methods=[&#39;POST&#39;])
def input_predict_text():

    title = request.get_json()[&#39;title&#39;] # 解析请求

    sentence = Sentence(title) # 对请求做数据预处理
    classifier.predict(sentence) # 调用模型，做预测，返回带标签的数据

    text = sentence.to_plain_string() # 解析出原始数据
    label = sentence.labels[0] # 解析出标签
    result = {&#39;title&#39; : text, &#39;tag&#39; : label.value} # 拼接成字典格式
    session[&#39;my_result&#39;] = result # 存入 session ，以减少重复请求对模型的压力
    
    return jsonify(result) # 返回 json 格式的数据

if __name__ == &#39;__main__&#39;:
    app.run(debug=True)  # 开发过程中开启 debug 调试模式
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动服务&#34;&gt;启动服务&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;python app.py&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;前端-vue&#34;&gt;前端 vue&lt;/h2&gt;

&lt;p&gt;前端采用 Vue 框架，与后端分离。使用 Webpack 进行资源管理与打包。&lt;/p&gt;

&lt;h3 id=&#34;相关依赖的安装-1&#34;&gt;相关依赖的安装&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install -g vue-cli
npm install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;自定义组件&#34;&gt;自定义组件&lt;/h3&gt;

&lt;p&gt;通过 &lt;code&gt;vue init webpack flask_vue_ML&lt;/code&gt; 后，进入项目文件夹，增加自定义内容。&lt;/p&gt;

&lt;h4 id=&#34;index-html&#34;&gt;index.html&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width,initial-scale=1.0&amp;quot;&amp;gt;
    &amp;lt;title&amp;gt;exposemodel&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;!-- 其它文件会自动注入这里 --&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;src-文件夹&#34;&gt;src 文件夹&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;components

&lt;ul&gt;
&lt;li&gt;Home.vue  // 自定义组件，增加&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;router

&lt;ul&gt;
&lt;li&gt;index.js  // 路由，修改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;App.vue  // 主组件，修改&lt;/li&gt;
&lt;li&gt;main.js  // 入口文件，修改&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##### Home.vue&lt;/p&gt;

&lt;p&gt;这里定义页面的基本样式，以及获取数据的逻辑。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vue&#34;&gt;&amp;lt;template&amp;gt;
  &amp;lt;div id=&amp;quot;todo-list-example&amp;quot; class=&amp;quot;container&amp;quot;&amp;gt;
    &amp;lt;!-- 我是进度条，最上方的 --&amp;gt;
    &amp;lt;vue-progress-bar&amp;gt;&amp;lt;/vue-progress-bar&amp;gt;
    &amp;lt;div class=&amp;quot;row&amp;quot;&amp;gt;
      &amp;lt;div class=&amp;quot;col-md-6 mx-auto&amp;quot;&amp;gt;
        &amp;lt;h1 class=&amp;quot;text-center&amp;quot;&amp;gt;Natural Language Processing (NLP)&amp;lt;/h1&amp;gt;
        &amp;lt;form v-on:submit.prevent=&amp;quot;addNewTask&amp;quot;&amp;gt;
          &amp;lt;label for=&amp;quot;tasknameinput&amp;quot;&amp;gt;Spam Classification&amp;lt;/label&amp;gt;
          &amp;lt;input v-model=&amp;quot;taskname&amp;quot; type=&amp;quot;text&amp;quot; id=&amp;quot;tasknameinput&amp;quot; class=&amp;quot;form-control&amp;quot; placeholder=&amp;quot;Enter Sentence&amp;quot;&amp;gt;
          &amp;lt;button type=&amp;quot;submit&amp;quot; class=&amp;quot;btn btn-success btn-block mt-3&amp;quot;&amp;gt;
            Submit
          &amp;lt;/button&amp;gt;
        &amp;lt;/form&amp;gt;
          
&amp;lt;!-- 省略表格定义内容 --&amp;gt;


&amp;lt;script&amp;gt;
// 这里解决跨域请求问题，向后端发起请求
import axios from &#39;axios&#39;

export default {
  data () {
    return {
      textClassify: [],
      id: &#39;&#39;,
      taskname: &#39;&#39;,
      isEdit: false
    }
  },
  mounted () {
    this.getTasks()
  },
    
// 省略进度条内容
    
// 请求任务相关操作
    getTasks () {
      axios({ method: &#39;GET&#39;, url: &#39;/api/tasks&#39; }).then(
        result =&amp;gt; {
          console.log(result.data)
          this.textClassify = result.data
        },
        error =&amp;gt; {
          console.error(error)
        }
      )
    },
&amp;lt;/script&amp;gt;
​```
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;index-js&#34;&gt;index.js&lt;/h5&gt;

&lt;p&gt;定义路由，设定访问路径，并将路径和组件关联&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import Vue from &#39;vue&#39;
import Router from &#39;vue-router&#39;
import Home from &#39;@/components/Home&#39;

Vue.use(Router)

export default new Router({
  routes: [
    {
      path: &#39;/&#39;,
      name: &#39;Home&#39;,
      component: Home
    }
  ]
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;app-vue&#34;&gt;App.vue&lt;/h5&gt;

&lt;p&gt;主组件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-vue&#34;&gt;&amp;lt;template&amp;gt;
  &amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;
    &amp;lt;router-view/&amp;gt;
    &amp;lt;!-- 植入一波广告：微信搜索：谷粒先生，关注我的公众号 --&amp;gt;
    &amp;lt;img src=&amp;quot;./assets/wechat.jpg&amp;quot;&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;

&amp;lt;script&amp;gt;
export default {
  name: &#39;App&#39;
}
&amp;lt;/script&amp;gt;

&amp;lt;style&amp;gt;
#app {
  font-family: &#39;Avenir&#39;, Helvetica, Arial, sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  text-align: center;
  color: #2c3e50;
  margin-top: 60px;
}
&amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;main-js&#34;&gt;main.js&lt;/h5&gt;

&lt;p&gt;初始化实例并加载必要插件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// The Vue build version to load with the `import` command
// (runtime-only or standalone) has been set in webpack.base.conf with an alias.
import Vue from &#39;vue&#39;
import App from &#39;./App&#39;
import router from &#39;./router&#39;
import VueProgressBar from &#39;vue-progressbar&#39;
require(&#39;../node_modules/bootstrap/dist/css/bootstrap.css&#39;)

Vue.config.productionTip = false

// 这是进度条
Vue.use(VueProgressBar, {
  color: &#39;rgb(143, 255, 199)&#39;,
  failedColor: &#39;red&#39;,
  height: &#39;10px&#39;
})

/* eslint-disable no-new */
new Vue({
  el: &#39;#app&#39;,
  router,
  components: { App },
  template: &#39;&amp;lt;App/&amp;gt;&#39;
})

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;启动服务-1&#34;&gt;启动服务&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;npm run dev&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;模型-flair&#34;&gt;模型 flair&lt;/h2&gt;

&lt;p&gt;模型这里采用 fair 框架，该框架在 2018 年底发布，易用性和效果都较前方案有了较大提升。这里直接采用官方样例训练好的垃圾邮件分类模型的权重，也就是在上文后端所读取的文件。关注我的公众号：谷粒先生，回复&lt;strong&gt;权重&lt;/strong&gt;，即可获得权重文件🔗链接。&lt;/p&gt;

&lt;h3 id=&#34;模型调用&#34;&gt;模型调用&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类
from flair.data import Sentence

classifier = TextClassifier.load_from_file(&#39;models/best-model.pt&#39;) # 模型加载

sentence = Sentence(title) # 对请求做数据预处理
classifier.predict(sentence) # 调用模型，做预测，返回带标签的数据
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;效果展示&#34;&gt;效果展示&lt;/h2&gt;

&lt;p&gt;本教程针对文本分类这个场景，构建了一套前后端分离的“完整”框架，能够给到一个最直观的感受。当然，这里还有很多优化空间，还有后续部署等事宜没有详细展开，有心的同学可以自行检索学习。通过这套流程，可以在测试服搭建一套实用主义哲学的算法模型。给到领导做展示或是公司内部使用，已经足够。项目地址 &lt;a href=&#34;https://github.com/kuhung/flask_vue_ML&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;kuhung/flask_vue_ML&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;终端端网站访问&#34;&gt;终端端网站访问&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/flask_vue_ML/flask_vue_ml.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;关注微信公众号：谷粒先生，下载权重文件并第一时间获取更新。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;喜欢我的朋友，别忘了点赞 👍、喜欢 ❤ +关注 🔔哦，你的鼓励是对我最大的支持~💪&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>如何设计一套类似视觉中国鹰眼的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>

&lt;p&gt;这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/vgc/vgc 不敢配图.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;“鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。&lt;/p&gt;

&lt;p&gt;爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。&lt;/p&gt;

&lt;p&gt;首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/vgc/vgc 图像工程与相关学科领域的联系与区别.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。&lt;/p&gt;

&lt;p&gt;首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。&lt;/p&gt;

&lt;p&gt;从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。&lt;/p&gt;

&lt;p&gt;第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。&lt;/p&gt;

&lt;p&gt;而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35868882&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;教 AI 学会看图说话：Image Caption&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。&lt;/p&gt;

&lt;p&gt;这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。&lt;/p&gt;

&lt;p&gt;最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。&lt;/p&gt;

&lt;h3 id=&#34;附录&#34;&gt;附录&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://36kr.com/p/5194005&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;视觉中国图片侵权追踪系统曝光：鹰眼系统&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kw.beijing.gov.cn/art/2018/12/27/art_841_75909.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;2018年度市科委第四季度项目(课题)验收公开清单&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://file.finance.sina.com.cn/211.154.219.97:9494/MRGG/CNSESZ_STOCK/2017/2017-4/2017-04-29/3366645.PDF&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;视觉（中国）文化发展股份有限公司 2016 年年度报告&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋&lt;/p&gt;

&lt;p&gt;《基于内容的图象和视频检索》&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hands On Machine Learning in Industry 一文看懂机器学习项目的完整生命周期</title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>

&lt;p&gt;机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。&lt;/p&gt;

&lt;h1 id=&#34;机器学习项目的生命周期&#34;&gt;机器学习项目的生命周期&lt;/h1&gt;

&lt;ol class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;p&gt;问题定义&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 定义问题，并关注大局&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据处理&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 获取数据&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 探索性的数据分析&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 清洗数据，为接下来的模型做准备&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;模型方案&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 探索不同的模型并挑选合适的模型&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 对模型进行微调，并集成为更好的模型&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 解决方案呈现&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;部署维护&lt;/p&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; 部署、监控并维护系统

&lt;br /&gt;&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;定义问题-从大局出发&#34;&gt;定义问题，从大局出发&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;和业务团队一起定义问题目标&lt;/li&gt;
&lt;li&gt;我们的解决方案将会如何发挥作用&lt;/li&gt;
&lt;li&gt;现在的解决方案是什么样的（如果有）&lt;/li&gt;
&lt;li&gt;你将如何定义这个问题（有监督、无监督，在线还是离线）&lt;/li&gt;
&lt;li&gt;结果该如何衡量&lt;/li&gt;
&lt;li&gt;衡量方法是否和商业目标一致&lt;/li&gt;
&lt;li&gt;要达成这一目标，至少的表现该是什么样子的&lt;/li&gt;
&lt;li&gt;类似的问题是什么？有无可复用的经验与工具&lt;/li&gt;
&lt;li&gt;我们有专家知识吗&lt;/li&gt;
&lt;li&gt;你将如何着手解决这个问题&lt;/li&gt;
&lt;li&gt;列出你或者别人目前所作的努力&lt;/li&gt;
&lt;li&gt;如果可能，对假说进行验证&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;获取数据&#34;&gt;获取数据&lt;/h2&gt;

&lt;p&gt;建议：尽量自动化以更容易地方式获取最新的数据&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;列出你所需的数据以及体量&lt;/li&gt;
&lt;li&gt;找寻并记录下获取数据的方式&lt;/li&gt;
&lt;li&gt;检查数据将占据多少空间&lt;/li&gt;
&lt;li&gt;检查是否有法律风险，如有必要请获得许可&lt;/li&gt;
&lt;li&gt;获取许可&lt;/li&gt;
&lt;li&gt;创建工作空间，确保存储足够大&lt;/li&gt;
&lt;li&gt;获取数据&lt;/li&gt;
&lt;li&gt;转换数据的格式以便能够方便操作（不需要改变数据本身）&lt;/li&gt;
&lt;li&gt;确保敏感信息被删除或保护加密（匿名）&lt;/li&gt;
&lt;li&gt;检查数据的大小和类型（时间序列、采样、地理信息等）&lt;/li&gt;
&lt;li&gt;划分测试集，把他放一边，并且不再去动他（防止数据泄露）&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;探索数据&#34;&gt;探索数据&lt;/h2&gt;

&lt;p&gt;建议：在该阶段尽量获取领域专家的意见&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建数据的副本以便做数据探索（如果数据量太大，做降采样处理）&lt;/li&gt;
&lt;li&gt;创建 Jupyter notebook 以便保存探索记录&lt;/li&gt;
&lt;li&gt;研究每个属性及其特征

&lt;ul&gt;
&lt;li&gt;名称&lt;/li&gt;
&lt;li&gt;类型（类别，整型/浮点，有无上下界，文本，结构化等）&lt;/li&gt;
&lt;li&gt;缺失值&lt;/li&gt;
&lt;li&gt;噪声数据（随机数，异常值，四舍五入的误差）&lt;/li&gt;
&lt;li&gt;对本任务可能有用的数据&lt;/li&gt;
&lt;li&gt;分布类型（高斯分布，均匀分布，指数分布）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;对于有监督问题：确定目标对象&lt;/li&gt;
&lt;li&gt;可视化数据&lt;/li&gt;
&lt;li&gt;研究变量间的相关性&lt;/li&gt;
&lt;li&gt;研究你将如何着手解决此问题&lt;/li&gt;
&lt;li&gt;确认比较有希望的解决方案&lt;/li&gt;
&lt;li&gt;确认有用的外部数据&lt;/li&gt;
&lt;li&gt;将以上信息存档记录下来&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;准备数据&#34;&gt;准备数据&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在数据的副本上操作（保持原始数据不被影响）&lt;/li&gt;
&lt;li&gt;将你所作的数据变换写成函数，有以下5个原因

&lt;ul&gt;
&lt;li&gt;便于在本项目的新数据上复用&lt;/li&gt;
&lt;li&gt;便于在别的项目中复用&lt;/li&gt;
&lt;li&gt;快速清洗和准备测试集&lt;/li&gt;
&lt;li&gt;在立项后，能够及时对数据进行处理&lt;/li&gt;
&lt;li&gt;让数据变换过程也能作为超参数的一份子，进行调参&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;数据清洗

&lt;ul&gt;
&lt;li&gt;调整或移除异常值（可选）&lt;/li&gt;
&lt;li&gt;填补缺失值（0，平均数、中位数），或者简单的去掉缺失的样本或特征&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征选择（可选）

&lt;ul&gt;
&lt;li&gt;去掉对本任务无用的信息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征工程，适度

&lt;ul&gt;
&lt;li&gt;连续数值离散化&lt;/li&gt;
&lt;li&gt;特征分解（分类特征、时间特征等）&lt;/li&gt;
&lt;li&gt;特征变换（log(x),sqrt(x),x^2等）&lt;/li&gt;
&lt;li&gt;特征组合&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特征尺度变换：标准化或归一化&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;挑选合适的模型&#34;&gt;挑选合适的模型&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果数据很大，做降采样，以便能够在合理时间内尝试多个模型（不过要注意，这样的操作对于复杂模型不太友好，比如神经网络和随机森林）&lt;/li&gt;
&lt;li&gt;再一次的，尽量自动化以上流程&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;训练很多模型，快且原始地使用模型参数，训练尽可能多的模型（线性模型、朴素贝叶斯、SVM、随机森林、神经网络等等）&lt;/li&gt;
&lt;li&gt;测量并评估他们的表现

&lt;ul&gt;
&lt;li&gt;对于每个模型，使用 N-fold 交叉验证，计算表现的均值与方差&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;分析每个模型上最为显著的特征&lt;/li&gt;
&lt;li&gt;分析模型所犯的错误类型

&lt;ul&gt;
&lt;li&gt;如果是人类，会采用什么样的方法避免犯错？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;快速地做一波特征选择和特征工程&lt;/li&gt;
&lt;li&gt;前面步骤重复一两次&lt;/li&gt;
&lt;li&gt;列出表现最好的3-5个模型，最好他们的错误情况不同以便集成&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;微调系统&#34;&gt;微调系统&lt;/h2&gt;

&lt;p&gt;建议：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随着微调的进行，你将会使用尽可能多的数据&lt;/li&gt;
&lt;li&gt;总是使你的操作自动化&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;使用交叉验证进行超参数的微调

&lt;ul&gt;
&lt;li&gt;将你的数据变换也变成超参数的一部分，特别是当你对数据不熟悉的时候（比如：我应该用0还是中位数填补缺失值，还是仅仅去掉那个样本？）&lt;/li&gt;
&lt;li&gt;除非超参数非常少，使用随机搜索而不是网格搜索。如果训练耗时非常久，你可能会想用贝叶斯优化方法。（比如使用高斯过程）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;采用集成方法。集成最优的方案，往往表现会超过单独模型方案。&lt;/li&gt;
&lt;li&gt;一旦你对自己的模型很有信心，那就在测试集上验证其泛化误差。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;方案呈现&#34;&gt;方案呈现&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;记下你所做的努力，文档化&lt;/li&gt;
&lt;li&gt;起草一份漂亮的展示稿

&lt;ul&gt;
&lt;li&gt;确保先强调大局&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;解释为何你的方案达到了商业目标&lt;/li&gt;
&lt;li&gt;不要忘记展现整个过程中你认为的有趣部分

&lt;ul&gt;
&lt;li&gt;讲述什么有效、以及什么没起作用&lt;/li&gt;
&lt;li&gt;列出你的前提条件，并说明边界&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;通过可视乎，确保你的关键发现易于理解和传播；或是利用容易记住的表达&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;部署&#34;&gt;部署&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;准备将你的解决方案接入生产环境（接入生产环境的数据，写单元测试等）&lt;/li&gt;
&lt;li&gt;写监控代码以监测系统的表现，当系统宕机时发出警告

&lt;ul&gt;
&lt;li&gt;要意识到，随着数据的更新，模型的效果也会衰减&lt;/li&gt;
&lt;li&gt;可能需要人工检测数据的表现&lt;/li&gt;
&lt;li&gt;同样监控输入数据（例如：失灵的传感器会传回随机的数据，而其他的传感器的输出会是一个稳定值）这对于在线学习系统尤为重要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;当模型达到一定偏差时，重新在新数据上训练（尽可能自动化）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上，我们从立项、数据准备、模型准备到模型的部署，全面梳理的真实项目中的机器学习模型生命周期。在真实的工业场景中，我们所作的可能有些许差别，但都差不多。例如：我们会对问题定义、会对数据进行探索、会给需求方呈现我们的解决方案、会监控我们的模型表现。&lt;/p&gt;

&lt;p&gt;在梳理过程中我也发现自身团队的不足：对大背景商业目标的认识不到位、很多时候是拿着锤子（模型）去找钉子（场景）、方案呈现上理工科思维偏重、系统迭代不足。除此之外，还有些细节不是很规范。简单来说就是有些跑马圈地、急功近利的感觉。业务向较重，算法模型潜力并未完全释放，在团队内推行以上规范非常有必要。&lt;/p&gt;

&lt;p&gt;不知道看本文的读者，你们的团队会有这样的情况吗？欢迎就此在评论区发表你的看法。喜欢本文的读者，别忘了点赞、喜欢、加关注哦，你的鼓励，将是我写作分享的动力(&lt;em&gt;^_^&lt;/em&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slack gpt2 Bot 机器人写文已经到了如此地步？邀你一同测评史上最强 GPT2 模型</title>
      <link>https://kuhungio.me/2019/slack-gpt2-bot/</link>
      <pubDate>Mon, 25 Mar 2019 22:36:06 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/slack-gpt2-bot/</guid>
      <description>

&lt;p&gt;记得在校的时候，某岩做过一个app，讲接龙故事的。类似于我写一段，另一个人写接下来的一段，最后凑成一个完整的故事。当时，可产生了不少有意思的段子。最近，GPT2 模型的发布，让人不禁想到，有没有可能让机器来完成这个任务呢？机器写十四行诗、机器写莎士比亚风格的文章，机器写对联，这些都已经成为了现实。人工智能虽然没有带来突飞猛进的质变，但着实催生了很多有意思的小玩意儿。对于GPT2，一个字概括来说就是：壕——数据量大，算力能够 cover 住。这套算法模型网罗了几乎现有的所有文本数据，成功“过拟合“地屠榜，刷新多个 NLP 任务榜单排行。作者为了预防滥用模型、同时让别的研究者能够有个初步地认识，开源了一个小一些地模型。该模型的能力之一，就是我们今天的主题：接着别人地话写故事。今天我们要通过算法来实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/slack-gpt2/slack.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;虽然作者有在尽力简化复现难度，但对于很多不是这行的人，让他去敲命令行来走完整个流程，还是困难重重。能够将深奥的原理讲给普通人听，并且简单易懂，是一项科学传播的必备能力。做为技术向的工程师，在产品处于雏形阶段时，能够通过一个 MVP 最小价值产品，实现核心功能，也是一项大大的加分项。对于今天的任务，我们选取容易上手，接口丰富的 slack 作为我们的前端交互窗口。&lt;/p&gt;

&lt;p&gt;如何构建一个 MVP 产品；或者具体的来讲，在我们的这个任务中，如何将数据挖掘工程师的模型成果，转化为可落地、可感知的产品或服务呢。操起斧子直接开干，依葫芦画瓢撸个前后端出来吗？这，其实是很多技术人员的一个误区——认为什么都可以从技术层面解决，”少废话别bb，bb is cheap，show me the code“。但从一个商业产品或服务商的角度来看，客户与渠道是前台，我们的客户是谁、如何触达客户以及选用何种渠道维系客户，是一个一开始就要考虑的事情。&lt;/p&gt;

&lt;p&gt;以这个 GPT2 bot 为例，我希望的客户是对 GPT感兴趣，但又没基础去折腾的学生或是其他领域的人士，抑或是没时间去跑 demo 的专业同行。如何触达客户：你看的这篇文章的平台，就是我的触达媒介。我最后选择用 slack 交付我的服务，而不是 qq 或 微信，是因为他成本更低，虽然阻挡了部分潜在客户，但权衡后是可以接受的。最后的工作才是依葫芦画瓢，照撸一个出来。本文参照了&lt;a href=&#34;https://github.com/EdwardHuCS/slack-gpt2&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;EdwardHuCS&lt;/a&gt;,并在其基础上做了部分改动。&lt;/p&gt;

&lt;p&gt;虽然这波 AI 热潮，让很多像我这样的非科班得以上车。但在实际生产环境中，我们还是暴露了诸多问题。其中之一，便是工程能力薄弱。会写 SQL 、会手推算法、会调包，但是就是不会写能跑的整个小系统。在业务变化快的公司中，这可能不是一个好事情。你的模型也许还在细调参数，但突然整个业务就没了。如果你能拿出一个能跑的马儿，兴许能影响这个业务。这就是前面提到的加分项。&lt;/p&gt;

&lt;p&gt;言归正传，我们回到在slack上面。我们的核心就以下代码：&lt;/p&gt;

&lt;h2 id=&#34;核心代码解读&#34;&gt;核心代码解读&lt;/h2&gt;

&lt;p&gt;导入一些基础配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import time
import re
from slackclient import SlackClient
import sys
from gpt2.src import generate_unconditional_samples
# instantiate Slackk client
slack_client = SlackClient(&#39;&#39;) # 认证口令
# starterbot&#39;s user ID in Slack: value is ssigned after the bot starts up
starterbot_id = None

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;延迟配置以及样例和匹配模式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# constants
RTM_READ_DELAY = 1 # 1 second delay between reading from RTM
EXAMPLE_COMMAND = &amp;quot;God, to me, is like a &amp;quot;
MENTION_REGEX = &amp;quot;^&amp;lt;@(|[WU].+?)&amp;gt;(.*)&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;通过 slack 的事件，解析出我们的消息和对应的频道
def parse_bot_commands(slack_events):
    &amp;quot;&amp;quot;&amp;quot;
        Parses a list of events coming from the Slack RTM API to find bot commands.
        If a bot command is found, this function returns a tuple of command and channel.
        If its not found, then this function returns None, None.
    &amp;quot;&amp;quot;&amp;quot;
    for event in slack_events:
        if event[&amp;quot;type&amp;quot;] == &amp;quot;message&amp;quot; and not &amp;quot;subtype&amp;quot; in event:
            user_id, message = parse_direct_mention(event[&amp;quot;text&amp;quot;])
            if user_id == starterbot_id:
                return message, event[&amp;quot;channel&amp;quot;]
    return None, None
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;消息解析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def parse_direct_mention(message_text):
    &amp;quot;&amp;quot;&amp;quot;
        Finds a direct mention (a mention that is at the beginning) in message text
        and returns the user ID which was mentioned. If there is no direct mention, returns None
    &amp;quot;&amp;quot;&amp;quot;
    matches = re.search(MENTION_REGEX, message_text)
    # the first group contains the username, the second group contains the remaining message
    return (matches.group(1), matches.group(2).strip()) if matches else (None, None)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;核心的模型导入&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def handle_command(command, channel):
    &amp;quot;&amp;quot;&amp;quot;
        Executes bot command if the command is known
    &amp;quot;&amp;quot;&amp;quot;
    # Default response is help text for the user
    response = &amp;quot;Not sure what you mean. Try *{}*.&amp;quot;.format(EXAMPLE_COMMAND)

    # This is where you start to implement more commands!
    if len(command) &amp;lt; 2:
        response = &amp;quot;Sure...write some more text then I can do that!&amp;quot;
    else:
        # 这里可以替换成任何你想要的模型
        response = &#39;&amp;quot;&#39;+command+generate_unconditional_samples.sample_model(nsamples=1, length=6*len(command), top_k=len(command), command=command)[0]


    # Sends the response back to the channel
    slack_client.api_call(
        &amp;quot;chat.postMessage&amp;quot;,
        channel=channel,
        text=response)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主函数入口&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if __name__ == &amp;quot;__main__&amp;quot;:
    if slack_client.rtm_connect(with_team_state=False):
        print(&amp;quot;Starter Bot connected and running!&amp;quot;)
        # Read bot&#39;s user ID by calling Web API method `auth.test`
        starterbot_id = slack_client.api_call(&amp;quot;auth.test&amp;quot;)[&amp;quot;user_id&amp;quot;]
        while True:
            command, channel = parse_bot_commands(slack_client.rtm_read())
            if command:
                handle_command(command, channel)
            time.sleep(RTM_READ_DELAY)
    else:
        print(&amp;quot;Connection failed. Exception traceback printed above.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;开始安装并运行&#34;&gt;开始安装并运行&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone git@github.com:kuhung/slack-gpt2.git
cd slack-gpt2
获取 slack app 的 token，并填充进上面的 slack_client
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n slackbot python=3.6
source activate slackbot
pip install -r requirements.txt
cd gpt2
pip install -r requirements.txt
python download_model.py 117M
cd ..
python starterbot.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你不熟悉或从来没用过slack，也没关系，还记得开头说的交付吗？直接加入我的 workspace，一起测评 GPT2 bot。链接：&lt;a href=&#34;https://join.slack.com/t/kuhung/shared_invite/enQtNTc4ODcxNDUwNzA1LTI4ODNlODRhMjc1NGY2M2IwYjNhNmUzYmNiMzMyNTliN2E2ZWMxNWIzZjMzMzVkOTlkNzExNWVhYzZkNmYzMjI&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;加入我的 slack workspace&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;如同大多数应用场景一样，数据挖掘的算法需要落地，最好的办法就是封装成一个接口，给到前后端去调用。这其中还有很多性能优化的东西，但作为一个 sideproject，以上操作足够让你给别人眼前一亮的感觉。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Competing on Analytics 凭什么打败竞争对手？基于数据、基于分析的商业竞争</title>
      <link>https://kuhungio.me/2019/competing-on-analytics/</link>
      <pubDate>Tue, 12 Mar 2019 10:48:59 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/competing-on-analytics/</guid>
      <description>

&lt;p&gt;数据科学家这个职位，随着12年的哈佛商业评论的一篇文章，成为了21世纪“最性感的职业”。这年头，越来越多的年轻人开始往这个方向奔，市场几近饱和。但是，很少有听见企业家说：“是的，我们很需要数据工程师，因为以下原因&amp;hellip;“对于看此文的老板们，你们是否不止一次听到媒体鼓吹大数据、鼓吹机器学习、鼓吹人工智能，却很少有听到说这些东西，对于企业来说，实实在在带来了什么。如果你的答案是“Yes”，那么这篇文章将解答你的疑惑。&lt;/p&gt;

&lt;p&gt;本文论点主要取自 Thomas H. Davenport 文章 《Competing on Analytics》，试图从企业管理的角度，阐述为什么我们需要数据科学家（或者说广义的数据相关人员）；他们能给企业带来哪些切实的好处；以及作为企业家，我们该如何转型，如何拥有更强的竞争力。&lt;/p&gt;

&lt;h1 id=&#34;同质化的市场危机&#34;&gt;同质化的市场危机&lt;/h1&gt;

&lt;p&gt;在当下，想依靠某个新奇的点子或者是产品服务，已经不大可能再和其他竞争者区分开来。作为一个人类组织，底子里仍保留有人类的天性。人类天生就爱模仿，从一出生模仿吃东西，到后面通过模仿习得语言，再到后面的学习。人类的本质可能就是个复读机。模仿可以说保证了我们人类种族的存在与延续。对于企业来说，也大抵相同。&lt;/p&gt;

&lt;p&gt;尽管我们知道，从道德原则上讲，大企业模仿别的东西是不对的。但是，从商业利益角度，无数的事实告诉我们，模仿，对于企业来说真的是一个大概率稳赚不亏的事情。把市面稳定的产品拿来微创新，再加持自己的人力或渠道优势，很快就能回本。保不齐也能把竞争对手耗死。现实即是如此。&lt;/p&gt;

&lt;h1 id=&#34;比你更有利的竞争对手&#34;&gt;比你更有利的竞争对手&lt;/h1&gt;

&lt;p&gt;越来越多的产品、服务开始同质化。无论互联网、游戏、手机或是制造业、服装业，越成熟的领域这个现象越明显。与此同时，我们的竞争对手可能在东南亚，拥有更低的人工成本；可能在不规矩的私营企业，拥有更多免费加班的程序员；也可能是腾讯头条这样的大厂，控制着大部分渠道。那么，你的产品服务，凭什么脱颖而出？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答案就是成为分析型竞争者&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;数据分析竞争者在干什么&#34;&gt;数据分析竞争者在干什么&lt;/h1&gt;

&lt;p&gt;数据分析型竞争者会做以下几个事情。&lt;/p&gt;

&lt;h2 id=&#34;用户&#34;&gt;用户&lt;/h2&gt;

&lt;p&gt;通过分析，去洞察客户的需求，以及他们所愿支付的价格，找到他们保持忠诚度的原因。在商业模式中，客户是我们的直接服务对象，也是收入来源。那么，势必需要搞清楚客户的数据情况。&lt;/p&gt;

&lt;p&gt;在当下，比较流行的技术是通过用户画像技术，去刻画我们的用户群体。用户的分布地域、用户的性别以及年龄，用户的偏好。只有这些东西都搞清楚，我们才能清楚的知道我们的客户是谁，为什么他们需要我们的服务或产品。&lt;/p&gt;

&lt;h2 id=&#34;渠道&#34;&gt;渠道&lt;/h2&gt;

&lt;p&gt;与此同时，也要分析我们触达用户的渠道。不得不说，发明电视黄金档广告的人，一定是个商业奇才。曾几何时，电视广告和路标广告曾是众多老板的竞相争夺的资源，屡屡出现标王，一次次刷新记录。在那个时代，只要你砸钱，拿到黄金时间的广告，就是稳赚不赔。但现在不一样了，各种互联网渠道，在抢占着人们的注意力。楼宇电梯广告、站台路牌广告各种花样层出不穷。&lt;/p&gt;

&lt;p&gt;但是，你就真的清楚该投哪一个了吗？还是听信对方销售人员一阵天花乱坠的吹嘘，就乖乖交了钱，却得不到想要的转化效果？通过适当的分析，我们可以知道用户在哪些渠道对我们的响应度最高，知道哪些渠道可以带来更高的转化，从而优化我们的渠道成本投入。&lt;/p&gt;

&lt;p&gt;举个我自己的例子：我的文章隔几天就会发一篇，分布在不同渠道：微信、知乎、头条、掘金、简书。那我是单单为了占坑防洗稿就完事了吗？不是的，作为一个数据挖掘工程师，我会分析各个渠道带来的阅读、关注和互动，从而调整渠道策略。&lt;/p&gt;

&lt;p&gt;目前我就发现，知乎和头条的信息流产品在分发策略上做的很不错，能保证充分的曝光。微信适合做核心粉丝的沉淀，和粉丝去探讨交流一些问题。而掘金、简书的曝光有限，那我就会在更新是把他们往后放。&lt;/p&gt;

&lt;p&gt;那是不是我就应该放弃简书掘金了呢？也不是的。通过分析我发现，掘金在谷歌搜索的排名占比靠前，简书在百度搜索的排名靠前，他们俩实际是很好的 SEO 流量优化渠道。这就是渠道分析的效果。&lt;/p&gt;

&lt;h2 id=&#34;人力&#34;&gt;人力&lt;/h2&gt;

&lt;p&gt;通过分析，去计算员工对公司利润做出的具体贡献，而不仅仅是关注薪酬成本。以前的自己觉得，买东西或是做事情，先去看成本是多少。工作后发现，领导的视角不是这样的。成本对于老板们来说，只是个数字。他们更关心做事的投入产出比。对于员工问题也是这样。&lt;/p&gt;

&lt;p&gt;但现实不是这样的。很少有公司会关注这名员工对利润的贡献，反而更多的去关注他的成本是多少。他今天996了没，没有996对不起我给他开的价钱，而丝毫不关心员工对公司利润所做的贡献。而另一个极端就是，有些老板觉得这类人便宜，从而养了很多闲人。这两种情形虽然短时不会给企业带来多大负面影响，但你的竞争性选手，已经在利用数据，去发现员工的价值贡献，并对人事招聘进行调整了。&lt;/p&gt;

&lt;h2 id=&#34;库存&#34;&gt;库存&lt;/h2&gt;

&lt;p&gt;在实业中，我们还要追踪现有的库存，预测并分析需求量，减少库存的积压，提高现金流转效率。这里主要是对重资产的企业老板，如果你能在这其中发现机会，一个点的提升，都会带来巨大收益。&lt;/p&gt;

&lt;h1 id=&#34;数据分析竞争者的特质&#34;&gt;数据分析竞争者的特质&lt;/h1&gt;

&lt;p&gt;那么，集体来讲，分析型数据竞争者具有怎么样的特质呢？如同招聘时给出的工作描述，我们也可以给分析型竞争者做画像。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;数据竞争型选手应广泛应用模型和算法以及对应的最优化技术。例如作者之前实习的某普惠金融银行，通过最广泛的数据建模，给中小微个人提供贷款，赚大型银行看不上的钱，同时自己也很滋润。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;组织内部全面应用数据分析等相关技术。对各个流程进行数据分析、对各个环节进行建模以优化体验，减少流失。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;同时，也应该有自上而下的支持。如果一个企业的领军人物都不相信，那一线员工又何来的信任和执行力呢。企业老板应具备一些基础知识，同时有能够值得信任、不编造数据的专家。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;为什么它有效&#34;&gt;为什么它有效&lt;/h1&gt;

&lt;p&gt;说了现状说了要求，那为什么套措施有效呢？如果大家都有，那不就是没有差异化了吗？难道我们要搞军备竞赛吗？这不就和贩卖焦虑的自媒体一样的了吗？&lt;/p&gt;

&lt;p&gt;其实不是这样的。一个身材羸弱的人和一个经常分析自己身体状态并针对性强化的人，他们外在的表现就会不一样。大部分企业在竞争中，使用的技术很相近，产品差别也不大；唯一能有差异化的，可能就是商业流程了。数据的挖掘分析，帮助企业家从流程中挤出每一滴价值。&lt;/p&gt;

&lt;p&gt;尽管很多公司都有数据分析团队，但只有娴熟运用的公司，才能在各行各业取得霸主地位。甚至，对于如头条、亚马逊这样的公司，数据挖掘、算法已经成为了企业的名片和核心竞争力。&lt;/p&gt;

&lt;h1 id=&#34;核心4条解决方案&#34;&gt;核心4条解决方案&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;合适的焦点、分析不可过于分散，免得失去焦点。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;合适的文化、小范围检验，最小可行产品验证。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;合适的人才、有分析能力且能深入浅出说明问题；有商业才能能够在商业角度阐述价值；以及沟通的技巧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;合适的技术、数据储备、硬件支持，最终才会立于不败之地。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，数据竞争型选手，如何说明他确实有效。很简单，以始为终点，检视最初的目标。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prophet in 000300 我把算法模型套在了股市上，发现...</title>
      <link>https://kuhungio.me/2019/prophet-in-000300/</link>
      <pubDate>Fri, 08 Mar 2019 22:48:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/prophet-in-000300/</guid>
      <description>

&lt;h2 id=&#34;跑步进场&#34;&gt;跑步进场&lt;/h2&gt;

&lt;p&gt;最近股市大涨，不少人忙着跑步进场。作为保守型“投资者”，主投指数基金：沪深300。在这波行情 中，短短2个月，也有13%的账面收益。虽然知道指数类适合长期持有，但也好奇，这个点是否是高位了。为了解决这个疑虑。我们今天用算法模型套一套，看能否发现些什么。&lt;/p&gt;

&lt;h2 id=&#34;时序预测的价值&#34;&gt;时序预测的价值&lt;/h2&gt;

&lt;p&gt;时序问题的预测在生活中很常见。例如：游戏在线人数预测、消费情况预测、 O2O 的到店人数预测、交通流量预测，这些场景的精确预测，为资源的调配起到了重大的参考作用。从个体角度来说，得到的服务和体验也大大提升。&lt;/p&gt;

&lt;p&gt;为此，Facebook 开源了一套工具 Prophet，专门用于时间学列预测。在这里，我们将用它，来一探股市究竟。&lt;/p&gt;

&lt;h2 id=&#34;时序预测的原理&#34;&gt;时序预测的原理&lt;/h2&gt;

&lt;p&gt;对于时间序列问题，常用的手法是时间序列的分解：这里有些类似于傅里叶变换的意味。将一个函数分解为多个规律函数的和积。时间序列的常见组成成分包括：季节项、趋势项以及噪声。在 Prophet 中，结合实际情况，他们又加入了节假日项目。之前在一次 kaggle 的比赛中，我们也发现节假日的数据波动，其实是类似于周末效应的。即：节假日的前后数据，类似于周六的前后数据。对数据进行修正后，评价指标会好很多。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;废话不多说，咱们开干。&lt;/p&gt;

&lt;h2 id=&#34;prophet-in-沪深300&#34;&gt;Prophet in 沪深300&lt;/h2&gt;

&lt;h3 id=&#34;工具包安装&#34;&gt;工具包安装&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;pip install fbprophet&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;数据准备与清洗&#34;&gt;数据准备与清洗&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import pandas as pd
import numpy as np
from fbprophet import Prophet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;数据准备&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据来源为网易财经，&lt;a href=&#34;http://quotes.money.163.com/0000300.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;沪深三百&lt;/a&gt;指数。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.read_csv(&#39;../data/000300.csv&#39;,encoding=&#39;GB2312&#39;) 
data.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/prophet/300_1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;数据清洗&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;选取需要的数据，并对数据做 log / box-cox 变换，使数据更符合线性、正态分布，减少方差差异。经济系统和生态系统类似，都存在指数级增长现象，也存在饱和现象。我们这里采用 log 变换。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = data[[u&#39;日期&#39;,u&#39;收盘价&#39;]]
df.columns = [&#39;ds&#39;,&#39;y&#39;]
df[&#39;y&#39;] = df[&#39;y&#39;].apply(lambda x: np.log(int(x)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;模型拟合与预测&#34;&gt;模型拟合与预测&lt;/h3&gt;

&lt;p&gt;简单定义，然后拟合。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m = Prophet()
m.fit(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;预测未来一年的行情&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = m.make_future_dataframe(periods=365)
forecast = m.predict(future)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;详细看最后15天的数据&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;forecast[[&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;]].tail(15)
future_predict[&#39;yhat&#39;] = future_predict[&#39;yhat&#39;].apply(lambda x:np.exp(x))
future_predict[&#39;yhat_lower&#39;] = future_predict[&#39;yhat_lower&#39;].apply(lambda x:np.exp(x))
future_predict[&#39;yhat_upper&#39;] = future_predict[&#39;yhat_upper&#39;].apply(lambda x:np.exp(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/prophet/300_2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;yhat 预测比较保守，20200307 相较于目前20190308 的大盘涨了100个点。预期最大收益：(6536-3658)/3658≈ 78%，预期最大亏损：(2158-3658)/3658≈-41%&lt;/p&gt;

&lt;h3 id=&#34;模型看到了什么&#34;&gt;模型看到了什么&lt;/h3&gt;

&lt;p&gt;Prophet 有个功能是成分拆分，咱们来看看国内股市的趋势以及季节性因素是什么。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig1 = m.plot(forecast)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;模型拟合情况&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/prophet/300_3.png&#34; alt=&#34;模型拟合情况&#34; /&gt;&lt;/p&gt;

&lt;p&gt;趋势项&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/prophet/300_4.png&#34; alt=&#34;整体趋势、周趋势和年趋势&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;模型数据表明，沪深股市短期看可能有波动，长期看上扬可能性更大。短期对于我们这种投资方式的参考意义不大，长期来看，稳中向好，我也将持续沪深300。当然，话说回来，投资有风险，决策需谨慎。不要只看狼吃肉，不见狼挨打。去年最差的时候，本人累计亏损15%&amp;hellip;&lt;/p&gt;

&lt;p&gt;另外再强调一下，模型并非万能。这里使用的信息单一，但真实世界，可是有多种信息共同作用于市场。模型也还未经过充分调参，没有划分数据做验证，实际使用价值有限。&lt;/p&gt;

&lt;p&gt;对此，你怎么看？欢迎在留言区写下你的看法。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Next Step for Machine Learning 机器学习落地需攻破的9个难题</title>
      <link>https://kuhungio.me/2019/the-next-step-for-machine-learning/</link>
      <pubDate>Sun, 24 Feb 2019 23:31:58 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/the-next-step-for-machine-learning/</guid>
      <description>

&lt;p&gt;机器学习在前两年的时间里，一下子就爆火了起来。很多公司也跟着这个趋势，招募了很多算法工程师、数据挖掘工程师。但是，在实践中，企业发现要落地，实际上还有很多问题需解决。以至于在大部分项目，还是规则主导。算法工程师的日常，也不过是清洗数据，调整规则。所以，机器学习技术，在真实的应用中到底缺少些什么呢？&lt;/p&gt;

&lt;p&gt;在国立台湾大学《机器学习》&lt;a href=&#34;https://www.youtube.com/watch?v=XnyM3-xtxHs&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;2019春季班&lt;/a&gt;，李宏毅老师给出了他的观察。以下的内容，结合李老师的最新讲义、加上我本身工作的理解，给大家梳理机器学习落地急需解决的9个难题。&lt;/p&gt;

&lt;h2 id=&#34;拒绝回答与可解释性-哲学层面&#34;&gt;拒绝回答与可解释性（哲学层面）&lt;/h2&gt;

&lt;h3 id=&#34;1-anomaly-detection-机器能不能知道-我不知道&#34;&gt;1. Anomaly Detection 机器能不能知道“我不知道”&lt;/h3&gt;

&lt;p&gt;机器能不能知道自己的识别范围，还是说生硬地给出模型内的东西，或者说抛出无法识别。在猫狗分类里，现有的模型已经到达很高的精度，甚至能给出猫狗的品种。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/Cat.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;但是正式上线后，用户真的会乖乖给到猫狗的图片吗？如果用户丢一张妹子图，机器能够知道自己不知道吗？目前这个领域的研究叫做 Anomaly Detection。知道自己不知道，对于一些异常的情况，十分重要。&lt;/p&gt;

&lt;h3 id=&#34;2-explainable-ai-说出为什么-我知道&#34;&gt;2. Explainable AI 说出为什么“我知道”&lt;/h3&gt;

&lt;p&gt;神马汉斯的故事：&lt;/p&gt;

&lt;p&gt;18世纪德国，一匹名叫汉斯的马成为当地网红。他能够计算简单的算术题，并用蹄子敲出正确回答。这在当时一度引起轰动。后来，有人做了个实验，把汉斯和周围的人完全隔绝，这匹马就完全蒙圈了。时事证明，这匹马的神奇能力不在于他的算数能力，而在于他的观察能力。当给到正确答案时，周围的人会有不一样的反应，汉斯也就随即停止敲马蹄。&lt;/p&gt;

&lt;p&gt;机器学习的成果，是否同汉斯一样，通过一些意想不到的渠道，获得的答案。在 &lt;a href=&#34;http://www.heatmapping.org/slides/2017_GCPR.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;GCPR 2017 Tutorial&lt;/a&gt; 的研究中，研究者通过注意力机制，研究机器判断的依据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/GCPR2017.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;实验者测试了两个模型，两个模型均为马匹识别。DNN 模型的焦点集中在马匹身上，是一个正常的模型。但 FV 的交点却集中在图片左下角。原来，图片的左下角有图片的出处，所有的包含马匹的图都有这个标记。所以，FV 模型学到的重点在于这些标记。同样的表现，却是不一样的判断依据。显然，FV 模型的判断依据是滑稽和不可靠的。&lt;/p&gt;

&lt;p&gt;我们需要一些技术，让 AI 不仅给出结果，同时要给出判断的依据。即：模型的可解释性。&lt;/p&gt;

&lt;h2 id=&#34;抵御恶意攻击&#34;&gt;抵御恶意攻击&lt;/h2&gt;

&lt;h3 id=&#34;3-防止-adversarial-attack&#34;&gt;3. 防止 Adversarial Attack&lt;/h3&gt;

&lt;p&gt;人有错觉，机器是否也会有错觉。我们来做一个认知实验。以下两个圈圈，哪个的颜色更深？好，记住你的答案。结果将在稍后揭晓。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/mistake.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于机器，有研究表明，通过改变图像中的个别像素，可以起到迷惑机器的作用。改变一个像素，就可以让模型的判断结果从熊猫到长臂猿。该技术名叫 Adversarial Attack。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/m_mistake.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样的技术相当危险。举个例子，当自动驾驶的车辆行驶在路上时，可能路边的人挥舞下旗子，机器的判断就会被干扰，做出不当的举动。&lt;/p&gt;

&lt;p&gt;回到开头的例子，正确答案是左边。这其实是一个计中计。你以为这是视觉认知实验，其实这也是某种形式的“心理攻击”。
&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/mistake_2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;学习模式&#34;&gt;学习模式&lt;/h2&gt;

&lt;h3 id=&#34;4-life-long-learning-终身学习&#34;&gt;4. Life-long learning 终身学习&lt;/h3&gt;

&lt;p&gt;终身学习是一个人类行为的概念。活到老学到老，大家都知道只有不断更新自己的知识，才能跟上社会发展的步伐。同时呢，先前学到的东西，对后面的学习仍有帮助。举个例子：学完线性代数之后，对学习和理解机器学习就大有帮助。&lt;/p&gt;

&lt;p&gt;但是，机器不一样。今天的我们，一般只让一个模型学习一个任务。但这样会存在一些问题。首先是随着建模的增多，模型数量将无限增长。其次，模型之前学到的技能，对之后的学习没有帮助。就像 Alphastar 它玩星际争霸很棒，但让他同时学下围棋，目前来说是不行的。它和 Alphazero 是两个不同的模型 。&lt;/p&gt;

&lt;p&gt;那么，自然而然的，我们就会抛出这样一个疑问，机器能否终身学习呢？这里的相关研究，提个关键词 Catastrophic Forgetting 。&lt;/p&gt;

&lt;h3 id=&#34;5-meta-learning-learn-to-learn-学习如何学习&#34;&gt;5. Meta-learning / Learn to learn 学习如何学习&lt;/h3&gt;

&lt;p&gt;现有的机器学习模型设计，都遵循着这样一个范式——在特定领域人工设计一套算法，让机器去学习。我们就想，能不能设计一套算法，让机器自己去设计自己的学习算法呢？&lt;/p&gt;

&lt;p&gt;这样的范式，我们称之为 meta-learning 元学习，或者叫 learn to learn，学习如何学习。&lt;/p&gt;

&lt;h2 id=&#34;模型改进&#34;&gt;模型改进&lt;/h2&gt;

&lt;h3 id=&#34;6-reinforcement-learning-增强学习为什么这么慢&#34;&gt;6. Reinforcement learning 增强学习为什么这么慢&lt;/h3&gt;

&lt;p&gt;现在撸模型，没用上增强学习，都不好意思说出来。在像星际争霸这样的游戏中，增强学习确实有用。但是，它真的有那么强吗？&lt;/p&gt;

&lt;p&gt;在星际争霸中，机器花了900小时，才到达4000分左右。而人类的能力在哪儿呢？人类只需要2小时，就能到达。像前面提到的Alphastar，它虽然在星际争霸上能够痛扁人类，但它可是花了200年的时间在玩这个游戏。模型世界就像是修仙小说里的精神世界。若是把一个人丢在里面，只能玩星际争霸，他其实也可以达到机器的水平，更可能比机器做得更好。增强学习为什么这么慢，能不能再快些？&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/Alphastar.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;7-network-compression-神经网络压缩&#34;&gt;7. Network Compression 神经网络压缩&lt;/h3&gt;

&lt;p&gt;机器学习目前多运行在大型服务器上，配备极强的 GPU、相当大的内存和数目众多的 CPU。但若想要把机器学习广泛应用于生活中，IoT 物联网这类设备的计算和存储都是十分有限的。我们能不能把模型缩小，同时保留其能力呢。我们能不能把大型神经网络进行剪枝，或者是参数二元化，以此来减轻内存和计算压力呢。我们现在有 tensorflow lite，有 coreML，但这些还不够。&lt;/p&gt;

&lt;h2 id=&#34;训练数据&#34;&gt;训练数据&lt;/h2&gt;

&lt;h3 id=&#34;8-few-shot-zero-shot-learning-一定需要很多训练数据吗&#34;&gt;8. Few-shot / Zero-shot learning 一定需要很多训练数据吗&lt;/h3&gt;

&lt;p&gt;做比赛、写论文的都知道，要想效果好，数据少不了。数据质量很大程度决定了结果的表现。但是在实际生产环境中，带标注的优质数据是极其稀少的。这个时候，老板想让你做一个异常游戏玩家的识别，数据样本又很少，你该怎么办？除去自己手工标注、请人标注、做数据扩增外，我们还有很没有别的办法。难道要跟老板摊牌，说做不了这一个任务吗？&lt;/p&gt;

&lt;p&gt;现实场景的样本之少，一直有在困惑我们一线的员工。现在我们就希望，模型能够通过少量的样本，扩展到大量的未标记数据。这样的研究有，我们称之为 Few-shot learning。更有甚至，模型能不能通过我对川菜的描述：麻辣、重油、就识别出桌上的饭菜是四川菜呢？这样的模型被称之为 Zero-shot learing，不需要样本进行学习。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/caption.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;9-机器学习的谎言-训练数据和测试数据很不一样&#34;&gt;9. 机器学习的谎言 训练数据和测试数据很不一样&lt;/h3&gt;

&lt;p&gt;当我们在学习机器学习各类算法时，教科书都会有这样一个假设：训练数据和测试数据拥有相同的分布。但在真实世界中，这就是个谎言。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/train-test.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以手写数字识别为例，当训练集和测试集同分布时，你可以轻松达到99%的正确率。但在真实生活中，你的老板可能会给你右边的任务。训练数据是黑白的，实际场景中背景却是彩色的。这里你有两个选择：一是把《机器学习》这本数仍到老板面前，告诉他书上写的要求同分布，你这个任务做不了。但是一想到你家里的老婆孩子，你可能还是会含泪接下这个任务。仔细想想，若是模型真的识别到数字的形状，背景色应该没有关系吧。但是当你真正来做这件事时，你会发现，同样的模型，正确率下降到了57.5%。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/the-next-step-fro-ML/train-test-2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;诸如此类的问题，在真实场景中很常见。实际工作中，我们也有采取一些措施，尽量避免分布不同步的情况发生。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;李宏毅老师以上的总结，在生产环境确实存在。这也是我把它梳理一遍的动机，希望所有从业者在工作中能够注意到它们，在这些问题上有所突破。看完本文的读者，别忘了点赞、评论、喜欢+关注哦。你的鼓励，是我下一步的动力。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bert Chinese Finetune 中文语料的 Bert 微调</title>
      <link>https://kuhungio.me/2019/bert-chinese-finetune/</link>
      <pubDate>Sun, 17 Feb 2019 11:30:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/bert-chinese-finetune/</guid>
      <description>

&lt;h1 id=&#34;finetune-bert-for-chinese&#34;&gt;Finetune Bert for Chinese&lt;/h1&gt;

&lt;p&gt;NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/google-research/bert&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Bert&lt;/a&gt; 的文档本身对 finetune 进行了较为详细的描述，但对于不熟悉官方标准数据集的工程师来说，有一定的上手难度。随着 &lt;a href=&#34;https://github.com/hanxiao/bert-as-service&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Bert as service&lt;/a&gt; 代码的开源，使用 Bert 分类或阅读理解的副产物&amp;ndash;词空间，成为一个更具实用价值的方向。&lt;/p&gt;

&lt;p&gt;因而，此文档着重以一个例子，梳理 &lt;strong&gt;finetune 垂直语料，获得微调后的模型&lt;/strong&gt; 这一过程。Bert 原理或 Bert as service 还请移步官方文档。&lt;/p&gt;

&lt;h2 id=&#34;依赖&#34;&gt;依赖&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python==3.6
tensorflow&amp;gt;=1.11.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;预训练模型&#34;&gt;预训练模型&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;下载 &lt;strong&gt;&lt;a href=&#34;https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;BERT-Base, Chinese&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;:
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M
parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据准备&#34;&gt;数据准备&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;train.tsv&lt;/code&gt; 训练集&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dev.tsv&lt;/code&gt; 验证集
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;数据格式&#34;&gt;数据格式&lt;/h4&gt;

&lt;p&gt;第一列为 label，第二列为具体内容，tab 分隔。因模型本身在字符级别做处理，因而无需分词。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csv&#34;&gt;fashion	衬衫和它一起穿,让你减龄十岁!越活越年轻!太美了!...
houseliving	95㎡简约美式小三居,过精美别致、悠然自得的小日子! 屋主的客...
game	赛季末用他们两天上一段，7.20最强LOL上分英雄推荐！ 各位小伙...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;样例数据位置：&lt;a href=&#34;https://github.com/kuhung/bert_finetune/tree/master/data&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;数据格式取决于业务场景，后面也可根据格式调整代码里的数据导入方式。&lt;/p&gt;

&lt;h2 id=&#34;操作&#34;&gt;操作&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/google-research/bert.git
cd bert
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bert 的 finetune 主要存在两类应用场景：分类和阅读理解。因分类较为容易获得样本，以下以分类为例，做模型微调：&lt;/p&gt;

&lt;h3 id=&#34;修改-run-classifier-py&#34;&gt;修改 &lt;code&gt;run_classifier.py&lt;/code&gt;&lt;/h3&gt;

&lt;h4 id=&#34;自定义-dataprocessor&#34;&gt;自定义 DataProcessor&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class DemoProcessor(DataProcessor):
    &amp;quot;&amp;quot;&amp;quot;Processor for Demo data set.&amp;quot;&amp;quot;&amp;quot;

    def __init__(self):
        self.labels = set()
    
    def get_train_examples(self, data_dir):
        &amp;quot;&amp;quot;&amp;quot;See base class.&amp;quot;&amp;quot;&amp;quot;
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, &amp;quot;train.tsv&amp;quot;)), &amp;quot;train&amp;quot;)

    def get_dev_examples(self, data_dir):
        &amp;quot;&amp;quot;&amp;quot;See base class.&amp;quot;&amp;quot;&amp;quot;
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, &amp;quot;dev.tsv&amp;quot;)), &amp;quot;dev&amp;quot;)

    def get_test_examples(self, data_dir):
      &amp;quot;&amp;quot;&amp;quot;See base class.&amp;quot;&amp;quot;&amp;quot;
      return self._create_examples(
          self._read_tsv(os.path.join(data_dir, &amp;quot;test.tsv&amp;quot;)), &amp;quot;test&amp;quot;)

    def get_labels(self):
        &amp;quot;&amp;quot;&amp;quot;See base class.&amp;quot;&amp;quot;&amp;quot;
        # return list(self.labels)
        return [&amp;quot;fashion&amp;quot;, &amp;quot;houseliving&amp;quot;,&amp;quot;game&amp;quot;] # 根据 label 自定义


    def _create_examples(self, lines, set_type):
        &amp;quot;&amp;quot;&amp;quot;Creates examples for the training and dev sets.&amp;quot;&amp;quot;&amp;quot;
        examples = []
        for (i, line) in enumerate(lines):
            guid = &amp;quot;%s-%s&amp;quot; % (set_type, i)
            text_a = tokenization.convert_to_unicode(line[1])
            label = tokenization.convert_to_unicode(line[0])
            self.labels.add(label)
            examples.append(
                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))
        return examples

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;添加-demoprocessor&#34;&gt;添加 DemoProcessor&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  processors = {
      &amp;quot;cola&amp;quot;: ColaProcessor,
      &amp;quot;mnli&amp;quot;: MnliProcessor,
      &amp;quot;mrpc&amp;quot;: MrpcProcessor,
      &amp;quot;xnli&amp;quot;: XnliProcessor,
      &amp;quot;demo&amp;quot;: DemoProcessor,
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;启动训练&#34;&gt;启动训练&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export BERT_Chinese_DIR=/path/to/bert/chinese_L-12_H-768_A-12
export Demo_DIR=/path/to/DemoDate

python run_classifier.py \
  --task_name=demo \
  --do_train=true \
  --do_eval=true \
  --data_dir=$Demo_DIR \
  --vocab_file=$BERT_Chinese_DIR/vocab.txt \
  --bert_config_file=$BERT_Chinese_DIR/bert_config.json \
  --init_checkpoint=$BERT_Chinese_DIR/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/tmp/Demo_output/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若一切顺利，将会有以下输出:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;***** Eval results *****
  eval_accuracy = xx
  eval_loss = xx
  global_step = xx
  loss = xx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终，微调后的模型保存在&lt;strong&gt;output_dir&lt;/strong&gt;指向的文件夹中。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;Bert 预训练后的 finetune，是一种很高效的方式，节省时间，同时提高模型在垂直语料的表现。finetune 过程，实际上不难。较大的难点在于数据准备和 pipeline 的设计。从商业角度讲，应着重考虑 finetune 之后，模型有效性的证明，以及在业务场景中的应用。如果评估指标和业务场景都已缕清，那么不妨一试。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Github 地址：&lt;a href=&#34;https://github.com/kuhung/bert_finetune&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/kuhung/bert_finetune&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NLPScott/bert-Chinese-classification-task&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/NLPScott/bert-Chinese-classification-task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/aa2eff7ec5c1&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.jianshu.com/p/aa2eff7ec5c1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Data Mining 什么是数据挖掘</title>
      <link>https://kuhungio.me/2019/what-is-data-mining/</link>
      <pubDate>Sun, 17 Feb 2019 00:40:20 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/what-is-data-mining/</guid>
      <description>

&lt;!-- more --&gt;

&lt;h2 id=&#34;一-数据挖掘的定义&#34;&gt;一、数据挖掘的定义&lt;/h2&gt;

&lt;h3 id=&#34;什么是数据挖掘&#34;&gt;什么是数据挖掘？&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;数据挖掘是一个用数据发现问题、解决问题的学科。&lt;/li&gt;
&lt;li&gt;通常通过对数据的探索、处理、分析或建模实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据挖掘学习路线&#34;&gt;数据挖掘学习路线&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;大学里并没有数据挖掘这么一个专业，现有的数据挖掘工程师大都来自工科或统计学等专业。&lt;/li&gt;
&lt;li&gt;目前的数据挖掘工程师大都来自不同背景，计算机科学、数学甚至是机械工程。要想成功胜任，其诀窍是热情、好奇心，不断学习新的工具的能力，以及对数据清洗和分析的耐心。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;给新人的建议&#34;&gt;给新人的建议&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;最重要的三个品质：好奇心、是非观以及批判性思考。这三个品质，放在其他领域同样适用。&lt;/li&gt;
&lt;li&gt;专业领域的三种能力：编程能力、统计基础、商业思维。编程和统计在大学较为容易学到，商业思维需要多实践总结。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;二-数据挖掘在做什么&#34;&gt;二、数据挖掘在做什么&lt;/h2&gt;

&lt;h3 id=&#34;数据挖掘工程师的一天&#34;&gt;数据挖掘工程师的一天&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;检查日常报表数据是否异常，寻求数据波动的合理解释。&lt;/li&gt;
&lt;li&gt;针对新业务，设计指标，搭建数据模型。&lt;/li&gt;
&lt;li&gt;搭建商品推荐系统、价格预测系统、文本分类系统或是聊天机器人。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据挖掘的算法&#34;&gt;数据挖掘的算法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;使用复杂的机器学习算法并不能保证效果。一般来讲，最好的解决办法，通常很简单。&lt;/li&gt;
&lt;li&gt;生产环境使用简单的算法，并不意味着要放弃前沿算法。每一套新的方法，其目的都在解决前面的薄弱之处。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据挖掘与服务器&#34;&gt;数据挖掘与服务器&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;本地 PC 由于硬件与系统限制，工程师常在服务器进行大规模数据的运算、脚本部署与接口部署。

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;三-商业中的数据挖掘&#34;&gt;三、商业中的数据挖掘&lt;/h2&gt;

&lt;h3 id=&#34;作为公司-该如何开展数据挖掘&#34;&gt;作为公司，该如何开展数据挖掘&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;评估可能的收益与需要的投入&lt;/li&gt;
&lt;li&gt;开始收集数据&lt;/li&gt;
&lt;li&gt;招募数据挖掘团队&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;招聘数据挖掘团队&#34;&gt;招聘数据挖掘团队&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;好奇心应该是数据挖掘从业者的最重要品质。&lt;/li&gt;
&lt;li&gt;招聘时，应确保候选人对工作内容感兴趣。&lt;/li&gt;
&lt;li&gt;候选人应具备一定的成果意识。商业更重成果，而不是过程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据挖掘应用&#34;&gt;数据挖掘应用&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;广告位点击预估&lt;/li&gt;
&lt;li&gt;信用卡风控评估&lt;/li&gt;
&lt;li&gt;用户流失干预&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;四-数据挖掘工具&#34;&gt;四、数据挖掘工具&lt;/h2&gt;

&lt;h3 id=&#34;数据挖掘工具与大数据&#34;&gt;数据挖掘工具与大数据&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握以下工具：Python、Linux、Pandas 及 Jupyter、关系型和非关系型数据库。&lt;/li&gt;
&lt;li&gt;大数据通常指传统数据系统无法处理的数据。体量和增速都相当大。处理工具以 Hadoop 为代表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;五-数据挖掘进阶&#34;&gt;五、数据挖掘进阶&lt;/h2&gt;

&lt;h3 id=&#34;神经网络和深度学习&#34;&gt;神经网络和深度学习&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;神经网络出现已数十年，但由于条件限制，这一方向搁置了数十年。目前随着新的优化方法的出现和算力的提升，这一方向的工业化逐渐成为可能。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;如何更上一层楼&#34;&gt;如何更上一层楼&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;掌握基本的编程知识，更多地去理解背后的原理。&lt;/li&gt;
&lt;li&gt;流程化意识，及时复盘总结，规范流程（复用）。&lt;/li&gt;
&lt;li&gt;成果导向，将知识转化为行动和成果，给他人带来价值，服务更多人。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>12306Bypass Server 给抢票神器加上微信提醒</title>
      <link>https://kuhungio.me/2019/12306bypass-server/</link>
      <pubDate>Sat, 26 Jan 2019 15:52:08 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/12306bypass-server/</guid>
      <description>

&lt;h1 id=&#34;前言&#34;&gt;前言&lt;/h1&gt;

&lt;p&gt;春节假期临近，车票一度紧张。某行、某团开了加速包后，仍然无法第一时间刷到目的地的票。稍微有点儿技术底子的我们岂能坐以待毙，自然是要自己动手，丰衣足食。&lt;/p&gt;

&lt;p&gt;网上有各类开源的工具包，这里不做过多点评。之前在好友圈内传得比较靠谱的是 12306Bypass，又叫分流。分流是一个 Windows 应用，工作在 PC 端。其核心功能完全免费，更更重要的是，它的监控刷新在本地可以真实的感知。&lt;/p&gt;

&lt;p&gt;以前在学校还好，可以守在电脑面前。但工作后，由于各种原因，无法第一时间获取分流的抢票信息，因而白白错过好几次下单付钱的机会。于是我们就有了这样一个愿望，希望能将分流的信息第一时间转发。&lt;/p&gt;

&lt;p&gt;前几日逛某论坛，有人向分流开发者传达了增加 Server 酱的请求。开发者还是很给力，在最近的几次版本迭代中实现了该功能。简单的来说，Server 酱就是一个提醒服务。在这里，我们把它用在抢票软件中。当软件抢到票时，通过该服务，给到微信提醒。通知我们及时付款。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/File_wechat.jpg&#34; alt=&#34;微信推送&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/File.jpg&#34; alt=&#34;最终效果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过这样的形式，即可在微信端第一时间收到下订单的信息。那么如何配置这样的一个服务呢？我们只需要以下步骤。&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;h1 id=&#34;准备工作&#34;&gt;准备工作&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;最新版本的分流软件 搜索关键词：12306Bypass

&lt;ul&gt;
&lt;li&gt;这里使用的版本号是&lt;code&gt;1.13.30&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;没用过？&lt;a href=&#34;https://www.12306bypass.com/?utm_source=kuhungio.me&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;下载链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Github 账号 这里用做 Server 酱的登陆认证

&lt;ul&gt;
&lt;li&gt;不知道？&lt;a href=&#34;https://github.com/?utm_source=kuhungio.me&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;注册链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;实操阶段&#34;&gt;实操阶段&lt;/h1&gt;

&lt;h2 id=&#34;server-酱&#34;&gt;Server 酱&lt;/h2&gt;

&lt;p&gt;用于获取认证的接口&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;登入：用GitHub账号 &lt;a href=&#34;http://sc.ftqq.com/?c=github&amp;amp;a=login?utm_source=kuhungio.me&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;登入网站&lt;/a&gt;，获取&lt;a href=&#34;http://sc.ftqq.com/?c=code&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;SCKEY&lt;/a&gt;（在「&lt;a href=&#34;http://sc.ftqq.com/?c=code&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;发送消息&lt;/a&gt;」页面）&lt;/li&gt;
&lt;li&gt;绑定：点击「&lt;a href=&#34;http://sc.ftqq.com/?c=wechat&amp;amp;a=bind&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;微信推送&lt;/a&gt;」，扫码关注同时即完成绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/Screenshot_1.jpg&#34; alt=&#34;SCKEY&#34; /&gt;&lt;/p&gt;

&lt;p&gt;记住 &lt;strong&gt;SCKEY&lt;/strong&gt; ，我们接下来会用着。&lt;/p&gt;

&lt;h2 id=&#34;分流&#34;&gt;分流&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;启动分流，按正常流程配置票务信息。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;点选主界面左下角的推送&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/Screenshot_2.jpg&#34; alt=&#34;分流推送功能&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;填入以下信息&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通知地址 `&lt;a href=&#34;https://sc.ftqq.com/[SCKEY].send&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://sc.ftqq.com/[SCKEY].send&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;通知参数  &lt;code&gt;text=#bypass#&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/Screenshot_3.jpg&#34; alt=&#34;推送配置&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;点击测试发送，即可在微信端，收到本文一开始的推送测试提醒啦&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;实际效果&#34;&gt;实际效果&lt;/h1&gt;

&lt;p&gt;就在配置完成不久后，分流帮我抢到了回家的车票。同时在微信端，Server 酱强制推送。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/IMG_0330.jpg&#34; alt=&#34;成功推送&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/12306bypass/File_succeed.jpg&#34; alt=&#34;成功详情&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;

&lt;p&gt;通过这样的一番配置，我们终于能够安稳的玩耍手机，而不用担心错过订单付款时间。事实上，分流本身的基础功能，也自带了一些提醒服务。但是他们大多较为繁琐。以 QQ 提醒为例，有被顶掉下线的风险。自带的微信提醒，模拟的微信桌面登陆，理论上需要2个微信号。按照上面的操作，我们只需要简单的配置，即可实现强制推送，错过的几率大大减小。&lt;/p&gt;

&lt;p&gt;这样的推送服务，其应用场景不局限于此。这也是我琢磨它的原因之一——应用场景广泛。只要需要推送的地方，都可以嵌入这样一套服务。例如网站新增评论、或是按秒计费的服务器上模型训练结束等等。&lt;/p&gt;

&lt;p&gt;Server 酱实现的功能有限，仅针对微信推送。但这也是它针对国内业务的一种优化。类似这样的推送服务很多，国外的 Slack 功能组件也很丰富。在一些涉及敏感信息的领域，构建一套自己的推送服务，也是不错的主意。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://kuhungio.me/about/</link>
      <pubDate>Wed, 09 Jan 2019 00:14:04 +0800</pubDate>
      
      <guid>https://kuhungio.me/about/</guid>
      <description>

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;笔名：谷粒 kuhung&lt;/li&gt;
&lt;li&gt;毕业院校：华中科技大学 机械学院&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;过往成果&#34;&gt;过往成果&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;时间&lt;/th&gt;
&lt;th&gt;平台&lt;/th&gt;
&lt;th&gt;项目&lt;/th&gt;
&lt;th&gt;名次&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2018-08&lt;/td&gt;
&lt;td&gt;第七届全国媒体技术处理大会&lt;/td&gt;
&lt;td&gt;文本溯源技术测评&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://smp2018.cips-smp.org/rewards.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;95&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2017-06&lt;/td&gt;
&lt;td&gt;Kaggle&lt;/td&gt;
&lt;td&gt;Intel&amp;amp;MobileODTCervicalCancerScreening&lt;/td&gt;
&lt;td&gt;top10%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2017-02&lt;/td&gt;
&lt;td&gt;DataCastle&lt;/td&gt;
&lt;td&gt;精准资助预测赛&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;7&lt;/sup&gt;&amp;frasl;&lt;sub&gt;124&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2016-12&lt;/td&gt;
&lt;td&gt;2016 BYTE CUP&lt;/td&gt;
&lt;td&gt;国际机器学习竞赛&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://biendata.com/competition/bytecup2016/final-leaderboard/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1029&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2016-10&lt;/td&gt;
&lt;td&gt;第五届全国社会媒体处理大会&lt;/td&gt;
&lt;td&gt;用户画像技术测评&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.cips-smp.org/smp2016/public/cup.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;373&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;工作经历&#34;&gt;工作经历&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;2018.07~至今 网易游戏&lt;a href=&#34;https://kuhungio.me/2019/what-is-data-mining/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;数据挖掘工程师&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2017.07~2017.09 微众银行数据科学实习生&lt;/li&gt;
&lt;li&gt;2017.03~2017.06 武汉安天数据挖掘实习生&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;工作方向&#34;&gt;工作方向&lt;/h2&gt;

&lt;p&gt;数据挖掘工程师，机器学习方向。从事数据平台建设和机器学习应用项目开发。&lt;/p&gt;

&lt;h2 id=&#34;兴趣方向&#34;&gt;兴趣方向&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;机器学习前后端及交付落地所涉及技术：Docker、AutoML 、数据可视化等。&lt;/li&gt;
&lt;li&gt;泛领域学界研究及工程化进展：包括机器视觉、自然语言处理、计算广告等。&lt;/li&gt;
&lt;li&gt;其它兴趣爱好：经济学社会学读物、写作分享&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;社交平台&#34;&gt;社交平台&lt;/h2&gt;

&lt;p&gt;微信公众号、头条、知乎搜索【谷粒先生】&lt;/p&gt;

&lt;h2 id=&#34;联系方式&#34;&gt;联系方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://kuhungio.me/images/post/wechat.JPG&#34; alt=&#34;个人微信&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>